---
title: "AI 역사의 쉬운 이해 일반인의 관점에서 보는 기술 발전사"
description: ""
coverImage: "/assets/img/2024-07-10-ALaypersonsHistoryofAI_0.png"
date: 2024-07-10 00:08
ogImage:
  url: /assets/img/2024-07-10-ALaypersonsHistoryofAI_0.png
tag: Tech
originalTitle: "A Layperson’s History of AI"
link: "https://medium.com/on-technology/a-laypersons-history-of-ai-0654e55a3811"
isUpdated: true
---

## 인공지능 연구 논문, 쉽게 설명해 드립니다

🤔 인공지능이 단순한 세포 모양의 퍼셉트론에서 언어 번역, 단백질 접힘과 같은 복잡한 작업을 마스터하는 과정은 어떻게 이뤄졌을까요?

🤔 인공지능이 얼굴을 인식하고, 비디오 게임을 플레이하며, 의미 있는 대화를 나눌 수 있는 비밀은 무엇일까요?

🤔 인공지능의 주요 발전 단계들은 무엇이며, 그것들이 현재의 인공지능 역사를 만들었을까요?

<div class="content-ad"></div>

자세한 답변에 관심이 있다면 계속 읽어보세요.

#인공지능 #인공지능역사 #기술사 #혁신 #딥러닝 #머신러닝 #ChatGPT

이 기사는 인공지능의 역사를 표현하며 이 분야에서 가장 중요한 발전을 설명합니다. 인공지능 분야에서 가장 중요한 연구 논문들을 기반으로 작성되었지만, 일반 대중을 대상으로 설명하려 노력했습니다. 기술적 배경 지식이 필요하지 않습니다.

⭐ 더 기술적인 세부 내용에 관심이 있다면 제 (더 고급) 5부작 기사 시리즈 "인공지능의 역사"를 읽어보세요 (부록 참조).

<div class="content-ad"></div>

# 1️⃣ 간단한 시작부터 스마트 컴퓨터로 (1950-2000)

## 퍼셉트론: 신경망의 탄생

1958년, 인공지능은 퍼셉트론이라는 간단한 아이디어로 시작되었습니다. 이를 컴퓨터 안의 작은 뇌세포로 상상해보세요. 이 퍼셉트론은 받은 데이터를 기반으로 배우고 간단한 결정을 내릴 수 있었습니다. 이 개념은 오늘날 우리가 보는 보다 복잡한 신경망과 기계 학습 알고리즘의 기반 요소가 되었습니다.

## 역전파: 기계에게 더 잘 배우게 가르치기

<div class="content-ad"></div>

1986년, 과학자들은 작은 뇌세포들을 효율적으로 훈련하는 더 좋은 방법을 소개했습니다. 이 방법은 역전파라고 불리며, 컴퓨터가 내부 설정을 조정함으로써 실수로부터 배울 수 있게 도와주었습니다. 이 개선은 딥러닝에 필수적인 다계층 네트워크를 만드는 데 계기를 제공하였습니다.

## 의사 결정 나무: 컴퓨터를 위한 명확한 선택지

1986년에도 의사 결정 나무가 소개되었습니다. 이것은 컴퓨터가 if-then 규칙들을 따라가며 결정을 내릴 수 있게 도와주는 흐름도로 생각해보세요. 이 방법은 특히 노이즈가 많거나 데이터가 불완전한 경우에 인공 지능 응용 프로그램의 기초가 되었습니다.

## 숨겨진 마코프 모델: 순서를 이해하기

<div class="content-ad"></div>

1989년, Hidden Markov Models (HMMs)라 불리는 새로운 접근 방식이 등장했습니다. 이 방법은 컴퓨터가 음성 패턴과 같은 시퀀스를 이해하는 데 도움이 되었습니다. 이 방법은 음성 인식과 같은 응용 프로그램에서 중요한 역할을 하며, 말을 텍스트로 해독하는 데 도움이 됩니다.

## 유니버설 네트워크: 단순함의 힘

또한 1989년, 연구원들은 심지어 단순한 신경망도 어떤 함수든 근사할 수 있다는 것을 증명했습니다. 이 아이디어는 충분한 수의 층과 뉴런이 있다면 신경망이 복잡한 문제를 해결할 수 있고, 이로써 유니버설 근사자가 될 수 있음을 보여 주었습니다.

## 서포트 벡터 머신: 선 긋기

<div class="content-ad"></div>

1992년, 서포트 벡터 머신(SVMs)이 나왔어. SVMs은 컴퓨터가 데이터를 분류하는 데 도움이 되는 알고리즘들이야. 서로 다른 카테고리 사이에서 최적의 경계를 찾아주는 거야. SVMs은 이미지 인식이나 생물정보학과 같은 작업들에서 인기를 얻었어.

**Bagging: 여러 모델을 결합하기**

1996년, Bagging 개념이 소개됐어. 이 기법은 여러 모델을 결합하여 예측 정확도를 향상시킨대. 다양한 모델의 결과를 평균화함으로써, Bagging은 오류를 줄이고 믿을만한 예측을 할 수 있게 도와줘.

**합성곱 신경망(Convolutional Neural Networks): 인간처럼 보기**

<div class="content-ad"></div>

1998년, 합성곱 신경망(Convolutional Neural Networks, CNNs)이 개발되었습니다. 이 네트워크들은 이미지를 인식하는 데 특히 뛰어나며, 이는 인간 두뇌와 유사한 방식으로 시각 데이터를 처리할 수 있기 때문입니다. CNNs가 숫자 인식 및 이미지 분류와 같은 작업에 필수적인 역할을 하게 되었습니다.

## 2️⃣ AI를 더 똑똑하고 빠르게 만들기 (2000–2010)

### Random Forests: 많은 나무의 힘

2001년, Random Forests는 여러 결정 트리를 결합하여 정확성을 향상시켰습니다. 이 방법은 여러 전문가가 의견을 내어 최종 결과를 믿을 수 있도록 한 것과 비슷합니다.

<div class="content-ad"></div>

## 진화 알고리즘: 생존자들의 생존

2002년, 진화 알고리즘이 자연 선택의 아이디어를 활용하여 복잡한 문제를 해결하는 데 사용되었습니다. 이러한 알고리즘은 시간이 지남에 따라 진화하며 가능성의 풀에서 최고의 해결책을 선택하며, 자연이 가장 적응력이 뛰어난 개체를 선택하는 방식과 유사합니다.

## 잠재 디리클레 할당: 숨겨진 주제 찾기

2003년, 잠재 디리클레 할당(LDA)이라는 기술이 컴퓨터가 대량의 텍스트 모음에서 숨겨진 주제를 발견하는 데 도움을 주었습니다. 이 방법은 문서 분류 및 추천 시스템과 같은 응용 프로그램에서 유용하게 사용되었습니다.

<div class="content-ad"></div>

**차원 축소: 데이터 단순화**

2006년, 연구자들은 중요한 정보를 잃지 않으면서 데이터의 복잡성을 줄이는 방법을 개발했습니다. 오토인코더와 같은 기술은 데이터를 간단한 형태로 압축하여 분석 및 시각화를 더 쉽게 만들어주었습니다.

**t-SNE: 복잡한 데이터 시각화**

2008년, t-SNE라는 새로운 기술이 등장하여 고차원 데이터를 두 가지 또는 세 가지 차원으로 시각화할 수 있게 되었습니다. 이 방법은 복잡한 데이터의 지도를 만드는 것과 같아서 패턴과 구조를 더 쉽게 파악할 수 있습니다.

<div class="content-ad"></div>

## ImageNet: Building a Massive Image Database

2009년, ImageNet 프로젝트가 레이블이 달린 거대한 이미지 데이터베이스를 만들었어요. 이 모음집은 AI 모델을 훈련하고 테스트하는 데 중요한 자원이 되었고, 이미지 인식 기술의 중요한 발전을 이끌게 되었어요.

# 3️⃣ 딥 러닝의 시대 (2010–2014)

## AlexNet: 이미지 인식의 돌파구

<div class="content-ad"></div>

2012년, AlexNet이라 불리는 딥 뉴럴 네트워크가 이미지 분류에서 새로운 기록을 세웠어요. AlexNet은 다층과 강력한 GPU(병렬 작업을 수행할 수 있는 강력한 컴퓨터 프로세서)를 사용하여 이미지 속 객체를 놀랄만한 정확도로 인식할 수 있었죠. 이는 더 복잡한 AI 모델의 길을 열어주었습니다.

## 단어 임베딩: 단어 의미 파악

2013년, 연구자들은 단어를 벡터(숫자 목록)로 나타내어 그 의미와 관계를 포착하는 방법을 개발했어요. 이 기술인 단어 임베딩은 번역과 감정 분석과 같은 작업들을 개선했죠.

## 변이 오토인코더: 새로운 데이터 생성

<div class="content-ad"></div>

2013년, VAE(변분 오토인코더)가 인공지능이 새로운 데이터를 생성하는 방법을 제공했습니다. 이러한 모델은 데이터의 근본적인 구조를 학습함으로써 현실적인 이미지, 음악 및 텍스트를 만들어낼 수 있었습니다.

**생성적 적대 신경망(GAN): 현실적인 이미지 생성**

2014년, 생성적 적대 신경망(GAN)이 강력한 도구로 등장하여 현실적인 이미지를 생성하는 데 사용되었습니다. 두 개의 신경망을 서로 대립시킴으로써 GAN은 거의 실제와 같이 보이는 이미지를 만들어낼 수 있어, 미술 및 엔터테인먼트 분야를 혁신하게 되었습니다.

**Dropout: 오버피팅 방지**

<div class="content-ad"></div>

2014년에 드롭아웃이라는 기술이 등장했는데, 이 기술은 신경망이 데이터의 소음에 혼동받지 않도록 도와주는 데 도움이 되었습니다. 훈련 중에 임의로 유닛을 제거함으로써, 드롭아웃은 신경망을 보다 견고하게 만들고 새로운 데이터에서의 성능을 향상시켰어요.

---

## 시퀀스 투 시퀀스 학습: 언어 번역

2014년에 장기 단기 메모리 (LSTM) 네트워크가 등장하여 입력 시퀀스를 출력 시퀀스로 매핑하는 데 사용되었습니다. 이를 통해 언어 번역과 같은 작업이 개선되었죠. 이 모델들은 긴 문장을 처리하고 정확한 번역을 생성할 수 있었어요.

---

## 소프트-어라인: 관련 부분에 집중

<div class="content-ad"></div>

2014년에는 관심 메커니즘이 도입되어 모델이 출력물을 생성할 때 입력의 관련 부분에 집중할 수 있었습니다. 이 방법은 모델이 중요한 정보를 동적으로 강조함으로써 기계 번역과 같은 작업을 개선했습니다.

### Adam: 효율적인 최적화

2014년에 Adam 최적화 알고리즘은 신경망을 효과적이고 빠르게 훈련할 수 있는 방법을 제공했습니다. 이 방법은 과거 성능에 기초하여 학습 속도(컴퓨터가 데이터로부터 학습하는 속도)를 조정하여 대규모 모델을 최적화하는 것을 더 쉽게 만들어 주었습니다.

# 4️⃣ 실시간 및 정확한 인공 지능 (2015–2016)

<div class="content-ad"></div>

## 배치 정규화: 빠른 훈련

2015년, 배치 정규화는 각 레이어 내의 입력을 정규화하여 딥 네트워크 훈련을 가속화했습니다. 이 기술은 학습 속도를 높이고 훈련 시간을 줄여 전체적으로 신경망의 성능을 향상시켰습니다.

## 인셉션: 효율적인 이미지 분류

2015년, 인셉션 모델은 최대한의 컴퓨팅 자원을 활용하는 새로운 아키텍처를 도입했습니다. 여러 스케일에서 동시에 이미지를 처리함으로써, 이 모델은 이미지 분류에서 최신 기술 성능을 달성했습니다.

<div class="content-ad"></div>

## 깊은 Q-러닝: 비디오 게임 마스터하기

2015년, 깊은 Q-네트워크(DQN)는 깊은 강화 학습(실수로부터 학습)을 사용하여 아타리 게임을 인간과 유사한 수준에서 플레이하는 방법을 익혔습니다. 이 방법은 AI가 복잡한 환경을 이해하고 성공을 위한 전략을 개발하는 데 도움이 되었습니다.

## 빠른 R-CNN: 빠른 객체 감지

2015년, Faster R-CNN은 영역 제안과 감지를 하나의 네트워크로 통합하여 객체 감지를 개선했습니다. 이 방법은 높은 정확성으로 실시간 감지를 가능케 하였으며 컴퓨터 비전 분야의 다양한 응용프로그램에 영향을 미쳤습니다.

<div class="content-ad"></div>

## U-Net: 정밀 이미지 세분화

2015년, U-Net은 수축 및 확장 경로를 활용하여 바이오메디컬 이미지 세분화에 혁명을 일으켰습니다. 이 아키텍처는 이미지 내 구조물을 정확하게 지정할 수 있게 해줘서 의학 연구에 이상적입니다.

## 잔차 학습: 더 깊은 네트워크

2015년, 잔차 학습은 매우 깊은 네트워크를 훈련하는 도전에 대처했습니다. 잔차 함수를 학습함으로써, 이러한 네트워크는 최적화하기 쉬워져 시각 인식 작업에서 높은 정확도를 달성했습니다.

<div class="content-ad"></div>

## YOLO: 실시간 객체 감지

2016년, YOLO (You Only Look Once)는 객체 감지에 대한 통합된 방법론을 소개했습니다. 감지를 간단한 예측 작업으로 취급하여 YOLO는 실시간 성능을 달성하면서 자율 주행과 같은 응용에 적합해졌습니다.

# 5️⃣Transformers 및 이상 (2017–2022)

## Transformers: 언어 모델 간소화

<div class="content-ad"></div>

2017년에 Transformer 모델이 복잡한 신경망을 단순한 주의 기반 아키텍처로 대체했습니다. 이 모델은 번역 및 요약과 같은 작업을 개선하여 다양한 고급 AI 응용 프로그램의 기반이 되었습니다.

### BERT: 더 나은 문맥 이해

2018년, BERT (Transformers로부터의 양방향 인코더 표현)는 텍스트를 양방향으로 읽어 문맥을 더 깊이이해해 주었습니다. 이 모델은 언어 처리에서 새로운 기준을 세우며, 질의 응답 및 문장 분류와 같은 작업을 개선했습니다.

### GPT-3: 소수 학습

<div class="content-ad"></div>

202`년에 GPT-3은 대규모 언어 모델의 힘을 입증했습니다. 1750억 개의 파라미터를 보유한 GPT-3은 최소한의 예제로도 다양한 작업을 수행할 수 있어 모델을 확장하여 더 좋은 결과를 달성할 수 있는 잠재력을 보여 주었습니다.

## 비전 트랜스포머: 이미지에 트랜스포머 적용하기

202`년에 비전 트랜스포머(ViT)는 Transformer 모델을 이미지 인식에 적용했습니다. 이미지를 패치(sequence)의 형태로 처리함으로써 ViT는 우수한 결과를 달성했습니다. 이는 컨볼루션 신경망(Convolutional Neural Networks)의 지배를 도전하는 것으로 볼 수 있습니다.

## 알파폴드: 단백질 구조 예측하기

<div class="content-ad"></div>

2021년에 알파폴드(AlphaFold)가 단백질 구조를 정확하게 예측함으로써 오랫동안 해결되지 못했던 과학적 문제를 해결했습니다. 이 업적은 인공지능이 생물학과 의학 분야에서의 잠재력을 증명하며 연구와 약물 발견을 가속화했습니다.

## ChatGPT: 대화형 인공지능

2022년, ChatGPT가 새로운 수준의 대화형 인공지능을 선보였습니다. 대화에 참여하고 질문에 응답하며 다양한 요청을 처리함으로써, ChatGPT는 일상 업무를 지원하고 의미 있는 상호작용을 제공할 수 있는 인공지능의 잠재력을 보여주었습니다.

# 2022년 이후의 전망은?

<div class="content-ad"></div>

2022년부터 현재까지(기사 작성 시간인 2024년 7월) 여러 중요한 발전이 있었습니다. 하지만 아직 이들이 분야에 미친 영향을 완전히 파악하기에는 너무 일러서 기사에서는 이를 생략하기로 결정했습니다. 지금은 1950년부터 2022년까지의 기간을 다루어 인공지능의 진화에 대한 포괄적인 이해를 제공하겠습니다.

읽어주셔서 감사합니다! 피드백을 환영합니다! 특히 중요한 연구를 빠뜨렸다고 생각하거나 어떤 개념이나 아이디어가 충분히 명확하지 않다고 생각하신다면 피드백 주시면 감사하겠습니다.

[이미지](/assets/img/2024-07-10-ALaypersonsHistoryofAI_0.png)

# ⭐ 부록: 원본 진전 시리즈
