---
title: "대형 언어 모델의 기초 이해 신경-기호적 관점에서 바라보기"
description: ""
coverImage: "/assets/img/2024-07-12-FoundationsofReasoningwithLargeLanguageModelsTheNeuro-SymbolicPerspective_0.png"
date: 2024-07-12 23:40
ogImage:
  url: /assets/img/2024-07-12-FoundationsofReasoningwithLargeLanguageModelsTheNeuro-SymbolicPerspective_0.png
tag: Tech
originalTitle: "Foundations of Reasoning with Large Language Models: The Neuro-Symbolic Perspective"
link: "https://medium.com/ai-in-plain-english/foundations-of-reasoning-with-language-models-the-neuro-symbolic-perspective-d3334b44646f"
isUpdated: true
---

인공지능 소프트웨어가 이 기사의 텍스트를 개선하는 데 사용되었습니다.

대형 언어 모델(LLMs)은 AI 분야에서 중요한 이정표를 찍고 있습니다. 텍스트 프롬프트를 계속하거나 질문에 답하며 쉽게 일관된 텍스트 단락을 생성하는 능력은 전문가와 일반인을 모두 매혹시킵니다.

그들의 유창함에 대한 대중의 경탄 뒤에는 현실 세계에 영향을 미치기 위한 그들의 잠재력을 타파하려는 전방대기 공업이 빠르게 성장하고 있는 산업이 숨어 있습니다. 초기 스타트업부터 거대 기술 기업까지, LLMs를 콘텐츠 생성, 고객 지원, 시장 분석 등의 전문적 사용 사례에 활용하기 위해 경주를 벌이고 있습니다.

그러나 자연어 능숙성에서의 성과에도 불구하고, 복잡한 작업 효과적으로 다루기 위한 고급 추론 능력에 대한 공동체의 인식이 증가하고 있습니다. 그들의 능력은 보다 깊은 분석적 엄밀성이나 구조적 논리 없이 표면 수준의 언어 능력에 한정되어 있는 것으로 보입니다.

<div class="content-ad"></div>

**성공은 한정적으로 부서져 있습니다**

일련의 연구들이 LLM (Large Language Models)의 언어 능력에도 불구하고 이 비평을 강조하는 갭을 분석합니다:

- 그들은 종종 지역적으로 일관된 텍스트를 생성하지만 심층적 검토에서 논리적 모순을 보입니다. 그들의 지식은 견고한 인과 관계 없이는 파악하기 어렵습니다.
- 그들은 다단계 추론 체이닝, 제약 조건 충족, 또는 불확실성 하에서의 계획을 필요로 하는 작업들에 어려움을 겪습니다. 예를 들어, LLM은 복잡한 다이어그램 추론 질문에서 실패합니다.
- 그들의 블랙박스 성격은 그들의 추론 과정을 공식적으로 검증하거나 수정하기 어렵게 만듭니다. 그러나 의료 분야와 같은 응용 프로그램에서 설명 가능성은 필수적입니다.

본질적으로, 현재의 LLM들은 인간 전문가들이 갖춰야 할 발전된 추론 능력 없이 좁고 단기적인 재능을 보여줍니다 — 가정을 파악하고, 해결책을 계획하고, 문제를 모듈화하며, 지식의 갭을 노출하는 것입니다.

<div class="content-ad"></div>

구조화된 추론의 필요성

총론적으로, LLMs가 복잡한 현실 세계 문제에 효과적으로 대처하는 것을 방해하는 기본적인 추론 결함이 있는 것으로 보입니다. 그들은 체계적인 사고 능력인 구조화된 사고를 부족하게 합니다 — 논리를 체계적으로 적용하여 결론을 도출하는 능력.

인간과 유사한 추론 능력을 달성하기 위해 이 결함을 해소하는 것은 현재 AI 연구의 가장 시급한 도전 중 하나이며 활발한 분야입니다. 그리고 현재 강세를 띠고 있는 중요한 접근 방식 중 하나는 명시적 추론 프레임워크를 설계하여 문제 분석 중 시스템적으로 LLM의 추론 능력을 안내하고 강화하는 것입니다.

[링크](/assets/img/2024-07-12-FoundationsofReasoningwithLargeLanguageModelsTheNeuro-SymbolicPerspective_0.png)

<div class="content-ad"></div>

## 추론능력 정의하기

인공지능 시스템인 대규모 언어 모델(LLMs)의 추론 능력에 대해 이야기할 때, 정확히 무엇을 의미하는지 알아볼까요? 몇 가지 주요 측면은 다음과 같습니다:

논리적 추론: 유효한 주장을 사용하여 이용 가능한 정보나 믿음에 기초해 사건, 개념 또는 상황에 대한 타당한 추론을 내리는 능력. 이에는 연역적 추론, 귀납적 추론, 타당 추론, 삼단 논법 추론 및 유추적 추론과 같은 기술이 포함됩니다.

인과적 추론: 변수와 사건 간의 인과 관계를 이해하고 모델링하는 능력. 이는 상관관계 대 인과관계 식별, 원인과 결과에 대한 방향과 메커니즘 결정, 상반되는 추론을 만들고 개입에 대해 추론하는 것을 포함합니다.

<div class="content-ad"></div>

일상적인 상식을 활용한 추론: 세상에 대한 기본적인 상식과 사실을 바탕으로 일반적 상황과 사건에 대한 가정과 추론을 하는 것을 말합니다. 직관적 물리학을 이해하거나 인간 활동 뒤에 숨겨진 동기를 추론하는 것과 같은 예시가 될 수 있습니다.

설명 가능한 추론: 특정 결론에 이르는 과정과 논리 체인을 설명할 수 있는 능력을 의미합니다. 이는 후성인 인식 능력이 필요하며, 사고 과정 자체에 대해 내성화하고 표현하는 능력이 필요합니다.

구조화된 추론: 문제 상황에 맞게 세밀하게 조정된 명시적 추론 프레임워크를 체계적으로 적용하는 것을 의미합니다. 작업 분해 전략, 탐색 트리, 증명 유도 등과 같은 시스템적 접근은 복잡성을 다루는 데 중요합니다.

능숙한 추론의 특징:

<div class="content-ad"></div>

인간들이 복잡한 문제를 해결하기 위해 추론을 사용할 때, 경험이 풍부한 전문가들을 구별하는 중요한 특징 몇 가지가 있습니다.

- 가정, 지식 공백 및 믿을 수 없는 주장 식별
- 구조화된 작업흐름을 통한 해법 전략화
- 문제를 모듈화하고 하위 작업 다룸
- 대안을 철저히 탐색
- 장단점 및 대가를 강조
- 새로운 관측에 기반한 신조 갱신
- 필요한 경우 추가 정보 탐색

요약하면, 고급 추론 능력은 편향을 완화하면서 구조적 방식으로 복잡한 작업에 접근하는 것을 가능하게 합니다. 이는 프로그래밍과 유사합니다. 그리고 대형 언어 모델에 명시적 추론 프레임워크를 통합하는 것이 이 연구의 핵심입니다.

# 추론 프레임워크에 대한 선도적인 연구

<div class="content-ad"></div>

이 안내서는 대형 언어 모델에 구조화된 사고를 심어 넣는이 흥미로운 분야의 최신 개발 사항을 다룹니다.

## 1. 추론의 위상

이 접근 방식은 LLMs 내에서 추론의 흐름을 명시적인 위상 구조로 모델링하는 데 초점을 맞춥니다. 가설은 LLMs에 구조화된 이산 요소를 도입하면 그들의 논리적 분석을 강화할 수 있다는 것입니다.

예를 들어, Chain-of-Thought (CoT) 프롬프트는 LLMs에게 문제에 체계적으로 접근하도록 선형 단계별 추론 가이드라인을 추가하는 것입니다 - 마치 프로그래머들이 실제 구현 전에 가짜 코드의 뼈대를 사용하는 것과 유사합니다.

<div class="content-ad"></div>

Tree-of-Thought은 LLM들이 여러 접근 방식을 동시에 탐색할 수 있도록 가지치기 논리 흐름을 허용함으로써 기존의 이점을 높입니다. 사람들이 가능성을 나열하여 해결책을 계획하는 것처럼, Graph-of-Thought는 더 복잡한 추론을 반영하기 위해 추론 체인 간 상호 연결을 가능하게 합니다.

그러므로 구조적 전제는 LLM들의 자유로운 신경 주의 패턴을 체계적인 위상 구조로 보완함으로써 분석적인 엄격함과 탄탄함을 향상시킬 수 있는지에 초점을 맞추고 있습니다. 실험 결과가 유망해 보입니다.

2. 자가 발견

DeepMind가 제안한 이 프레임워크는 모델이 기본적인 추론 구성 요소를 결합하여 각 작업에 맞는 추론 구조를 동적으로 구축할 수 있도록 허용합니다.

<div class="content-ad"></div>

기본 기술로는 작업을 하위 문제로 분해하는 기법, 표현을 재정의하는 것, 외부 지식 통합, 대안적 시각 탐색 등이 포함되어 있습니다.

최소한의 블록만 사용하는 것을 원칙으로 하는 모형은 주어진 문제에 대해 최소하지만 최대효과의 추론 템플릿을 생성하는 방법을 배웁니다.

수동 토폴로지 생성을 피하는 이 자동화된 적응 접근법은 유리합니다. 예비 결과는 이러한 모델에서 발견된 추론 구조를 사용하는 것으로 어려운 벤치마크에서 개선된 성능을 보여줍니다.

<div class="content-ad"></div>

3. CodeMind

CodeMind은 코드 추론을 대상으로 하며, 다음과 같은 형식적인 지표를 제안합니다:

- 독립적 추론 — 모델을 평가할 때, 명세나 맥락 없이 코드 논리에만 근거하여 생소한 프로그램을 분석합니다. 순수한 분석 능력을 직접적으로 확인합니다.
- 종속적 추론 — 모델이 스스로 만든 코드를 신뢰성 있게 분석할 수 있는지 확인하기 위해, 생성된 프로그램에 대한 설명을 요청합니다. 자체 일관성을 평가합니다.
- 명세 추론 — 테스트 케이스에 대한 프롬프트 실행 중에 제시된 요구사항에 대한 구현의 일치도를 측정합니다.

구현의 제어된 생성과 사용자 정의 평가를 통해 모델의 추론 능력을 정량화하고, 이는 코드 논리 분석 능력에 대한 평가를 갈무리합니다.

<div class="content-ad"></div>

안녕하세요!

아래는 최신 LLM(Large Language Models)의 코딩 과제 능력을 자세하게 살펴본 향상된 테이블입니다. 특히 코드 추론을 평가하기 위한 CodeMind 프레임워크에 중점을 두었습니다.

보다 단순한 명세에 기반한 코드 생성 및 수정에서 뚜렷한 강점을 보이고 있지만, 복잡한 시나리오, 미묘한 이해, 그리고 심층적 추론에 도전을 겪고 있는 것으로 나타났어요.

<div class="content-ad"></div>

창수 리우, 시주오 딜런 장, 레이하네 자바르반의 작품에 대한 참고 사항의 포함은 CodeMind 프레임워크에 대한 추가 탐구 및 검증을 위한 기초를 제공합니다.

# 전문화된 추론 모듈

검색 보충을 위한 지식 그래프

지식 그래프는 언어 모델을 여러 가지 방법으로 보충할 수 있는 외부 구조화된 지식 원천을 제공합니다.

<div class="content-ad"></div>

- 쿼리는 추론 작업과 관련된 맥락적인 하위 그래프를 검색할 수 있어요. 관련된 사실과 관계를 제공하여 언어 모델의 예측을 뒷받침해요.
- 개인화된 페이지랭크와 같은 그래프 탐색 알고리즘은 인접한 연결된 정보를 발견할 수 있어요. 이를통해 키워드 검색으로는 놓칠 수 있는 정보를 확장된 맥락을 통해 발견할 수 있어요. 관련 체인을 따라 확장된 맥락은 상상력 리스크를 줄여요.

- 위상적 지표 및 그래프 알고리즘은 추론을 중점으로 하는 중요한 엔티티를 식별하고 우선순위를 정하는 추가 신호를 제공해요. 예를 들어, 커뮤니티 탐지는 제한된 검색을 위해 맥락적 클러스터를 드러내 줄 수 있어요.

- 관련된 엔티티 및 술어에 대한 다중 단계 경로는 결론을 도출하는 방법에 대한 이해할 수 있는 근거를 제공해요. 이는 설명 가능성과 정확성을 지원해 줘요.

그러니까, 지식 그래프는 언어 모델을 향상시킵니다. 더 넓은 맥락적 기반을 통해 커버리지를 늘리며, 연결성을 통한 확대, 위상학적 가이드에 따른 중요 지역에 초점을 맞추고, 중간의 이해 가능한 추론 체인에 주목해요.

특화된 보조 모듈

특정 추론 기술을 대상으로 하는 추가 모듈은 지식 검색 프로세스를 보완할 수 있어요.

<div class="content-ad"></div>

- 자기 일관성 모듈은 다중 독립적 추론 체인을 생성하고 내부 일관성이 가장 높은 옵션을 선택하여 결론을 다양한 관점에서 일치시킵니다.
- 적대적 추론 모듈은 현재 작업 중인 가설에 대한 가능한 반사사실적 시나리오와 증거를 도입하여 모델이 주장을 강화하고 대안적 전망을 다루도록 합니다.
- 불확실성 모델링 모듈은 이유 과정에서 새로운 전제들이 드러날 때마다 반복적으로 업데이트되고 정제되는 가능한 결과들에 대한 확률 분포를 유지합니다.

이러한 전문화된 모듈을 지식 검색과 연계하여 연구의 철저함과 넓은 시각을 제공하면서도 전체적인 작업 흐름을 해석 가능하게 유지하고 복잡한 추론 작업에 최적화됩니다.

모듈식 접근법을 사용하면 맞춤형 파이프라인을 통해 모델 추론의 특정 약점에 유연하게 대응할 수 있습니다. 아키텍처는 이질적인 구성 요소 간의 보완적 강점을 활용할 수 있습니다.

## 구조화된 추론에서 술어의 역할

<div class="content-ad"></div>

프리미스 순서 효과는 대형 언어 모델이 추론 작업에서 실수를 일으키는 현상을 가리키는데, 심지어 순열이 작업이나 도출 가능한 결론에 영향을 주지 않는 한에도 특히 뚜렷하게 관찰됩니다.

- 프리미스는 논리 추론의 기초로 작용하며 새로운 결론에 이르도록 하는 명제, 사실, 공리 또는 규칙을 의미합니다. 추론 작업은 일반적으로 시작 맥락으로 프리미스 집합을 제공합니다.
- 엄밀한 논리 추론에서 프리미스의 상대적인 배치는 최종으로 유추할 수 있는 결론을 변경하지 않습니다. 명제 순서에 관계없이 같은 결론이 유지됩니다. 그러나 사람들에게는 어떤 순서가 단계별로 따르기 쉬운 추론 프로세스를 만듭니다.
- 반면, 현재 대형 언어 모델은 프리미스 순서에 매우 취약한 것으로 밝혀졌습니다. 결론은 동일한 경우에도 추론 단계의 순서와 일치하지 않을 때 정확도가 급격히 하락합니다(30% 이상 감소 관찰).
- 구체적으로, 대형 언어 모델은 프리미스 순서가 "순방향 순서"와 일치할 때 최고의 정확도를 달성합니다. 다시말해, 프리미스가 추론 지식의 필요한 순서대로 프롬프트에 나타나면 성능이 빠르게 악화되는 비순차적인 절차에 어려움을 겪는 모습이 나타납니다.
- 이 효과는 논리적 추론의 긴 연쇄와 주의를 산만하게하는/관련 없는 프리미스의 도입에 의해 지속되며 강화됩니다. 동일한 논리 작업에 대해 모델에게 사람보다 순서가 훨씬 더 중요한 것으로 보입니다.

현재 대형 언어 모델들은 프리미스 순서와 일치하는 추론 순서에 비례하여 결론을 유도하는 것보다는, 주어진 순서와 무관하게 제시된 명제로부터 결론을 유연하게 도출해야 공정하지 않습니다.

지식 그래프의 핵심에는 개념을 특징 짓고 연결하는 관계인 술어가 있습니다. 하지만 술어는 단순한 레이블 이상의 의미를 갖습니다. 그들의 의미는 배경화, 서명 및 의미추론에서 비롯됩니다.

<div class="content-ad"></div>

지식 벡터 임베딩을 통해 의미론적 관련성을 평가하는 것도 중요하지만, 상징적 관련화는 더 강력한 신호를 제공합니다. 술어는 지식 그래프에 외부 이해를 임베딩하는 체계적인 골조 역할을 합니다.

<div class="content-ad"></div>

2024년에 Chen 등 (Chen et al. 2024)이 발견한 전제 순서 효과는 지식 그래프 형태의 구조화된 지식을 활용하여 추론에 맥락을 제공하는 데 도움이 된다는 점을 지지하는 것 같습니다:

- 지식 그래프는 개념, 엔티티 및 그들 간의 관계에 대해 자연스럽게 구조를 부여하므로 추론을 위한 맥락 시퀀스를 제한하고 임의의 순열을 제한할 수 있습니다.
- 지식 그래프의 연결은 해석 가능한 순서로 전제를 연결하며, 모델에 대한 다중-점프 추론을 용이하게 할 것으로 기대됩니다. 이는 순방향 순서 프롬프트가 LLM의 추론 단계를 잘 일치시킨 것과 유사합니다.
- 지식 그래프 내의 맥락은 형식적으로 정의된 스키마와 온톨로지가 있으므로 다의성이 적어집니다. 이는 불필요하거나 주의 산만한 정보를 제한함으로써 순서 효과를 악화시키는 요소로 분석되었습니다.
- 지식 그래프 내의 다중 관계 데이터 표현은 다단계, 순회 및 조합 추론 패턴에 대해 쉽게 이해할 수 있습니다. 고정된 스키마는 LLM이 보여준 순서 모델 제한을 완화합니다.

지식 그래프는 부서진 텍스트 순서에 대한 의존성을 줄이며, 추론을 위한 해석 가능한 구조화된 경로를 제공하고, 부수적인 정보를 걸러내며 개별 원자적 사실을 결합하는 데 지원이 됩니다.

모든 이러한 요소들은 이 논문에서 특성화된 전제 순서 효과와 관련된 LLM의 취약성을 해소할 수 있습니다.

<div class="content-ad"></div>

타로 전문가인 당신의 지식은 정말 놀라워요! 이해하기 쉽게 번역해 드리겠습니다.

## 추론을 위한 순차 결정 만들기

회상 증강 사고 과정(RATP) 프레임워크는 지식 그래프 상에서 추론을 마르코프 결정 과정(MDP)으로 캐스팅하여 순차적 의사 결정 작업으로 다룹니다.

각 단계에서 모델은 기억에서 사고를 처리할지 외부 문서를 검색을 통해 통합할지를 결정하면서 내부 지식과 외부 지식을 균형 있게 유지합니다. 이 결정 트리를 탐색하는 것은 상향식 유틸리티 추정 값을 가이드로 하는 몬테카를로 트리 탐색을 활용합니다.

<div class="content-ad"></div>

완벽한 작업 흐름은 장기적 맥락과 관련없는 정보 검색을 다루기 위한 확률적 계획을 포함하는 반복적인 검색 및 추론 단계로 이루어져 있습니다. 이는 두 가지 주요 약점입니다. 이 방식으로 검색을 명시적 추론 위상에 통합하면 투명성과 견고성을 제공합니다.

지식 그래프의 핵심 역할과 순차적 추론 아키텍처의 구성요소로서, 술어 및 검색 보강은 언어 모델이 구조화된 이해력을 갖추는 동시에 주요 표현 병목 현상을 극복할 수 있게 해줍니다.

외부의 지식과 알고리즘적 엄격함, 최적화된 추론의 퓨전은 견고하고 신뢰할 수 있는 추론을 달성하기 위한 유망한 방향을 제시합니다.

# 앞으로의 길

<div class="content-ad"></div>

앞으로 강력하고 인간과 유사한 투명한 추론을 향한 길은 대형 언어 모델의 인상적인 상관관계 주도적 추론과 지식 그래프에 포함된 구조화된 설명적 지식을 결합한 통합된 아키텍처에서 기인할 것입니다.

대형 언어 모델은 텍스트를 계속해서 생성하고 일관된 단락을 만들어내는 뛰어난 다재다능성을 보여주지만, 사실을 뒷받침하지 않는 주장, 논리적인 모순 및 내부 사고 과정을 명시적으로 설명하지 못하는 능력 등의 문제가 있습니다. 그들의 지식은 신경 가중치 행렬의 수천 차원 안에 내재적이고 암시적으로 남아 있습니다.

반면, 지식 그래프는 실제 세계에 근거를 둔 개념 및 관계의 명시적인 인과 모델을 제공합니다. 그러나 그들의 정적 명제적 사실은 다재다능한 추론 능력을 갖추고 있지 않습니다.

양자를 결합한 신경-기호 시스템은 개별적인 약점을 완화하고 강점을 살리며 통계적 다재다능성을 사실적 책임성과 융합하는 것을 약속합니다.

<div class="content-ad"></div>

벡터, 상징적 및 확률적 구성 요소 간의 밀접한 협력을 가능케 하는 접근 방식이 투명한 추론 기술을 개발하기 위한 가장 기배한 토양을 제공합니다. 내재적 및 획득된 지식을 연결하기 위한 양방향 커뮤니케이션이 핵심 요소입니다.

지식 그래프를 활용하여 추론 경로를 안내하거나 텍스트 프롬프트로 그래프 분석을 재평가하는 기술이 설정한 템플릿은 매력적인 가능성을 부각시킵니다.

추론을 위한 신경-상징적 구조가 아직 초기 단계에 있음에도 불구하고, 신경 상관관계를 구조화된 인과 모델과 융합하는 철학적 기초는 다재다능하고 신뢰성 있는 지능 해제에 독특하게 발돋움할 것으로 보입니다.

앞으로 몇 년 동안은 기호, 벡터 및 확률을 아우르는 혼합 추론에 특히 민감한 모델, 목표, 벤치마크 및 하드웨어 가속기에서 신속한 공동 혁신이 예상됩니다. 그리고 핵심을 이끌 수 있는 선구적인 다학제적 팀은 학문적 여백을 넘어서 발상할 수 있을 것입니다.

<div class="content-ad"></div>

모든 것의 근원, 우리의 내면은 이성적으로 추론하고 내재된 직관과 얻은 모델을 시너지적으로 결합시킵니다. 그래서 내재된 신경적 적응과 체계적인 외부 지식을 결합한 AI를 개발함으로써, 기계가 사고하고 설명하는 데 한 발짝 더 나아갈 수 있게 되었습니다.

# 간단한 한국어로 🚀

In Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:

- 작성자를 클랩하고 팔로우해 주세요 ️👏️️
- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter
- 다른 플랫폼 방문하기: Stackademic | CoFeed | Venture
- PlainEnglish.io에서 더 많은 콘텐츠 확인하기
