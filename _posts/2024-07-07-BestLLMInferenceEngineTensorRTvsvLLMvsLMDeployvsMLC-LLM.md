---
title: "ìµœê³ ì˜ LLM ì¶”ë¡  ì—”ì§„ì€ TensorRT vs vLLM vs LMDeploy vs MLC-LLM ë¹„êµ"
description: ""
coverImage: "/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_0.png"
date: 2024-07-08 00:00
ogImage:
  url: /assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_0.png
tag: Tech
originalTitle: "Best LLM Inference Engine? TensorRT vs vLLM vs LMDeploy vs MLC-LLM"
link: "https://medium.com/@zaiinn440/best-llm-inference-engine-tensorrt-vs-vllm-vs-lmdeploy-vs-mlc-llm-e8ff033d7615"
isUpdated: true
---

ë‹¤ì–‘í•œ LLM ì¶”ë¡  ì—”ì§„ ë²¤ì¹˜ë§ˆí‚¹ ì¤‘ì…ë‹ˆë‹¤.

![LLM Inference Engines](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_0.png)

LLMì€ ì±„íŒ… ë° ì½”ë“œ ì™„ì„± ëª¨ë¸ê³¼ ê°™ì€ í…ìŠ¤íŠ¸ ìƒì„± ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ë“¤ì˜ í° í¬ê¸°ëŠ” ì¶”ë¡ ì— ë„ì „ì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ë³¸ ì¶”ë¡ ì€ LLMì´ í† í° ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ê° ë‹¤ìŒ í† í°ì— ëŒ€í•œ ë°˜ë³µ í˜¸ì¶œì´ í•„ìš”í•©ë‹ˆë‹¤. ì…ë ¥ ì‹œí€€ìŠ¤ê°€ ì»¤ì§ˆìˆ˜ë¡ ì²˜ë¦¬ ì‹œê°„ì´ ì¦ê°€í•©ë‹ˆë‹¤. ê²Œë‹¤ê°€, LLMì€ ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ, ëª¨ë“  ê·¸ ê°€ì¤‘ì¹˜ë“¤ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ê¸° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.

LLM ì¶”ë¡  ë° ì„œë¹„ìŠ¤ ìµœì í™”ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ í”„ë ˆì„ì›Œí¬ì™€ íŒ¨í‚¤ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¶”ë¡  ì—”ì§„ì„ ì‚¬ìš©í•˜ê³  ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤.

<div class="content-ad"></div>

- TensorRT-LLM
- vLLM
- LMDeploy
- MLC-LLM

# 1. TensorRT-LLM

# ì†Œê°œ

TensorRT-LLMì€ NVIDIA GPUì—ì„œ ìµœì‹  LLMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ ê°€ì†í™”í•˜ê³  ìµœì í™”í•˜ëŠ” ë˜ ë‹¤ë¥¸ ì¶”ë¡  ì—”ì§„ì…ë‹ˆë‹¤. LLMì€ TensorRT Engineìœ¼ë¡œ ì»´íŒŒì¼ë˜ê³  In-Flight Batching(ëŒ€ê¸° ì‹œê°„ ê°ì†Œì™€ ë” ë†’ì€ GPU í™œìš©ë¥ ì„ í—ˆìš©í•˜ëŠ” ì²˜ë¦¬)ê³¼ ê°™ì€ ì¶”ë¡  ìµœì í™”ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ Triton ì„œë²„ì™€ í•¨ê»˜ ë°°í¬ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìµœì í™”ì—ëŠ” paged KV caching, MultiGPU-MultiNode Inference ë° FP8 ì§€ì›ì´ í¬í•¨ë©ë‹ˆë‹¤.

<div class="content-ad"></div>

# ì‚¬ìš©ë²•

HF ëª¨ë¸, TensorRT ëª¨ë¸ ë° TensorRT-INT8 ëª¨ë¸(ì–‘ìí™”) ê°„ì˜ ì‹¤í–‰ ì‹œê°„, ROUGE ì ìˆ˜, ì§€ì—° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ì„ ë¹„êµí•  ê²ƒì…ë‹ˆë‹¤.

Linux ì‹œìŠ¤í…œì— Nvidia-container-toolkitì„ ì„¤ì¹˜í•˜ê³  HF ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ Git LFSë¥¼ ì´ˆê¸°í™”í•˜ê³  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.

```js
!curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
!apt-get update
!git clone https://github.com/NVIDIA/TensorRT-LLM/
!apt-get update && apt-get -y install python3.10 python3-pip openmpi-bin libopenmpi-dev
!pip3 install tensorrt_llm -U --pre --extra-index-url https://pypi.nvidia.com
!pip install -r TensorRT-LLM/examples/phi/requirements.txt
!pip install flash_attn pytest
!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash
!apt-get install git-lfs
```

<div class="content-ad"></div>

ì§€ê¸ˆ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.

```js
PHI_PATH="TensorRT-LLM/examples/phi"
!rm -rf $PHI_PATH/7B
!mkdir -p $PHI_PATH/7B && git clone https://huggingface.co/microsoft/Phi-3-small-128k-instruct $PHI_PATH/7B
```

ëª¨ë¸ì„ TensorRT-LLM ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ë¡œ TensorRT-LLMì„ ë¹Œë“œí•˜ì„¸ìš”.

```js
!python3 $PHI_PATH/convert_checkpoint.py --model_dir $PHI_PATH/7B/ \
                --dtype bfloat16 \
                --output_dir $PHI_PATH/7B/trt_ckpt/bf16/1-gpu/
# ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° TensorRT-LLM ëª¨ë¸ ë¹Œë“œ
!trtllm-build --checkpoint_dir $PHI_PATH/7B/trt_ckpt/bf16/1-gpu/ \
                --gemm_plugin bfloat16 \
                --output_dir $PHI_PATH/7B/trt_engines/bf16/1-gpu/
```

<div class="content-ad"></div>

ì´ì œ HF ëª¨ë¸ì— INT8 ê°€ì¤‘ì¹˜ë§Œ ì–‘ìí™”ë¥¼ ì ìš©í•˜ê³  ì²´í¬í¬ì¸íŠ¸ë¥¼ TensorRT-LLMìœ¼ë¡œ ë³€í™˜í•´ë³´ì„¸ìš”.

```python
!python3 $PHI_PATH/convert_checkpoint.py --model_dir $PHI_PATH/7B \
                --dtype bfloat16 \
                --use_weight_only \
                --output_dir $PHI_PATH/7B/trt_ckpt/int8_weight_only/1-gpu/
!trtllm-build --checkpoint_dir $PHI_PATH/7B/trt_ckpt/int8_weight_only/1-gpu/ \
                --gemm_plugin bfloat16 \
                --output_dir $PHI_PATH/7B/trt_engines/int8_weight_only/1-gpu/
```

ì´ì œ ë² ì´ìŠ¤ phi3 ë° ë‘ TensorRT ëª¨ë¸ì„ ìš”ì•½ ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.

```python
%%capture phi_hf_results
# Huggingface
!time python3 $PHI_PATH/../summarize.py --test_hf \
                       --hf_model_dir $PHI_PATH/7B/ \
                       --data_type bf16 \
                       --engine_dir $PHI_PATH/7B/trt_engines/bf16/1-gpu/
%%capture phi_trt_results
# TensorRT-LLM
!time python3 $PHI_PATH/../summarize.py --test_trt_llm \
                       --hf_model_dir $PHI_PATH/7B/ \
                       --data_type bf16 \
                       --engine_dir $PHI_PATH/7B/trt_engines/bf16/1-gpu/
%%capture phi_int8_results
# TensorRT-LLM (INT8)
!time python3 $PHI_PATH/../summarize.py --test_trt_llm \
                       --hf_model_dir $PHI_PATH/7B/ \
                       --data_type bf16 \
                       --engine_dir $PHI_PATH/7B/trt_engines/int8_weight_only/1-gpu/
```

<div class="content-ad"></div>

ì´ì œ ê²°ê³¼ë¥¼ ìº¡ì²˜í•œ í›„ ì¶œë ¥ì„ íŒŒì‹±í•˜ê³  ëª¨ë“  ëª¨ë¸ ì‚¬ì´ì˜ ì‹¤í–‰ ì‹œê°„, ROUGE ì ìˆ˜, ëŒ€ê¸° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ê·¸ë¦¼ì„ ê·¸ë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![Image 1](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_1.png)

![Image 2](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_2.png)

## 2. vLLM

<div class="content-ad"></div>

# ì†Œê°œ

vLLMì€ ìµœì‹  ê¸°ìˆ ì„ í™œìš©í•œ LLM ì¶”ë¡  ë° ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í˜ì´ì§€ ì–´í…ì…˜, ì—°ì† ë°°ì¹˜, ì–‘ìí™” (GPTQ, AWQ, FP8), ê·¸ë¦¬ê³  ìµœì í™”ëœ CUDA ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ì†ë„ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

# ì‚¬ìš© ë°©ë²•

ë§ˆì´í¬ë¡œì†Œí”„íŠ¸/Phi3-mini-4k-instructì˜ ì²˜ë¦¬ëŸ‰ê³¼ ëŒ€ê¸° ì‹œê°„ì„ í‰ê°€í•´ ë´…ì‹œë‹¤. ë¨¼ì € ì˜ì¡´ì„±ì„ ì„¤ì •í•˜ê³  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒë¶€í„° ì‹œì‘í•´ ë³´ì„¸ìš”.

<div class="content-ad"></div>

!pip install -q vllm
!git clone https://github.com/vllm-project/vllm.git
!pip install -q datasets
!pip install transformers scipy
from vllm import LLM, SamplingParams
from datasets import load_dataset
import time
from tqdm import tqdm
from transformers import AutoTokenizer

ì´ì œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ë°ì´í„°ì…‹ì˜ ì¼ë¶€ì—ì„œ ì¶œë ¥ì„ ìƒì„±í•´ ë´…ì‹œë‹¤.

dataset = load_dataset("akemiH/MedQA-Reason", split="train").select(range(10))
prompts = []
for sample in dataset:
prompts.append(sample)
sampling_params = SamplingParams(max_tokens=524)
llm = LLM(model="microsoft/Phi-3-mini-4k-instruct", trust_remote_code=True)
def generate_with_time(prompt):
start = time.time()
outputs = llm.generate(prompt, sampling_params)
taken = time.time() - start
generated_text = outputs[0].outputs[0].text
return generated_text, taken
generated_text = []
time_taken = 0
for sample in tqdm(prompts):
text, taken = generate_with_time(sample)
time_taken += taken
generated_text.append(text)

# ì¶œë ¥ì„ í† í¬ë‚˜ì´ì¦ˆí•˜ê³  ì²˜ë¦¬ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")
token = 1
for sample in generated_text:
tokens = tokenizer(sample)
tok = len(tokens.input_ids)
token += tok
print(token)
print("tok/s", token // time_taken)

![2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_3.png](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_3.png)

<div class="content-ad"></div>

ì´ë²ˆì—ëŠ” ShareGPT ë°ì´í„°ì…‹ì—ì„œ vLLMì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí‚¹í•´ë³´ê² ì–´ìš”.

```js
!wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json
%cd vllm
!python benchmarks/benchmark_throughput.py --backend vllm --dataset ../ShareGPT_V3_unfiltered_cleaned_split.json --model microsoft/Phi-3-mini-4k-instruct --tokenizer microsoft/Phi-3-mini-4k-instruct --num-prompts=1000
```

![Markdown image](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_4.png)

# 3. LMDeploy

<div class="content-ad"></div>

# ì†Œê°œ

ì´ íŒ¨í‚¤ì§€ëŠ” íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ì œê³µí•˜ë©´ì„œ, ì§€ì†ì ì¸ ë°°ì¹˜, ë¸”ë¡ëœ KV ìºì‹œ, ë™ì  ë¶„í•  ë° í•©ë³‘, í…ì„œ ë³‘ë ¬ ì²˜ë¦¬, ê³ ì„±ëŠ¥ CUDA ì»¤ë„ì„ ì œê³µí•¨ìœ¼ë¡œì¨ LLMsë¥¼ ì••ì¶•, ë°°í¬ ë° ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ 4ë¹„íŠ¸ ì¶”ë¡  ì„±ëŠ¥ì€ FP16ì˜ 2.4ë°° ë†’ë‹¤ëŠ” íš¨ê³¼ì ì¸ ì–‘ìí™”ë¥¼ ì œê³µí•˜ë©°, ë‹¤ì¤‘ ëª¨ë¸ ì„œë¹„ìŠ¤ë¥¼ ì—¬ëŸ¬ ëŒ€ì˜ ë¨¸ì‹ ê³¼ ì¹´ë“œì— ê±¸ì³ ë°°í¬í•˜ëŠ” ê°„í¸í•œ ë¶„ì‚° ì„œë²„ ë° ìƒí˜¸ì‘ìš© ì¶”ë¡  ëª¨ë“œ(ëŒ€í™” ë‚´ì—­ì„ ê¸°ì–µí•˜ê³  ê³¼ê±° ì„¸ì…˜ì˜ ë°˜ë³µ ì²˜ë¦¬ë¥¼ í”¼í•¨)ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë˜í•œ í† í° ëŒ€ê¸° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰, ìš”ì²­ ì²˜ë¦¬ëŸ‰, API ì„œë²„ ë° íŠ¸ë¦¬í†¤ ì¶”ë¡  ì„œë²„ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

# ì‚¬ìš©ë²•

ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ê³  íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

<div class="content-ad"></div>

LMdeployê°€ TurboMindì™€ PyTorch ë‘ ê°œì˜ ì¶”ë¡  ì—”ì§„ì„ ê°œë°œí–ˆë‹¤ëŠ” ì •ë³´ì•¼.

ë§ˆì´í¬ë¡œì†Œí”„íŠ¸/Phi3-mini-128k-instructì˜ PyTorch ì—”ì§„ì„ í”„ë¡œíŒŒì¼ë§í•´ ë³´ìêµ¬.

<div class="content-ad"></div>

**í”„ë¡œí•„ ìƒì„± ì½”ë“œ:**

```shell
!python3 profile_generation.py microsoft/Phi-3-mini-128k-instruct --backend pytorch
```

ì´ ì½”ë“œëŠ” ì—”ì§„ì„ ì—¬ëŸ¬ ë¼ìš´ë“œì— ê±¸ì³ í”„ë¡œí•„ë§í•˜ê³ , ê° ë¼ìš´ë“œì— ëŒ€í•œ í† í° ì§€ì—° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ì„ ë³´ê³ í•©ë‹ˆë‹¤.

**Pytorch ì—”ì§„ì˜ í† í° ì§€ì—° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ í”„ë¡œí•„:**

![ì´ë¯¸ì§€](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_5.png)

<div class="content-ad"></div>

# 4. MLC-LLM

# ì†Œê°œ

MLC-LLMì€ MLCEngineì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê³ ì„±ëŠ¥ ë°°í¬ ë° ì¶”ë¡  ì—”ì§„ì„ ì œê³µí•©ë‹ˆë‹¤.

# ì‚¬ìš©ë²•

<div class="content-ad"></div>

ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•œ í›„ condaë¡œ ì¢…ì† í•­ëª©ì„ ì„¤ì •í•˜ê³  conda í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ git ì €ì¥ì†Œë¥¼ ë³µì œí•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤.

conda activate your-environment
python -m pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly-cu121 mlc-ai-nightly-cu121
conda env remove -n mlc-chat-venv
conda create -n mlc-chat-venv -c conda-forge \
 "cmake>=3.24" \
 rust \
 git \
 python=3.11
conda activate mlc-chat-venv
git clone --recursive https://github.com/mlc-ai/mlc-llm.git && cd mlc-llm/
mkdir -p build && cd build
python ../cmake/gen_cmake_config.py
cmake .. && cmake --build . --parallel $(nproc) && cd ..
set(USE_FLASHINFER ON)
conda activate your-own-env
cd mlc-llm/python
pip install -e .

MLC LLMìœ¼ë¡œ ëª¨ë¸ì„ ì‹¤í–‰í•˜ë ¤ë©´ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ MLC í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. Git LFSë¥¼ ì‚¬ìš©í•˜ì—¬ HF ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ê°€ì¤‘ì¹˜ë¥¼ ë³€í™˜í•˜ì„¸ìš”.

mlc_llm convert_weight ./dist/models/Phi-3-small-128k-instruct/ \
 --quantization q0f16 \
 --model-type "phi3" \
 -o ./dist/Phi-3-small-128k-instruct-q0f16-MLC

<div class="content-ad"></div>

ì´ì œ MLC í˜•ì‹ ëª¨ë¸ì„ MLC ì—”ì§„ì— ë¡œë“œí•´ ë³´ì„¸ìš”.

```js
from mlc_llm import MLCEngine
# ì—”ì§„ ìƒì„±
model = "HF://mlc-ai/Phi-3-mini-128k-instruct-q0f16-MLC"
engine = MLCEngine(model)

# ì´ì œ ì²˜ë¦¬ëŸ‰ì„ ê³„ì‚°í•´ ë´…ì‹œë‹¤
import time
from transformers import AutoTokenizer
start = time.time()
response = engine.chat.completions.create(
    messages=[{"role": "user", "content": "ë¨¸ì‹  ëŸ¬ë‹ì´ ë¬´ì—‡ì¸ê°€ìš”?"}],
    model=model,
    stream=False,
)
taken = time.time() - start
tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-128k-instruct")
print("tok/s", 82 // taken)
```

![ì´ë¯¸ì§€](/assets/img/2024-07-07-BestLLMInferenceEngineTensorRTvsvLLMvsLMDeployvsMLC-LLM_6.png)

# ê°œìš”

<div class="content-ad"></div>

íŠ¹íˆ HF ëª¨ë¸ê³¼ ì¼ë°˜ TensorRT ëŒ€ë¹„ TensorRT INT8 ëª¨ë¸ì´ ì¶”ë¡  ì†ë„ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°˜ë©´ ì¼ë°˜ TensorRT ëª¨ë¸ì€ ìš”ì•½ ì‘ì—…ì—ì„œ ê°€ì¥ ë†’ì€ ROUGE ì ìˆ˜ë¥¼ ê¸°ë¡í•˜ì—¬ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜í–ˆìŠµë‹ˆë‹¤. LMDeployëŠ” A100ì—ì„œ vLLM ëŒ€ë¹„ ìµœëŒ€ 1.8ë°° ë†’ì€ ìš”ì²­ ì²˜ë¦¬ëŸ‰ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ ì‹¤í—˜ì„ ìœ„í•œ ì»´í“¨íŒ…ì„ í›„ì›í•´ì¤€ QueryLoopAIì—ê²Œ íŠ¹ë³„íˆ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.

ë˜í•œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê±°ë‚˜ ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì €ì—ê²Œ ì—°ë½í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- LinkedIn ë° Twitterì—ì„œ ì—°ë½í•˜ê³  íŒ”ë¡œìš°í•˜ê¸°
- ğŸ“š Mediumì—ì„œ ì €ë¥¼ íŒ”ë¡œìš°í•˜ê¸°
- ğŸ“¢ ì£¼ê°„ AI ë‰´ìŠ¤ë ˆí„°ë¥¼ êµ¬ë…í•˜ê¸°
- ğŸ¤— Hugging Face ì‚¬ì´íŠ¸ ë°©ë¬¸í•˜ê¸°
