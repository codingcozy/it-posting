---
title: "기계 학습, 생성형 AI, 딥러닝을 사용한 시계열 데이터 예측 방법"
description: ""
coverImage: "/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_0.png"
date: 2024-07-06 10:55
ogImage:
  url: /assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_0.png
tag: Tech
originalTitle: "Predicting Time Series Data with Machine Learning, Generative AI, and Deep Learning"
link: "https://medium.com/@palashm0002/predicting-time-series-data-with-machine-learning-generative-ai-and-deep-learning-36bf99ad6f5e"
isUpdated: true
---

### Time Series Data Prediction

시계열 데이터 예측은 금융 및 의료부터 마케팅 및 물류에 이르기까지 다양한 산업에서 중요한 측면입니다. 과거 데이터를 기반으로 미래 값을 예측하는 능력은 의사 결정 프로세스와 운영 효율성의 중요한 향상을 이끌어낼 수 있습니다. 기계 학습, 생성적 인공지능 및 딥러닝의 발전으로 인해 시계열 예측 문제를 다루기 위한 보다 정교한 방법들이 현재 제공되고 있습니다. 이 블로그에서는 시계열 데이터 예측에 사용할 수 있는 다양한 접근 방식과 모델을 탐구합니다.

# 시계열 데이터의 이해

시계열 데이터는 특정 시간 간격에서 수집하거나 기록된 데이터 포인트의 일련이다. 주식 가격, 날씨 데이터, 판매 수치 및 센서 읽기가 그 예시로 들 수 있습니다. 시계열 예측의 목표는 과거 관측치를 사용하여 미래 값을 예측하는 것이며, 데이터 내에 내재된 복잡성과 패턴으로 인해 도전적일 수 있습니다.

<div class="content-ad"></div>

### 1. 머신 러닝 접근 방법

(https://yourdomain.com/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_1.png)

- ARIMA은 시계열 예측을 위한 고전적인 통계적 방법입니다. 자기 회귀(AR) 모델,
  차분(데이터를 정상적으로 만들기 위한), 이동 평균(MA) 모델을 결합합니다.

<div class="content-ad"></div>

아래는 예시 사용법입니다:

```python
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

# 시계열 데이터를 불러옵니다
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# ARIMA 모델 적합
model = ARIMA(time_series_data['Value'], order=(5, 1, 0))  # (p,d,q)
model_fit = model.fit()

# 예측 수행
predictions = model_fit.forecast(steps=10)
print(predictions)
```

![SARIMA](/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_3.png)

- SARIMA는 계절 패턴을 고려하여 ARIMA를 확장한 것입니다. 매월 매출 데이터와 같은 계절적 패턴이 있는 데이터에 유용합니다.

<div class="content-ad"></div>

예시 사용법:

```python
import pandas as pd
import numpy as np
from statsmodels.tsa.statespace.sarimax import SARIMAX

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# SARIMA 모델 적합
model = SARIMAX(time_series_data['Value'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))  # (p,d,q) (P,D,Q,s)
model_fit = model.fit(disp=False)

# 예측 수행
predictions = model_fit.forecast(steps=10)
print(predictions)
```

![Predicting Time Series Data with ML](/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_4.png)

- Facebook에서 개발된 Prophet은 시계열 데이터를 예측하기 위한 강력한 도구로, 누락된 데이터나 이상치를 처리하고 신뢰할 수 있는 불확실성 구간을 제공합니다.

<div class="content-ad"></div>

예시 사용법:

```python
from fbprophet import Prophet
import pandas as pd

# 시계열 데이터를 불러옵니다
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.rename(columns={'Date': 'ds', 'Value': 'y'}, inplace=True)

# Prophet 모델을 적합시킵니다
model = Prophet()
model.fit(time_series_data)

# 미래 데이터 프레임 및 예측 생성
future = model.make_future_dataframe(periods=10)
forecast = model.predict(future)
print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])
```

![Time Series Prediction](/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_5.png)

- XGBoost는 이전 시간 단계를 특성으로 취급하여 지도 학습 작업으로 문제를 변환하는 방식으로 시계열 예측에 사용할 수 있는 그래디언트 부스팅 프레임워크입니다.

<div class="content-ad"></div>

예시 사용법:

```python
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# 지도 학습을 위한 데이터 준비
def create_lag_features(data, lag=1):
    df = data.copy()
    for i in range(1, lag + 1):
        df[f'lag_{i}'] = df['Value'].shift(i)
    return df.dropna()

lag = 5
data_with_lags = create_lag_features(time_series_data, lag=lag)
X = data_with_lags.drop('Value', axis=1)
y = data_with_lags['Value']

# 데이터를 훈련 및 테스트 세트로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# XGBoost 모델 훈련
model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
```

Markdown 형식으로 이미지 첨부:
![Predicting Time Series Data with Machine Learning, Generative AI, and Deep Learning](/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_6.png)

<div class="content-ad"></div>

- GAN은 생성기(generator)와 판별기(discriminator)로 구성되어 있습니다. 시계열 예측을 위해 GAN을 사용하면 기저 데이터 분포를 학습하여 가능성 있는 미래 시퀀스를 생성할 수 있습니다.

예시 사용법:

```js
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, LeakyReLU, Reshape
from tensorflow.keras.optimizers import Adam

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# GAN을 위한 데이터 준비
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

X_train, y_train = create_dataset(scaled_data, time_step)
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

# GAN 구성 요소
def build_generator():
    model = Sequential()
    model.add(Dense(100, input_dim=time_step))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(time_step, activation='tanh'))
    model.add(Reshape((time_step, 1)))
    return model

def build_discriminator():
    model = Sequential()
    model.add(LSTM(50, input_shape=(time_step, 1)))
    model.add(Dense(1, activation='sigmoid'))
    return model

# 판별기 구성 및 컴파일
discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])

# 생성기 구성
generator = build_generator()

# 생성기는 노이즈를 입력으로 받아 데이터를 생성합니다
z = Input(shape=(time_step,))
generated_data = generator(z)

# 결합 모델에서는 생성기만 학습합니다
discriminator.trainable = False

# 판별기는 생성된 데이터를 입력으로 받아 유효성을 결정합니다
validity = discriminator(generated_data)

# 결합 모델 (생성기와 판별기를 쌓은 모델)
combined = Model(z, validity)
combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))

# GAN 학습
epochs = 10000
batch_size = 32
valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))

for epoch in range(epochs):
    # ---------------------
    #  판별기 학습
    # ---------------------

    # 랜덤한 실제 데이터 배치 선택
    idx = np.random.randint(0, X_train.shape[0], batch_size)
    real_data = X_train[idx]

    # 가짜 데이터 배치 생성
    noise = np.random.normal(0, 1, (batch_size, time_step))
    gen_data = generator.predict(noise)

    # 판별기 학습
    d_loss_real = discriminator.train_on_batch(real_data, valid)
    d_loss_fake = discriminator.train_on_batch(gen_data, fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # ---------------------
    #  생성기 학습
    # ---------------------

    noise = np.random.normal(0, 1, (batch_size, time_step))

    # 생성기 학습 (판별기가 샘플을 유효하다고 레이블할 수 있도록)
    g_loss = combined.train_on_batch(noise, valid)

    # 진행 상황 출력
    if epoch % 1000 == 0:
        print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]")

# 예측 생성
noise = np.random.normal(0, 1, (1, time_step))
generated_prediction = generator.predict(noise)
generated_prediction = scaler.inverse_transform(generated_prediction)
print(generated_prediction)
```

![Example Image](/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_7.png)

<div class="content-ad"></div>

- 딥마인드에서 개발한 WaveNet은 원래 오디오 생성을 위해 설계된 딥 생성 모델로, 시계열 예측을 위해 특히 오디오 및 음성 분야에서 적용되어 왔습니다.

사용 예시:

```python
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, Add, Activation, Multiply, Lambda, Dense, Flatten
from tensorflow.keras.optimizers import Adam

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# WaveNet을 위한 데이터 준비
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# WaveNet 모델 정의
def residual_block(x, dilation_rate):
    tanh_out = Conv1D(32, kernel_size=2, dilation_rate=dilation_rate, padding='causal', activation='tanh')(x)
    sigm_out = Conv1D(32, kernel_size=2, dilation_rate=dilation_rate, padding='causal', activation='sigmoid')(x)
    out = Multiply()([tanh_out, sigm_out])
    out = Conv1D(32, kernel_size=1, padding='same')(out)
    out = Add()([out, x])
    return out

input_layer = Input(shape=(time_step, 1))
out = Conv1D(32, kernel_size=2, padding='causal', activation='tanh')(input_layer)
skip_connections = []
for i in range(10):
    out = residual_block(out, 2**i)
    skip_connections.append(out)

out = Add()(skip_connections)
out = Activation('relu')(out)
out = Conv1D(1, kernel_size=1, activation='relu')(out)
out = Flatten()(out)
out = Dense(1)(out)

model = Model(input_layer, out)
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# 모델 훈련
model.fit(X, y, epochs=10, batch_size=16)

# 예측 생성
predictions = model.predict(X)
predictions = scaler.inverse_transform(predictions)
print(predictions)
```

#3. 딥러닝 접근법

<div class="content-ad"></div>

/assets/img/2024-07-06-PredictingTimeSeriesDatawithMachineLearningGenerativeAIandDeepLearning_8.png

LSTM 네트워크는 장기 의존성을 학습할 수 있는 순환 신경망(RNN)의 일종입니다. 시간 순서 예측을 위해 널리 사용되며 시간적 패턴을 포착할 수 있는 능력으로 유명합니다.

예시 사용법:

```js
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# LSTM을 위한 데이터 준비
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# LSTM 모델 구축
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, batch_size=1, epochs=1)

# 예측 만들기
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
print(test_predict)
```

<div class="content-ad"></div>

GRU는 LSTM의 변형으로, 간단하면서도 종종 시계열 작업에 대해 동등한 성능을 발휘합니다. GRU는 순서를 모델링하고 시간 종속성을 포착하는 데 사용됩니다.

예제 사용법 :

```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
from sklearn.preprocessing import MinMaxScaler

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# GRU 모델을 위한 데이터 준비
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# GRU 모델 구축
model = Sequential()
model.add(GRU(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(GRU(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, batch_size=1, epochs=1)

# 예측 생성
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
print(test_predict)
```

<div class="content-ad"></div>

미래를 예측하는 것이 어려운 과제일 수 있지만, 신경망과 딥러닝을 활용한 시계열 데이터 예측은 가능합니다. 최근에는 자연어 처리에서 성공을 거둔 트랜스포머(Transformer)가 시계열 예측을 위해 적응되었습니다. Temporal Fusion Transformer (TFT)와 같은 모델은 주의 메커니즘(attention mechanism)을 활용하여 시간적 데이터를 효과적으로 처리합니다.

아래는 예제 사용법입니다:

```python
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, MultiHeadAttention, LayerNormalization, Dropout

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
...
```

혹시 이 코드가 도움이 되셨나요? 더 궁금한 점이 있거나 도움이 필요하시다면 언제든지 물어보세요!

<div class="content-ad"></div>

하단은 Seq2Seq 모델을 이용하여 데이터 시퀀스를 예측하는 코드 예시입니다.

시퀀스 데이터 예측을 위해 Seq2Seq 모델이 사용됩니다. 초기에는 언어 번역을 위해 개발되었지만, 입력 시퀀스에서 출력 시퀀스로의 매핑을 학습함으로써 시계열 예측에 효과적입니다.

아래는 코드 사용 예시입니다:

```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# Seq2Seq에 맞게 데이터 준비
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# Seq2Seq 모델 정의
encoder_inputs = Input(shape=(time_step, 1))
encoder = LSTM(50, return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_inputs)

decoder_inputs = Input(shape=(time_step, 1))
decoder_lstm = LSTM(50, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])
decoder_dense = Dense(1)
decoder_outputs = decoder_dense(decoder_outputs)

model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='mean_squared_error')

# 모델 학습
model.fit([X, X], y, epochs=10, batch_size=16)

# 예측 생성
predictions = model.predict([X, X])
predictions = scaler.inverse_transform(predictions)
print(predictions)
```

<div class="content-ad"></div>

이미지 경로를 Markdown 형식으로 변경해주세요.

TCN은 시계열 데이터의 장기 의존성을 포착하기 위해 확장된 합성곱을 사용합니다. 순차 데이터 모델링을 위한 RNN에 대한 견고한 대안을 제공합니다.

예시 사용법:

```js
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dense, Flatten

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# TCN용 데이터 준비
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# TCN 모델 정의
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=2, dilation_rate=1, activation='relu', input_shape=(time_step, 1)))
model.add(Conv1D(filters=64, kernel_size=2, dilation_rate=2, activation='relu'))
model.add(Conv1D(filters=64, kernel_size=2, dilation_rate=4, activation='relu'))
model.add(Flatten())
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

# 모델 훈련
model.fit(X, y, epochs=10, batch_size=16)

# 예측 생성
predictions = model.predict(X)
predictions = scaler.inverse_transform(predictions)
print(predictions)
```

<div class="content-ad"></div>

아마존에서 개발된 DeepAR은 시계열 예측을 위해 설계된 자기회귀 순환 신경망입니다. 여러 시계열을 처리하며 복잡한 패턴을 잡을 수 있습니다.

예시 사용법:

```python
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Flatten

# 시계열 데이터 불러오기
time_series_data = pd.read_csv('time_series_data.csv')
time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])
time_series_data.set_index('Date', inplace=True)

# DeepAR와 유사한 모델용 데이터 준비
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]
        X.append(a)
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 10
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))

X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# DeepAR와 유사한 모델 정의
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

# 모델 훈련
model.fit(X, y, epochs=10, batch_size=16)

# 예측
predictions = model.predict(X)
predictions = scaler.inverse_transform(predictions)
print(predictions)
```

<div class="content-ad"></div>

시계열 데이터 예측은 복잡하지만 매력적인 분야로, 기계 학습, 생성적 AI, 그리고 심층 학습의 발전에서 크게 이점을 얻고 있습니다. ARIMA, Prophet, LSTM, 그리고 Transformers와 같은 모델을 활용하여 실무자들은 데이터에서 숨겨진 패턴을 찾아 정확한 예측을 할 수 있습니다. 기술이 계속 발전함에 따라 시계열 예측을 위한 도구와 방법도 보다 정교해지며, 다양한 영역에서 혁신과 개선을 위한 새로운 기회를 제공하게 될 것입니다.
