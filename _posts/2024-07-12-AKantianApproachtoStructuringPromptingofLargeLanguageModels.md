---
title: "칸트 철학으로 대형 언어 모델 프롬프트 구조화하는 방법"
description: ""
coverImage: "/assets/img/2024-07-12-AKantianApproachtoStructuringPromptingofLargeLanguageModels_0.png"
date: 2024-07-12 23:49
ogImage:
  url: /assets/img/2024-07-12-AKantianApproachtoStructuringPromptingofLargeLanguageModels_0.png
tag: Tech
originalTitle: "A Kantian Approach to Structuring Prompting of Large Language Models"
link: "https://medium.com/ai-in-plain-english/a-kantian-approach-to-structuring-prompting-of-large-language-models-fc35e138e532"
isUpdated: true
---

인공 지능 소프트웨어가 이 기사의 텍스트의 문법, 흐름, 가독성을 향상시키는 데 사용되었습니다.

대형 언어 모델(LLM)의 발전은 적절하게 프롬프트된 경우에 다양한 영역에서 놀라운 유창함과 능력을 보여주었습니다.

그러나 대부분의 프롬프트 공학 기술은 아직도 모델 구조를 안내하는 형식적인 인식론적 기초가 부족하며 직관에 더 의존합니다.

현명한 철학자 이머누엘 칸트의 인지 모델에서 영감을 받아, UPAR이라 불리는 LLM 프롬프팅 프레임워크가 소개되었습니다. 이는 대규모 신경망 내에서 타고난 인간의 추론 능력을 흉내 내기 위해 칸트의 철학적 원리를 통합합니다. (Geng et al. 2023)

<div class="content-ad"></div>

UPAR는 이해, 계획, 실행 및 반성 네 단계를 거쳐 추론을 구축합니다. 이 구조는 LLM 응답에 경험적 근거, 논리적 일관성 및 내적 정제를 심어줍니다.

지식 갭을 극복하고 이해하기 위해 UPAR는 지식 그래프를 활용한 검색 보조 생성 (RAG)을 통합할 수 있습니다. 참조 말뭉치에서 구성된 지식 그래프는 엔티티를 노드로, 관계를 연결로 나타냅니다. 관련 노드를 탐색하면 관련 데이터가 회상되어 낯선 개념을 해결할 수 있습니다.

계획 및 실행 단계에서는 LLM 컴파일러 프레임워크를 활용하여 지식 서브그래프 전반에 걸쳐 효과적이고 병렬적인 엔티티 검색을 조율할 수 있습니다. 계획, 가져오기 및 실행 간에 컴파일러 분리가 동시 쿼리 체인을 통해 산란을 방지합니다.

반성 단계에서는 He CritiquingLLM 모델 [Wu et al. 2023]이 답변 품질을 평가하기 위해 설명적 비평을 자동으로 생성할 수 있습니다.

<div class="content-ad"></div>

UPAR 운율의 추론 위상학은 복잡한 질문, 증거 집계 및 세밀한 결론 도출 사이의 상호 작용을 나타내기 위해 체인, 트리 또는 방향성 비순환 그래프와 같은 명시적 그래프 구조를 활용할 수 있습니다.

LLM 추론 위상에 대한 최근 연구는 그래프 기반 접근법이 복잡한 추론을 다루는 데 간단한 순차적 체인이나 가지치기 트리를 능가한다는 것을 보여줍니다.

RAG는 지식 공백을 다루고, LLM 컴파일러는 증거 축적을 조정하며, 추론 위상은 다면적 추론을 구조화함으로써 칸트적 영감을 받은 UPAR 프레임워크가 직관적 인식에 부합하여 형성될 수 있도록 함께 작동합니다.

![이미지](/assets/img/2024-07-12-AKantianApproachtoStructuringPromptingofLargeLanguageModels_0.png)

<div class="content-ad"></div>

# 비구조화된 추론의 한계

인상적인 발전에도 불구하고, 순수한 통계적 패턴으로 동작하는 대형 언어 모델은 복잡한 논리적 추론에 여전히 어려움을 겪고 있습니다. 질의를 받았을 때 단어 순서에 대한 원시적 매력은 근거가 없어도 타당한 내러티브를 유창하게 생성할 수 있게 합니다.

예를 들어, 대형 언어 모델은 가설과 결론을 연결하는 다단계 원인 설명을 합성할 수 있습니다 — 그럴싸한 추론의 사슬을 형성하는 것처럼 보입니다. 그러나 외부 조정이 부족하면 이러한 추론은 상상력 넘치지만 근거가 없을 수 있습니다. 구조화된 추론 구조가 없으면 심지어 상세한 언어 모델에서 파생된 결론도 현실과 불일치할 위험이 있습니다.

나는 대규모 신경망이 인간의 마음과 마찬가지로 형식적 추론 구조를 내재적으로 편입하여 신뢰할 수 있는, 검토 가능한 추론을 체계적으로 구축해야 한다고 주장합니다.

<div class="content-ad"></div>

탄생적 철학자 이만귤 칸트의 인식 모델은 우리가 세계를 이해하기 위해 매일 무의식적으로 활용하는 특정 추론 계층을 규명합니다. 이들은 다음과 같습니다:

- 감성 — 지각을 조립하는 것
- 이해 — 지각을 조직화하는 것
- 추론 — 더 높은 원리를 추상화하는 것
- 판단 — 경험을 바탕으로 한 것

칸트는 인간의 지식과 경험이 이러한 형식적 추론 계층 간 상호작용에서 발생한다고 주장했습니다. 토큰 연상의 연속으로만 구동되는 LLMs는 이러한 선천적 구조를 띄지 않습니다.

칸트주의에서 영감을 받은 UPAR과 같은 건축적으로 안내된 프레임워크를 통합함으로써, 반복적인 인간의 추론을 반영하는 본질적인 골조를 새기는 것이 중요합니다.

<div class="content-ad"></div>

이해 단계는 먼저 관찰에서 비롯된 구체적인 상황 모델을 구축합니다.

계획은 원칙에 기반한 궤적을 개요화합니다.

행동은 안내된 생성을 실행합니다.

반성은 제공된 맥락과 일치 여부를 확인합니다.

<div class="content-ad"></div>

이 문구는 공식 추론 층의 발현이 LLMs에게 세밀하게 구성 가능한 추론 체인을 조립할 명시적 뼈대를 제공하여, 비구조적인 통계 합회를 넘어 신뢰성을 향상시킵니다.

이렇게 철저한 구조적 통합은 LLMs를 유도되지 않은 상상력 있는 추론에서 구조화된, 근거 있는 추론으로 발전시킴으로써 새로운 인식력에 대한 투명성과 신뢰를 향상시키는 데 도움이 됩니다.

# UPAR - 우리의 이해를 모방하는

UPAR (이해, 계획, 실행, 반성) 패러다임은 철학적 추론 층을 대형 언어 모델 내에 새겨 인간의 본능적 인식을 모방하고자 합니다.

<div class="content-ad"></div>

UPAR 구조는 네 가지 구분된 단계를 통해 추론을 진행합니다:

이해를 통해 먼저 입력 쿼리나 상황 주변의 개체, 관계 및 제약 조건을 분석하여 구조화된 맥락 모델을 구성합니다. 이 상황적 소화는 원시 지각에서 중요한 신호를 추출합니다.

계획은 다음으로 이해를 정제한 후, 문제 해결로 향하는 논리적인 원칙에 따른 경로를 전략적으로 계획합니다. 꼼꼼한 궤적 조정은 일관성을 강화합니다.

행동은 이후에 이러한 계획된 대응 생성 프로세스를 계획된 이해와 일치하도록 실행하여 구조화되지 않은 서술이 아닌 근거 있는, 지지되는 결론을 실현합니다.

<div class="content-ad"></div>

마침내, Reflect는 총체적인 과정을 검토하고 판단하며 도출된 결론과 지지되는 추론을 정제합니다. 이를 통해 반복적인 개선을 위한 조정이 가능해집니다. 이 재귀적인 분석은 내성의 상징이 됩니다.

이 네 단계가 함께 확립하는 것은 LLMs 내부의 형식적 추론 아키텍처입니다. 이것은 검증 가능한 타당성을 흉내내는 지식을 체계적으로 구성하는 과정을 구현하는 것입니다.

난해한 통계적 연관성이 흩뿌려진 서술을 생성하는 대신에, UPAR의 구조는 모델 추론을 구조화된 내제적 궤적으로 결정적 결론을 향하는 흐름으로 수렴시키는 것입니다. 응답은 명시적인 단계를 따라 완전히 추적 가능하며, 맥락 제약 조건을 이해하고 해결책 구상을 계획하고 생성 프로세스를 실행하며 결과물을 비평하는 과정이 반영됩니다.

UPAR는 칸트의 인식론으로부터 아키텍처적 계층을 새겨들어, LLM 추론 내에서 경험적 타당성, 논리적 일관성 및 내성적으로 정제를 강화합니다. 체계적인 궤적은 비단지 단지 마법처럼 생성된 서술보다 직관적인 인간적 추론 연쇄와 보다 밀접한 닮음을 지니고 있습니다.

<div class="content-ad"></div>

의도적 UPAR 통합은 LLMs을 구조적으로 안내된 추론을 통해 미구조적 추론의 진전을 이끕니다 - 신뢰와 떠오르는 지능에 대한 통찰력을 향상시킵니다.

# 외부 지식으로 LLMs 확장

대형 언어 모델은 방대한 말뭉치에서 추출된 풍부한 통계적 지식을 포괄하지만, 그들의 본질적인 매개 변수적 지식은 외부 기록된 지식의 폭에 비해 본질적으로 제한적입니다.

학습 시스템으로서, 그들의 이해 범위는 새로운 외부 지혜를 도입함으로써 확장될 수 있습니다 - 마치 인간의 이해가 지속적인 정보 소비를 통해 성장하는 것처럼요.

<div class="content-ad"></div>

지식 그래프를 통한 검색 보강 생성은 외부 개념을 맥락적으로 소화하여 생소한 쿼리를 해결하는 자동화된 방법론으로 작용합니다. 참고 말뭉치에서 구축된 지식 그래프에는 노드로 표현된 개체와 관련 데이터를 인코딩하는 연결적 엣지로 표현된 관계가 포함되어 있습니다.

연결된 노드와 관계를 탐색하여 관련 컨텍스트 단편을 대화 전체에 원활하게 추가함으로써, 내재적 매개변수를 초월하는 접근 가능한 통찰력의 범위를 계속해서 확장할 수 있습니다.

그러나 최적화되지 않은 지식 흡수는 추론 프로세스에 혼란을 줄 수 있습니다. 인간은 외부 지식을 통합할 때 의식적으로 관심을 집중하며, 의도적으로 회수, 연결 및 응집을 수행합니다.

이를 모방하기 위해 LLM 컴파일러 프레임워크를 통합하여, 지식 서브그래프로부터 효율적으로 병렬 엔티티를 검색하고, 분산증거를 가져와 최종 컨텍스트 퓨전을 목표 추론에 조화롭게 조직함으로써, 쿼리 체인 간의 동시적 방해를 방지합니다.

<div class="content-ad"></div>

프로그래머의 자동화된 스케줄러는 컴퓨터 부하, 지연 시간 목표 및 관련성에 기초하여 전문 그래프 모듈의 최적 쿼링을 할당합니다 — 검색 대역폭을 집중합니다. 동적 균형 조절은 그래프가 확장됨에 따라 흡수 효율을 지속적으로 극대화합니다.

병렬 계획을 통해 모델 집중력을 집중시키는 동시에 효율적인 하위 시스템 검색은 접근 가능한 맥락적 연관성을 확장함으로써 흡수 대역폭을 합리적으로 조정합니다. 지속적인 인간 정보 쿼리는 새로운 엔티티와 관계를 형성합니다 — 유동적 지능을 자율적으로 결정합니다.

지식 증강의 포괄적이면서도 통제된 융합과 설계된 추론 단계는 보편적으로 접근 가능한 이해로 나아가는 추세를 견인합니다 — 신흥 지능과 확립된 지능 사이의 맥락적 격차를 좁히려고 노력합니다.

# UPAR에 평가를 통합하기

<div class="content-ad"></div>

현재 UPAR의 반성 단계는 끝에서 끝으로 이어지는 추론 과정의 자가평가를 포함하고 있지만, 비판 능력을 더 강화함으로써 투명성을 향상시키고 순환 개선을 가속화시킬 수 있습니다.

특히, 최근 제안된 CritiquingLLM 모델은 생성된 텍스트의 품질을 평가하는 설명적 비평을 자동으로 생성하는 것을 가능하게 합니다. 지시에 따라 작업을 수행하는 과제로 공식화되며, UPAR의 상황 이해, 계획 전략, 취해진 행동 및 자기반성 단계를 비판하는 데 맞춤화될 수 있습니다.

나는 모듈식 CritiquingLLM 변형을 UPAR 단계 전반에 통합하는 것을 제안합니다:

이해 비판: 구축된 상황 모델의 완성도, 관련성 및 사실적 정확성을 평가하여 지식 결여나 관련 없는 연관성을 진단하여 추론의 순수성을 향상시키기 위해 개선이 필요한 부분을 파악합니다.

<div class="content-ad"></div>

계획 검토: 타로는 계획의 전략적 최적성, 대비책 커버리지 및 논리적 일관성을 평가합니다. 잠재적 약점을 보완하기 위해 조정 사항을 권고합니다.

행동 검토: 타로는 실증적 근거, 맥락적 조정 및 구체적 대응 내에서 논리적 추론을 평가합니다. 지원되지 않은 부분을 강조하여 다시 떠올리기가 필요합니다.

반복적 검토: 반복적인 UPAR 주기를 통해 CritiquingLLM 변형의 계속적인 조정은 복합적인 평가 능력을 확고히하며, 뚜렷하고 책임감 있는 투명한 지능을 창출합니다.

또한 CritiquingLLM의 설명적 결과는 인간-인공지능 협업을 돕습니다. 체계적인 추론을 일치시키기 위해 UPAR 단계별로 재평가가 필요한 특정 요소를 명확히 설명해 줍니다.

<div class="content-ad"></div>

단순한 숫자 평가보다 깊이 있는 평가는 이해, 계획 및 행동 향상을 촉진하여, 체계적 내성사상을 통해 점차적으로 자가비판적 지능의 발현을 촉발합니다.

UPAR의 추론 아키텍처와 CritiquingLLM의 평가 지원 구조의 융합은 투명한 추론을 향한 상호 보완적 능력을 구성하며, 비판 중심, 경험적으로 기반된 책임이 있는 지능의 현현을 이끌어 냅니다.

# 결론

본 글은 칸트의 인식론에 영감을 받은 선의적인 아키텍처 통합을 통해 LLM 신뢰성을 향상시키는 잠재적인 방법을 논의했습니다. 구체적으로, UPAR 프레임워크는 이해, 계획, 행동 및 반성으로 추론 과정을 구조화하며, 생래적인 인간 사고를 흉내냅니다. 제어된 워크플로우에서의 맥락적 지식 소화 강화는透明성을 희생하지 않으면서 정확도를 최적화합니다. 자동 평가는 지속적인 조정을 위한 반복적 피드백을 제공합니다.

<div class="content-ad"></div>

UPAR 초기 평가는 복잡한 과학적 추론 작업에서 원시 프롬프팅 방법에 비해 상당한 향상을 보여줍니다. 이 구조적 방법론은 대규모이면서도 해석 가능한 모델을 공학적으로 향상시키는 방향을 보여주며 경험적으로 기반을 다지고 검토 가능성을 향상시킵니다. UPAR 실행 확장 및 동적 지식 그래프, 추론 위상 및 비평 기술을 향상시키는 계속되는 노력이 앞날을 열어갑니다.

철저한 철학적 연구를 통해 인간 지혜와 알고리즘의 힘을 결합하는 건설적 철학을 통해 보다 시스템적으로 투명한 결과를 만들어내며 이는 순전히 데이터 기반 시스템에서 도전적인 부분입니다. 고의로 계획된 구조적 노력이 비로소 신흥 지능을 신뢰성과 책임성으로 이끄는 데 중요하며 이 기술에서 사회적 신뢰를 형성하는 데 상당한 영향을 미칩니다. 인간의 지혜와 알고리즘의 힘을 결합한 건설적인 철학적 연구를 통해 보다 보편적인 번영을 이루길 바랍니다.

# 간단하게 말하면 🚀

In Plain English 커뮤니티의 일부가 되어 주셔서 감사합니다! 계속해서 부탁드릴 사항:

<div class="content-ad"></div>

- 반드시 작가를 박수로 격려해 주시고 구독해 주세요 🌟👏🌟
- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter
- 다른 플랫폼에서도 만나보세요: Stackademic | CoFeed | Venture
- 다양한 컨텐츠는 PlainEnglish.io 에서 확인하세요 ✨
