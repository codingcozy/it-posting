---
title: "ë¡œì»¬ ê³ ê¸‰ RAG ì‹œìŠ¤í…œ êµ¬ì¶•, í‰ê°€, ì¶”ì  ë°©ë²•  Mistral 7b  LlamaIndex  W,B ì‚¬ìš©"
description: ""
coverImage: "/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_0.png"
date: 2024-07-13 03:34
ogImage:
  url: /assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_0.png
tag: Tech
originalTitle: "Building, Evaluating and Tracking a Local Advanced RAG System | Mistral 7b + LlamaIndex + W,B"
link: "https://medium.com/towards-data-science/building-evaluating-and-tracking-a-local-advanced-rag-system-mistral-7b-llamaindex-w-b-5c9c69059f92"
isUpdated: true
---

![Image](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_0.png)

Retrieval Augmented Generation (RAG)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ê³¼ ì§€ì‹ì— ëŒ€í•œ ì„ íƒì  ì•¡ì„¸ìŠ¤ë¥¼ ê²°í•©í•œ ê°•ë ¥í•œ NLP ê¸°ìˆ ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¬¸ì„œì—ì„œ ì£¼ìš”í•œ ë¬¸ë§¥ ì¡°ê°ë“¤ì„ ì œê³µí•¨ìœ¼ë¡œì¨ LLM í™˜ê°ì„ ì¤„ì´ëŠ” RAGë¥¼ í†µí•´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ê¸€ì˜ ì•„ì´ë””ì–´ëŠ” ë¡œì»¬ë¡œ ì‹¤í–‰ë˜ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ìì‹ ë§Œì˜ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì£¼ê³ , ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€, ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹¤í—˜ì„ ì¶”ì í•˜ê³  W&Bì—ì„œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

# ì†Œê°œ

ìš°ë¦¬ëŠ” ë‹¤ìŒì˜ ì£¼ìš” ì¸¡ë©´ì„ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤:

<div class="content-ad"></div>

- Mistral-7bì™€ LlamaIndexë¥¼ í™œìš©í•´ ë¡œì»¬ RAG ì‹œìŠ¤í…œì˜ ê¸°ë³¸ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤.
- ì¶©ì‹¤ì„±ê³¼ ê´€ë ¨ì„± ì¸¡ë©´ì—ì„œ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- Weights & Biases (W&B)ë¥¼ í™œìš©í•´ ì‹¤í—˜ì„ ëê¹Œì§€ ì¶”ì  ì¤‘ì…ë‹ˆë‹¤.
- ê³„ì¸µ ë…¸ë“œì™€ ì¬ë­í‚¹ê³¼ ê°™ì€ ê³ ê¸‰ RAG ê¸°ìˆ ì„ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

GitHubì—ì„œ ìì„¸í•œ ì£¼ì„ê³¼ ì½”ë“œë¥¼ í¬í•¨í•œ ì™„ë²½í•œ ë…¸íŠ¸ë¶ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ğŸ  ë¡œì»¬ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì¤‘

![ì´ë¯¸ì§€](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_1.png)

<div class="content-ad"></div>

ë¨¼ì € LlamaIndex ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”. ì €í¬ëŠ” í™˜ê²½ ì„¤ì •í•˜ê³  ì‹¤í—˜ì— ì‚¬ìš©í•  ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì‘ì—…ë¶€í„° ì‹œì‘í•  ê²ƒì…ë‹ˆë‹¤. LlamaIndexëŠ” ìœ ì—°í•œ ë°ì´í„° í†µí•©ì„ ê°€ëŠ¥ì¼€ í•˜ëŠ” ë‹¤ì–‘í•œ ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ë¡œë”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

```js
# LlamaIndexì—ì„œ PDFReaderë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
from llama_index import VectorStoreIndex, download_loader

# ì»¤ìŠ¤í…€ ë¡œë” ì´ˆê¸°í™”
PDFReader = download_loader("PDFReader")
loader = PDFReader()

# PDF íŒŒì¼ ì½ê¸°
documents = loader.load_data(file=Path("./Mixtral.pdf"))
```

ì´ì œ LLM ì„¤ì •ì„ í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ì €ëŠ” M1 ë§¥ë¶ì„ ì‚¬ìš© ì¤‘ì´ë¼ llama.cppë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. ì´ëŠ” Metalê³¼ Cuda ëª¨ë‘ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë™í•˜ë©° ë©”ëª¨ë¦¬ ì œí•œì´ ìˆëŠ” í™˜ê²½ì—ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì„¤ì¹˜í•˜ê¸° ìœ„í•´ì„œëŠ” ê³µì‹ ì €ì¥ì†Œë¥¼ ì°¸ê³ í•˜ê±°ë‚˜ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”:

```js
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make
```

<div class="content-ad"></div>

ì—¬ê¸°ì„œëŠ” Mistral-7b ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì‹¤í—˜ì„ ë” ë¹ ë¥´ê³  ëª¨ë“  ì‚¬ëŒë“¤ì—ê²Œ ì´ìš© ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ ì´ ëª¨ë¸ì˜ ì–‘ìí™”ëœ ë²„ì „ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. í’ˆì§ˆ ì†ì‹¤ì´ ê·¹íˆ ë‚®ì€ 2ë¹„íŠ¸ ì–‘ìí™”ê¹Œì§€ ì§€ì›í•˜ëŠ” QuIP ì–‘ìí™”ëœ ëª¨ë¸ì„ í™•ì¸í•˜ëŠ” ê²ƒì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤.

from llama_index import (
SimpleDirectoryReader,
VectorStoreIndex,
ServiceContext,
)
from llama_index.llms import LlamaCPP
from llama_index.llms.llama_utils import (
messages_to_prompt,
completion_to_prompt,
)

llm = LlamaCPP( # ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  GGML ëª¨ë¸ì˜ URLì„ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
model_url="https://huggingface.co/ikawrakow/various-2bit-sota-gguf/blob/main/mistral-7b-2.20bpw.gguf", # ì„ íƒì ìœ¼ë¡œ, model_url ëŒ€ì‹  ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
model_path=None,
temperature=0.1,
max_new_tokens=512, # llama2ì˜ ì½˜í…ìŠ¤íŠ¸ ì°½ì€ 4096 í† í°ì´ì§€ë§Œ, ì•½ê°„ì˜ ì—¬ìœ  ê³µê°„ì„ ë‚¨ê¸°ê¸° ìœ„í•´ ë‚®ê²Œ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
context_window=3900,
generate_kwargs={}, # ìµœì†Œ 1ë¡œ ì„¤ì •í•˜ì—¬ GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
model_kwargs={"n_gpu_layers": 1}, # ì…ë ¥ì„ Llama2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
messages_to_prompt=messages_to_prompt,
completion_to_prompt=completion_to_prompt,
verbose=False,
)

ë‹¤ìŒìœ¼ë¡œ, ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ê³  ë²¡í„° DBë¥¼ ìƒì„±í•˜ë©°, ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ì„¤ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ë‹¨ê³„ #1 | ServiceContext

<div class="content-ad"></div>

ServiceContextëŠ” LlamaIndexì—ì„œ ëª¨ë¸ê³¼ ì½œë°±ì˜ ë¼ì´í”„ì‚¬ì´í´ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. í•„ìˆ˜ ì„¤ì •ìœ¼ë¡œ ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤. LlamaIndexëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ GPUë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•  ê²ƒì…ë‹ˆë‹¤. M-í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ë§¥ë¶ì´ë¼ë©´ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”.

```python
# Setting up the ServiceContext with the language model and embedding model
embed_model = "local:BAAI/bge-small-en-v1.5"
service_context = ServiceContext.from_defaults(
    llm=llm,
    embed_model=embed_model,
    callback_manager=callback_manager
)
```

## Step #2 | VectorStore

VectorStoreëŠ” LLAMAIndexì—ì„œ ë¬¸ì„œ ë²¡í„°ì˜ ìª¼ê°œê¸°, ì„ë² ë”©, ì €ì¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ VectorStoreë¥¼ ìƒì„±í•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

# ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ìœ„í•œ VectorStoreIndex ìƒì„±

index = VectorStoreIndex.from_documents(documents, service_context=service_context)

# ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ì—”ì§„ìœ¼ë¡œ ì¸ë±ìŠ¤ ë³€í™˜

query_engine = index.as_query_engine()

## í…ŒìŠ¤íŠ¸í•´ ë´…ì‹œë‹¤

def query_and_display(question):
response = query_engine.query(question)
display_response(response)

query_and_display("ëˆ„ê°€ ë¯¹ìŠ¤íŠ¸ëŸ´ ë…¼ë¬¸ì„ ì¼ë‚˜ìš”?")
query_and_display("Sparse MoEê°€ ë¬´ì—‡ì¸ê°€ìš”?")
query_and_display("Sparse MoEì— ëª‡ ëª…ì˜ ì „ë¬¸ê°€ê°€ ì‚¬ìš©ë˜ë‚˜ìš”?")

ìµœì¢… ì‘ë‹µ: ë¯¹ìŠ¤íŠ¸ëŸ´ ë…¼ë¬¸ì€ ì•Œë²„íŠ¸ Q. ì¥, ì•Œë ‰ì‚°ë“œë¥´ ì‚¬ë¸”ë¼ìš¸ ë“± ì—°êµ¬ì íŒ€ì´ ì¼ìŠµë‹ˆë‹¤.

<div class="content-ad"></div>

ìµœì¢… ì‘ë‹µ: Sparse Mixture of Experts (MoE)ì€ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê° í† í°ì´ ì—¬ëŸ¬ ì„œë¸Œ ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì „ë¬¸ê°€ë“¤ì— ì˜í•´ ì²˜ë¦¬ë˜ëŠ” ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ ìœ í˜•ì„ ê°€ë¦¬í‚µë‹ˆë‹¤.

ìµœì¢… ì‘ë‹µ: Sparse MoEì—ì„œ ì‚¬ìš©ë˜ëŠ” ì „ë¬¸ê°€ì˜ íŠ¹ì • ìˆ˜ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸš© ğŸš© ğŸš© (ì‹¤ì œë¡œëŠ”, 8ì´ ì •ë‹µì…ë‹ˆë‹¤)

# ğŸ” í‰ê°€

![ì´ë¯¸ì§€](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_2.png)

<div class="content-ad"></div>

ì•Œê² ì–´ìš”. ì¢‹ì•„ìš”. ê·¸ëŸ¼, ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ê³  ìˆë‚˜ìš”? ì´ì œ ìš°ë¦¬ëŠ” RAG ì„¤ì •ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ë‹¨ê³„ë¡œ ì´ë™í•˜ê²Œ ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë˜ ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤ ğŸ™‚

ìš°ë¦¬ì˜ RAG ì‹œìŠ¤í…œì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì£¼ëª©í•´ì•¼ í•  í•µì‹¬ ë©”íŠ¸ë¦­ìŠ¤ëŠ” ë¯¿ìŒì„±ê³¼ ê´€ë ¨ì„±ì…ë‹ˆë‹¤. ë¯¿ìŒì„±ì€ ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ë§¥ì— ì–¼ë§ˆë‚˜ ê·¼ì ‘í•˜ê²Œ ë”°ë¼ê°€ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ”ë°, ì´ëŠ” ë‹µë³€ì´ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ê³  ê°€ê³µë˜ì§€ ì•Šì•˜ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤. í•œí¸, ê´€ë ¨ì„±ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ì— ì‹¤ì œë¡œ ëŒ€ë‹µí•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ë©°, ë¬¸ë§¥ì˜ ë§ ê·¸ëŒ€ë¡œê°€ ì•„ë‹ˆë”ë¼ë„ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

## ë‹¨ê³„ #1 | ì§ˆë¬¸ ìƒì„±

í‰ê°€í•˜ê¸° ìœ„í•´ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ì†”ì§íˆ ë§í•˜ìë©´, ìš°ë¦¬ëŠ” ì§ì ‘ ì´ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì´ ê·€ì°®ì•„ìš”. ê·¸ëŸ¬ë‹ˆ ì´ë¯¸ êµ¬ë¹„ëœ Llamaindex + GPT-3.5 Api ë‚´ì˜ QuestionsGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë˜ëŠ” ë¡œì»¬ LLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. llm ê°ì²´ë¥¼ ê°„ë‹¨íˆ ë°”ê¿”ì£¼ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.

<div class="content-ad"></div>

# ë¬¸ì„œ ì„¤ì • ë° í‰ê°€ìš© ì§ˆë¬¸ ìƒì„±í•˜ê¸°

ì„ì˜ì˜ ë¬¸ì„œ = ë¬¸ì„œì˜ ë³µì œ(deep copy)

# ë¬¸ì„œë¥¼ ì„ê³  5ê°œì˜ ì„ì˜ì˜ ë¬¸ì„œ ì„ íƒí•˜ê¸°. í‰ê°€ë¥¼ ë¹ ë¥´ê²Œ ì§„í–‰í•˜ê¸° ìœ„í•¨

random.shuffle(ì„ì˜ì˜ ë¬¸ì„œ)
ì„ì˜ì˜ ë¬¸ì„œ = ì„ì˜ì˜ ë¬¸ì„œ[:5]

# GPTë¥¼ locall llmìœ¼ë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆìŒ

llm_eval = OpenAI(ì˜¨ë„=0, ëª¨ë¸="gpt-3.5-turbo")

# GPT API ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±. ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ

ì„œë¹„ìŠ¤*ì»¨í…ìŠ¤íŠ¸ = ê¸°ë³¸ê°’ì—ì„œ ê°€ì ¸ì˜¨ ì„œë¹„ìŠ¤*ì»¨í…ìŠ¤íŠ¸(
llm=llm_eval,
embed_model=embed_model,
)

# í‰ê°€ë¥¼ ìœ„í•´ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ ìƒì„±

ë°ì´í„°*ìƒì„±ì = ë¬¸ì„œì—ì„œ*ë°ì´í„°ì…‹*ìƒì„±ê¸°(
ì„ì˜ì˜ ë¬¸ì„œ, ì„œë¹„ìŠ¤*ì»¨í…ìŠ¤íŠ¸=ì„œë¹„ìŠ¤*ì»¨í…ìŠ¤íŠ¸, ê°œë³„*ì²­í¬ë‹¹*ì§ˆë¬¸*ìˆ˜=2
)

# Async ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ nest_asyncio ì ìš©

nest*asyncio.apply()
í‰ê°€*ì§ˆë¬¸ = ë°ì´í„°\_ìƒì„±ì.generate_questions_from_nodes()

ê·¸ë¦¬ê³  ë§ˆì¹¨!

í‰ê°€\_ì§ˆë¬¸[:3]

['Agieval ë²¤ì¹˜ë§ˆí¬ì˜ ëª©ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?',
'ì „ë¬¸ê°€ ì„ íƒ ë¼ìš°íŒ…ì„ ì‚¬ìš©í•œ Mixture-of-experts ì ‘ê·¼ë²•ì´ ì‹ ê²½ ì •ë³´ ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¶„ì•¼ì— ì–´ë–»ê²Œ ê¸°ì—¬í•˜ë‚˜ìš”?',
'ë¼ìš°íŒ… ë¶„ì„ì—ì„œ ì„ íƒëœ ì „ë¬¸ê°€ì˜ ë¶„í¬ëŠ” ë‹¤ë¥¸ ë„ë©”ì¸ ê°„ì— ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€?']

## ë‹¨ê³„ #2 | ë©”íŠ¸ë¦­ìŠ¤ ê°€ì ¸ì˜¤ê¸°

<div class="content-ad"></div>

BatchEvalRunnerì„ ì‚¬ìš©í•˜ì—¬ FaithfulnessEvaluatorì™€ RelevancyEvaluatorë¡œ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. BatchEvalRunnerì€ ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëŒ€ê·œëª¨ ì§ˆë¬¸ ì„¸íŠ¸ì— ëŒ€í•´ RAG ì‹œìŠ¤í…œì„ í‰ê°€í•  ë•Œ íŠ¹íˆ ìœ ìš©í•œ ëŒ€ëŸ‰ ì²˜ë¦¬ ê¸°ëŠ¥ì…ë‹ˆë‹¤.

```python
# BatchEvalRunnerë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
from llama_index.evaluation import (
    BatchEvalRunner,
    FaithfulnessEvaluator,
    RelevancyEvaluator,
)

# eval_llmì„ ì‚¬ìš©í•˜ì—¬ evaluatorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
faithfulness_evaluator = FaithfulnessEvaluator(service_context=service_context_eval)
relevancy_evaluator = RelevancyEvaluator(service_context=service_context_eval)

# ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ Batch runner
runner = BatchEvalRunner(
    {"faithfulness": faithfulness_evaluator, "relevancy": relevancy_evaluator},
    workers=8,
)

# ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
eval_results = await runner.aevaluate_queries(
    index.as_query_engine(), queries=eval_questions
)
```

ì´ì œ ê´€ë ¨ì„±ê³¼ ì¶©ì‹¤ë„ì— ëŒ€í•œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.

```python
# ê²°ê³¼ë¡œë¶€í„° ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°
faithfulness_df = pd.DataFrame.from_records([eval_result.dict() for eval_result in eval_results["faithfulness"]])
relevancy_df = pd.DataFrame.from_records([eval_result.dict() for eval_result in eval_results["relevancy"]])

# ì ìˆ˜ í•„ìš”í•©ë‹ˆë‹¤!
faithfulness_df["score"].mean(), relevancy_df["score"].mean()

>> (0.9166666666666666, 0.9166666666666666)
```

<div class="content-ad"></div>

# ğŸ“‹ ì‹¤í—˜ ì¶”ì  ì¤‘ | W&B

![Experiment Image](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_3.png)

ì´ìƒì ìœ¼ë¡œëŠ” ê²°ê³¼ë¥¼ ë…¸íŠ¸ë¶ ì¶œë ¥ë¿ë§Œ ì•„ë‹ˆë¼ ì €ì¥í•˜ê¸¸ ì›í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ Weights&Biasesê°€ ìš°ë¦¬ë¥¼ ë„ì™€ì¤ë‹ˆë‹¤. ë” ë‚˜ì€ ì¶”ì ì„ ìœ„í•´, ìš°ë¦¬ëŠ” í‰ê°€ ì ìˆ˜ì™€ ê°™ì€ í•µì‹¬ ê²°ê³¼ë¥¼ w&bì— ë¡œê·¸í•©ë‹ˆë‹¤. ë˜í•œ ìƒì„±ëœ í‰ê°€ ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ íŒŒì¼ì„ ì•„í‹°íŒ©íŠ¸ë¡œ ì˜êµ¬ì ìœ¼ë¡œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
!pip install wandb
```

<div class="content-ad"></div>

í‰ê°€ ê²°ê³¼ë¥¼ ì¶”ì í•˜ê³  ì ì ˆíˆ ì €ì¥í•´ë´ìš”.

```js
import wandb

# í˜„ì¬ ì„¸ì…˜ì„ ìœ„í•œ ì‹¤í–‰ ìƒì„±
wandb.init(project=PROJECT, name="baseline-evaluation")

# ê²°ê³¼ë¥¼ ë‹´ì€ í…Œì´ë¸” ìƒì„±
faithfulness_table = wandb.Table(dataframe=faithfulness_df)
relevancy_table = wandb.Table(dataframe=relevancy_df)

# ê¸°ë¡í•˜ê¸°
wandb.log({"faithfulness": faithfulness_table, "relevancy": relevancy_table})
```

ì´ì œ ëŒ€ì‹œë³´ë“œì—ì„œ ë©‹ì§€ê²Œ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”:

![Dashboard Image](https://yourwebsite.com/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_4.png)

<div class="content-ad"></div>

ê·€í•˜ê°€ ì†Œì¤‘í•œ ì§€í‘œë¥¼ ì¶”ì í•˜ëŠ” ë° ìœ ìš©í•œ ê²ƒì€ ì¢‹ì€ ì ìˆ˜ì˜ í‰ê· ê³¼ ê°™ì€ ì§€í‘œë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ëŒ€ì‹œë³´ë“œì— ì‚¬ìš©ì ì •ì˜ ì°¨íŠ¸ë¥¼ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ì´ì „ì— ìƒì„±í•œ í‰ê°€ ì§ˆë¬¸ì„ ì €ì¥í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.

```js
# wandb log scalar í‰ê·  ì¶©ì‹¤ì„± ë° ê´€ë ¨ì„± ì ìˆ˜
wandb.log({"faithfulness_mean": faithfulness_df["score"].mean()})
wandb.log({"relevancy_mean": relevancy_df["score"].mean()})
```

![Image](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_5.png)

ëŒ€ìš©ëŸ‰ íŒŒì¼(ì²´í¬í¬ì¸íŠ¸, í…ìŠ¤íŠ¸ ë˜ëŠ” IndexStore(ë²¡í„°í™”ëœ ë°ì´í„°ë² ì´ìŠ¤))ì„ ì €ì¥í•˜ëŠ” ë°ë„ ìœ ìš©í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

# W&Bì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì„ CSV íŒŒì¼ì— ìœ ì§€í•˜ê³ , ë‚˜ì¤‘ì— ë¡œë“œí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

# Artifact ê°ì²´ ìƒì„±

artifact = wandb.Artifact(name="eval-questions", type="text")

# ì§ˆë¬¸ ëª©ë¡ì„ artifactì— íŒŒì¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

with artifact.new_file("questions.txt", mode="w") as f:
f.write("\n".join(eval_questions))

# Artifactë¥¼ W&Bì— ê¸°ë¡í•©ë‹ˆë‹¤.

wandb.log_artifact(artifact)

![Artifact Image1](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_6.png)

# W&B ì´ˆê¸°í™”

wandb_args = {"project": WANDB_PROJECT, "name": "baseline-evaluation"}
wandb_callback = WandbCallbackHandler(run_args=wandb_args)
callback_manager = CallbackManager([wandb_callback])

service_context = ServiceContext.from_defaults(
...
callback_manager=callback_manager # ì—¬ê¸°ì— W&B í•¸ë“¤ëŸ¬ê°€ ìˆìŠµë‹ˆë‹¤.
)

![Artifact Image2](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_7.png)

<div class="content-ad"></div>

# ğŸï¸ ê³ ê¸‰ RAG

![ì´ë¯¸ì§€](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_8.png)

ì´ì œ RAG í’ˆì§ˆì„ ì—…ê·¸ë ˆì´ë“œ í•´ë´…ì‹œë‹¤. ê¸°ë³¸ RAGëŠ” ì´ë¯¸ ì§ˆë¬¸ì— ì‘í•  ìˆ˜ ìˆì§€ë§Œ ê·¸ë‹¤ì§€ ì˜í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ê³„ì¸µì  ë…¸ë“œ êµ¬ë¬¸ ë¶„ì„ ë° ì¬ìˆœìœ„ ì„¤ì •ì„ í†µí•´ ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸ í†µí•©ê³¼ ê²€ìƒ‰ ìš°ì„  ìˆœìœ„ ë¶€ì—¬ê°€ ê°€ëŠ¥í•œ ê³ ê¸‰ ì„¤ì •ì„ íƒìƒ‰í•´ë´…ì‹œë‹¤.

![ì´ë¯¸ì§€](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_9.png)

<div class="content-ad"></div>

ìš°ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê³„ì¸µ êµ¬ì¡°ì—ì„œ ë¬¸ì„œ ì²­í¬ íŠ¸ë¦¬ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê³„ì¸µ ë…¸ë“œ íŒŒì„œë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ” VectorStoreì— ìƒ‰ì¸í™”ë©ë‹ˆë‹¤. ì´ˆê¸° ê²€ìƒ‰ í›„, êµì°¨ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ìˆœìœ„ ì§€ì •í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ì¿¼ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸ ê°„ì˜ ì„¸ë°€í•œ ê´€ê³„ë¥¼ í¬ì°©í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

```python
from llama_index.node_parser import HierarchicalNodeParser

# ê³„ì¸µ ë…¸ë“œ íŒŒì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì£¼ì˜: ì²­í¬ í¬ê¸°ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
node_parser = HierarchicalNodeParser.from_defaults(
    chunk_sizes=[2048, 512, 128]
)

# ë¬¸ì„œì—ì„œ ë…¸ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
nodes = node_parser.get_nodes_from_documents(documents)
```

ë…¸ë“œê°€ ì–´ë–»ê²Œ ë³´ì´ëŠ”ì§€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?

```python
from llama_index.node_parser import get_leaf_nodes

leaf_nodes = get_leaf_nodes(nodes)
print(leaf_nodes[0].text)

>>> ì „ë¬¸ê°€ë“¤ì˜ í˜¼í•©ë¬¼
ì•Œë²„íŠ¸ Q. ì¥, ì•Œë ‰ì‚°ë“œë¥´ ì‚¬ë¸”ë¼ì´ë¡¤, ...
...
ìš°ë¦¬ëŠ” Sparse Mixture of Experts (SMoE) ì–¸ì–´ ëª¨ë¸ì¸ Mixtral 8x7Bë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. Mixtralì€ Mistral 7Bì™€ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§€ë©° ê° ë ˆì´ì–´ê°€ êµ¬ì„±ë˜ëŠ” ê²ƒì´ ë‹¤ë¥¸ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
```

<div class="content-ad"></div>

ì´ì œ ì´ ê³„ì¸µ êµ¬ì¡°ì—ì„œ ìƒ‰ì¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

```js
# context ê²€ìƒ‰ ëª…ì„¸ ìƒì„±
auto_merging_context = ServiceContext.from_defaults(
    llm=llm,
    embed_model="local:BAAI/bge-small-en-v1.5",
    node_parser=node_parser,  # hierarchical ë…¸ë“œ íŒŒì„œê°€ ì—¬ê¸°ì— ìˆìŒì„ ëª…ì‹¬í•˜ì„¸ìš”
)

# ë…¸ë“œ, ê·¸ë˜í”„ ë° ê¸°íƒ€ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° ì»¨í…Œì´ë„ˆì¸ StorageContext
storage_context = StorageContext.from_defaults()
storage_context.docstore.add_documents(nodes)

# êµ¬ì„±ì—ì„œ ì¸ë±ìŠ¤ ìƒì„±
automerging_index = VectorStoreIndex(
    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context
)
```

ì´ì œ ì´ëŸ¬í•œ ë…¸ë“œë“¤ì„ ì¬ìˆœìœ„ ì§€ì •í•´ë´…ì‹œë‹¤. ì´ˆê¸° ê²€ìƒ‰ ì‹œìŠ¤í…œì€ ì¢…ì¢… ê¹Šì€ ì˜ë¯¸ì  ì´í•´ë³´ë‹¤ëŠ” ì†ë„ë¥¼ ìš°ì„ ì‹œí•©ë‹ˆë‹¤. êµì°¨ ì¸ì½”ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” SentenceTransformerRerankëŠ” ì¿¼ë¦¬ì™€ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ì„¸ë¶€ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ì˜ íŒŒì•…í•˜ëŠ” ë° ì¢‹ìŠµë‹ˆë‹¤.

```js
from llama_index.indices.postprocessor import SentenceTransformerRerank
from llama_index.retrievers import AutoMergingRetriever
from llama_index.query_engine import RetrieverQueryEngine

# ì¸ë±ìŠ¤ì—ì„œ retriever ê°€ì ¸ì˜¤ê¸°
automerging_retriever = automerging_index.as_retriever(
    similarity_top_k=12
)

# AutoMergingRetriever ìƒì„±
# hierarchical ë…¸ë“œ íŒŒì„œê°€ ìˆëŠ” Indexì—ì„œ retrieverë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì— ì£¼ëª©í•˜ì„¸ìš”
retriever = AutoMergingRetriever(
    automerging_retriever,
    automerging_index.storage_context,
    verbose=True,
)

# re-ranker ìƒì„±, ë‚˜ì¤‘ì— ë³‘í•©ëœ ì²­í¬ì— í•„ìš”í•  ê²ƒì…ë‹ˆë‹¤
rerank = SentenceTransformerRerank(top_n=4, model="BAAI/bge-reranker-base")

# ì¿¼ë¦¬ ì—”ì§„ ë˜í¼ ìƒì„±. í›„ì²˜ë¦¬ê¸°ë¥¼ ë„£ê¸°ìœ„í•´ ë˜í¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.
auto_merging_engine = RetrieverQueryEngine.from_args(
    automerging_retriever,
    node_postprocessors=[rerank],
    verbose=True,
    service_context=auto_merging_context
)
```

<div class="content-ad"></div>

## ì™„ë£Œí–ˆì–´ìš”, í…ŒìŠ¤íŠ¸í•´ë³´ì£ 

```js
response = auto_merging_engine.query("Sparse MoEì—ì„œ ì „ë¬¸ê°€ëŠ” ëª‡ ëª… ì‚¬ìš©ë˜ë‚˜ìš”?");
display_response(response);
```

ìµœì¢… ì‘ë‹µ: Mixtral 8x7Bì—ì„œ ê° ë ˆì´ì–´ëŠ” 8ê°œì˜ í”¼ë“œí¬ì›Œë“œ ë¸”ë¡ ë˜ëŠ” ì „ë¬¸ê°€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì „ë¬¸ê°€ëŠ” ì´ 8ëª…ì…ë‹ˆë‹¤. âœ…

ìš°ë¦¬ëŠ” ì´ ì‹œìŠ¤í…œì„ ê¸°ì¤€ì„ ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆì–´ìš”. ê¸°ì¤€ì„ ë³´ë‹¤ ê°œì„ ëœ ì ì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”. W&Bì— ê²°ê³¼ë¥¼ ê¸°ë¡í•œ ë’¤, ê° ì‹¤í–‰ ì‚¬ì´ì˜ ë¹„êµ ì°¨íŠ¸ë¥¼ ê´€ì°°í•  ìˆ˜ ìˆì–´ìš”.

<div class="content-ad"></div>

![BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_10.png](/assets/img/2024-07-13-BuildingEvaluatingandTrackingaLocalAdvancedRAGSystemMistral7bLlamaIndexWB_10.png)

ëª¨ë“  ì½”ë“œì™€ ìì„¸í•œ ë‚´ìš©ì€ GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”. ì´ ê¸€ì´ ì—¬ëŸ¬ë¶„ì—ê²Œ ë„ì›€ì´ ë˜ì—ˆê¸°ë¥¼ ë°”ë¼ë©° ğŸ¤—
