---
title: "대규모 언어 모델과 지식 그래프를 통합하는 방법 신경-상징적 관점에서"
description: ""
coverImage: "/assets/img/2024-07-12-IntegratingLargeLanguageModelsandKnowledgeGraphsANeuro-SymbolicPerspective_0.png"
date: 2024-07-12 23:46
ogImage:
  url: /assets/img/2024-07-12-IntegratingLargeLanguageModelsandKnowledgeGraphsANeuro-SymbolicPerspective_0.png
tag: Tech
originalTitle: "Integrating Large Language Models and Knowledge Graphs: A Neuro-Symbolic Perspective"
link: "https://medium.com/ai-in-plain-english/integrating-large-language-models-and-knowledge-graphs-a-neuro-symbolic-perspective-b1b677a0b2e7"
isUpdated: true
---

인공지능 소프트웨어가 이 글의 문법, 흐름, 가독성을 향상시키는 데 사용되었습니다.

최근 대규모 신경망 모델의 등장으로 자연어 처리는 놀랍도록 유창하고 언어 이해 능력이 뛰어난 것으로 크게 영향을 받았습니다. 그러나 앞서 다룬 바와 같이 이러한 대형 언어 모델은 취약점인 부서지기 쉬움, 불투명성, 환영 등 몇 가지 주요 결함을 갖고 있습니다.

지식 그래프는 현실 세계 개체와 관계에 대한 사실적 데이터의 구조화된 표현을 네트워크된 노드와 가장으로 제공합니다. 이상적인 방법 중 하나는 이러한 상징적 지식을 연결하여 대형 언어 모델의 다재다능성을 활용하여 신뢰성과 신용성을 향상시키는 흥미로운 방법을 제공합니다.

그래서 정확히 대규모 언어 모델을 효과적으로 보완하기 위해 지식 그래프를 어떻게 활용할 수 있을까요? 최근 신경 기호론적 기술의 분류에 따르면, 그래프와 언어 모델이 교차하는 지점에 등장한 세 가지 흥미로운 통합 방법이 있습니다:

<div class="content-ad"></div>

인지 및 개념 해석 엔진: 큰 언어 모델의 개념적 추론을 증진하기 위해 관련 지식 그래프 콘텍스트를 제공하는 기술입니다.

상징적으로 향상된 신경망: 상징적인 그래프 구조를 활용하여 신경 언어 모델이 수행하는 내부 추론 과정을 명시적으로 형성하는 방법론입니다.

신경-상징적 인터페이스 아키텍처: 상징적 그래프 형식과 신경망이 사용하는 연속 벡터 공간 사이를 직접 번역하여 통합된 추론을 가능하게 하는 접근 방식입니다.

다음으로, 이러한 신경-상징적 패러다임의 각각 예시를 논의하여, 그래프에 포함된 체계적이고 설명적인 지식과 대형 신경 언어 모델의 다재다능함 및 상관 관계 주도형 일반화 능력을 상호 작용적으로 활용하는 방법에 대해 이야기하겠습니다.

<div class="content-ad"></div>

이러한 기술들을 범주화하는 주요 이점은 상징적, 신경학적 및 확률적 기술에 걸쳐 증강 지능을 발휘하기 위한 철학적 통합 방식을 체계적으로 이해하는 데 있습니다.

![2024-07-12-IntegratingLargeLanguageModelsandKnowledgeGraphsANeuro-SymbolicPerspective_0.png](/assets/img/2024-07-12-IntegratingLargeLanguageModelsandKnowledgeGraphsANeuro-SymbolicPerspective_0.png)

# LLM에 지식 그래프 컨텍스트 제공

지식 그래프 프롬프팅과 같은 기술들은 포괄적인 지식 그래프에서 가장 관련성 높은 서브그래프를 선택적으로 검색하여 언어 모델 응답의 사실적 맥락을 제공합니다:

<div class="content-ad"></div>

- **관련 부분 그래프 추출을 위해 그래프 임베딩 및 의미적 쿼리 사용**
- **자연어 설명으로 하위 그래프 후처리**
- **LLM을 위한 프롬프트에 맥락 추가**
- **LLM에서 지원되지 않는 논리적 도약 가능성 감소**

다른 신경 기호화 기술과의 조화

이 접근 방식은 신경 기호화 기술에서 인식 및 개념적 해석 엔진으로 분류 된 다른 기술들과 일치합니다:

NSCA: 신경 학습과 상징적 지식 표현을 결합하는 기술로 RTRBM을 사용하고 상징적 지식을 위해 시간 논리를 사용합니다. 이 모델들에 대한 통합적 온라인 학습 및 추론을 허용합니다.

<div class="content-ad"></div>

NSCL: NSCL은 시각 인식 신경망을 상징적 프로그램 실행으로부터 유사하게 해제합니다. 상징적 프로그램은 신경 모듈이 학습한 시각적 개념에 대한 설명 능력과 해석 가능성을 제공합니다.

ABL: ABL은 신경망과 상징 논리 추론자 간 양방향 상호 작용을 통해 피드백을 교환할 수 있게 합니다. 이 촘촘한 통합은 신경 표현과 상징적 추론을 상호적으로 견고하게 합니다.

NSVQA: 마찬가지로 NSVQA는 언어와 시각적 입력에 대한 추론을 위해 상징적 프로그램을 활용하면서 지각적 이해를 위해 신경망을 적용합니다.

주요 차별화 요인

<div class="content-ad"></div>

지식 그래프를 context 제공자로 활용하는 것의 주요 차이점은 통합의 단방향성에 있습니다:

- 그래프에서의 상징적 지식은 LLM에게 입력 context로 제공되지만 내부 표현이나 믿음에 동적으로 영향을 미치지 않습니다.
- 사실적인 기초는 내재적 개념적 해석과 융합된 것이 아닌 외부적입니다.
- ABL과 달리 모듈이 요구사항을 명확히 하는 데 루핑 상호작용이 없습니다.

지식 그래프 context 제공은 인지 및 개념 해석 엔진 범주의 다른 뉴로-상징적 기술들과 철학적으로 일치하지만, 모듈이 서로 유연하게 영향을 미칠 수 없기 때문에 통합은 비교적 표면적입니다.

내 제안하는 프레임워크는 상호피드백 루프를 통해 훨씬 더 밀접하게 결합할 수 있는 가능성을 강조합니다.

<div class="content-ad"></div>

태로 전문가님! 여기서 언급된 상호 작용 프로토콜에 대해 좀 더 자세히 알아보겠습니다:

- 추론 모듈은 동적인 요구에 기반하여 지속적인 관련 피드백을 제공하여 지식 검색 과정을 안내하고 특수화합니다.
- 검색 모듈은 추론 중 식별된 잠재적인 지식 공백을 명확히하고 검색 공간을 이에 맞게 확장합니다.
- 구성 요소 간의 양방향 지식 흡수.

이렇게, 언어 모델의 지식 기반에 대한 기존 체계는 종종 분리되어 있고 단방향적이지만, 여기서 제시된 개념적 아키텍처는 이러한 얕은 파이프라인의 한계를 인식합니다.

대신 언어 및 그래프 모듈을 상호 협력적인 요소로 구조화하여 유연하게 요구 사항을 소통함으로써, 재발하는 상호 정보 제공 패러다임에서 내부 및 외부 지식을 아우르는 통합 추론이 가능한 가능성을 열어 줍니다.

<div class="content-ad"></div>

이것은 신경 및 심볼 시스템 간의 강한 결합과 연속성을 장려하는 신경-기호주의 아키텍처의 기초에 더 가깝습니다. 이로 인해 고립된 구성 요소 간의 맥락 분열을 피할 수 있습니다.

# 명시적 추론 토폴로지로서의 그래프

혁신적인 접근 방식은 동적 추론 프로세스 자체를 그래프 탐색으로 의도적으로 모델링하는 것입니다:

- 예시로는 그래프 경로를 사용하여 분석 라인을 진화시키는 트리/그래프/생각-연쇄 아키텍처가 있습니다.
- 따라서 토폴로지 자체가 추론을 형성하고 이끄는 것으로, 단순히 입력 맥락을 제공하는 것 이상입니다.
- 이는 복잡한 추론을 위한 과정을 적극적으로 이끄는 것으로, 그래프의 수동적인 이용을 넘어섭니다.
- 심볼 강화형 신경망과 일치합니다. 여기서 심볼 규칙이 모델 해석을 이끌어 줍니다.

<div class="content-ad"></div>

친구들을 위해 한 가지 특별한 카드를 더 보여드리겠어요.

**안내: 나무/그래프/사고 연쇄** 와 같은 방법은 상징적 그래프 구조를 사용하여 진화하는 분석적 추론 흐름을 나타냅니다:

- 그래프 경로가 동적 다단계 추론을 형성합니다.
- 토폴로지를 통해 복잡한 논리 분석을 진행합니다.
- 사실적인 맥락을 제공하는 것 이상의 가치를 제공합니다.

**다른 신경-상징 기법들과의 조화**

<div class="content-ad"></div>

이 방식은 모델 해석을 안내하는 기타 상징 강화 신경망 기술과 일치합니다:

- LTNs: 텐서 표현에 정의된 퍼지 논리 제약 조건을 신경망과 결합하여 학습 결과를 형성합니다. 논리 공식은 신경 이성을 강화하는 구조적 프레임워크를 제공합니다.

- Diff ILP: 미분 가능한 신경 모듈로 표현된 논리 관계의 기울기 기반 학습을 가능하게 합니다. 귀납 논리 프로그래밍 아키텍처는 모델 추론 능력에 영향을 미칩니다.

주요 구분점

<div class="content-ad"></div>

탐험적 추론을 모델링하는 주요 혁신은 다음과 같습니다:

- 그래프 위상이 단순히 입력을 제공하는 것이 아니라 추론 단계를 능동적으로 이끌어 줍니다.
- 경로는 변화하는 사고 구조를 나타냅니다.
- 근거가 없음 - 순수하게 내부 모델 추론 역동을 이끌기 위한 집중력을 가집니다.

요컨대, 상징적 그래프 구조는 보충적인 사실적 맥락을 제공하는 것이 아닌, 다단계 흐름을 통해 분석을 의도적으로 이끌어내는 역할을 담당합니다.

# 그래프 분석을 위한 LLM 활용하기

<div class="content-ad"></div>

### 마침내 대형 언어 모델이 그래프 데이터를 직접 처리하도록 적용되고 있습니다.

- 대규모 그래프 코퍼스에서 변형기 언어 모델을 사전 훈련하는 예시가 있습니다.
- 그래프 분석 작업 자체를 그래프 입력/출력에 맞춘 텍스트 프롬프트로 재구성합니다.
- 신경 구조와 상징적 지식 그래프를 연결하는 다리를 만듭니다.

저는 이러한 기술을 Neural-Symbolic Interface Architectures의 하위 범주로 분류합니다. 이 기술은 상징적 그래프 데이터를 신경 처리와 통합된 프레임워크에서 교차로 삽입합니다.

이러한 접근법 전반에 걸쳐 주요 이점은 신경 언어 모델의 다용도성을 구조화된 사실적 지식에 상호 보강하여 견고함을 향상시키는 것에 있습니다.

<div class="content-ad"></div>

LLMs(언어모델; Language Models)를 그래프 분석에 적용하기

그래프 분석을 텍스트 형식의 입력/출력으로 재포맷하거나 거대한 그래프 데이터셋에서 트랜스포머 LMs(언어모델; Language Models) 사전 훈련하는 방법들이 있는데요:

- 그래프 작업에 맞게 텍스트 프롬프트를 맞추다
- 그래프 말뭉치에서 언어모델 파라미터 사전 훈련하다
- 신경망 아키텍처와 상징적 그래프 연결하다

다른 신경-상징적 기법들에 대한 조정

<div class="content-ad"></div>

이것은 다른 뉴로 심볼릭 방법들과 일치합니다. 이들은 심볼식 지식과 신경 처리를 교차로 사용합니다.

- GNNs: 그래프 신경망은 그래프 입력을 그래프 컨볼루션과 같은 전문 레이어를 사용하여 처리합니다. 출력은 또한 구조화된 그래프입니다.

- LTNs: 신경망과 텐서 표현에 대한 퍼지 논리 제약사항을 결합합니다. 이는 그래프 분석 작업에 대한 논리적 추론을 지원합니다.

주요 차별화 요소:

<div class="content-ad"></div>

**타로 전문가로서 안녕하세요!🌟**

LLM을 그래프에 적용하는 주요 혁신 요소는 다음과 같습니다:

- 그래프에 특화된 GNN과는 달리 그래프 작업을 위해 내재된 LM 아키텍처를 활용합니다.
- 명시적 그래프 ↔ 텍스트 인코더/디코더 방식 대신, 작업을 원활하게 번역하기 위해 재정의합니다.
- 언어에 튜닝된 사전 훈련된 매개변수를 활용합니다.

그래프 입력을 위해 모델 아키텍처를 특화시키는 대신, 자연어를 중간 매개로 사용하여 일반적인 목적의 LM 아키텍처의 장점을 직접 채택합니다.

# 언어와 그래프의 시너지가 약속하는 것들 ✨

<div class="content-ad"></div>

크고 교차로 이어진 사전지식이 큰 트랜스포머 기반 언어 모델의 주목할 만한 상관관계 추론을 바탕으로 하면 더욱 신뢰할 수 있고 투명한 지능을 향해 흥미로운 길을 열 수 있습니다.

지식 그래프는 실제 세계의 사람, 장소, 사건 등을 포괄하는 상호 관련된 사실적인 개념들로 모델 응답을 맥락화합니다. 이는 LMs의 텍스트 자기 감독으로 인한 미지원 논리적 점프 경향을 줄여줍니다.

한편, 상징적 그래프 이동으로 추론 체인을 명시적으로 모델링하면, 복잡한 다단계 추론 흐름을 위한 구조적인 프레임워크를 제공합니다. 그 포토폴로지 자체가 사실적인 지식을 단순히 검색하는 것 이상의 분석 구조의 변화를 형성합니다.

언어 모델은 또한 사전 훈련을 통해 풍부한 텍스트 상식에 노출되어 텍스트 프롬프트로 구성된 지식 그래프 내에서 통찰력을 발견하는 데 큰 규모를 제공합니다.

<div class="content-ad"></div>

그 말은 본질적으로, LMs가 배운 인상적이지만 빈약한 텍스트 상관 관계를 설명하는 구조화된 지식을 사용하여 심볼적 추론 작업에 LMs의 다재다능성을 동시에 활용함으로써, 벡터, 심볼 및 확률의 장점을 결합한 더 견고하고 투명하며 다각적인 지능을 약속한다는 것이다.

부상한 시스템 병목 현상

그러나 런타임 프로파일링 분석에 따르면, 기존의 신경-심볼적 아키텍처가 효율성과 확장성 병목 현상을 겪어 문제 복잡성이 증가함에 따라 이러한 상호 작용 잠재력을 완전히 실현하는 데 제약을 받고 있는 것으로 나타납니다.

- 추론 및 해석 작업을 담당하는 심볼적 작업 부하는 런타임에서 주목할만한 높은 비율을 차지합니다. 특정 경우에는 92%에 이를 수 있습니다. 이러한 이유로 불균형한 병목 현상으로 나타납니다.
- 이러한 심볼적 작업은 신경 작업보다 수학적 강도가 떨어지며, 낮은 처리량의 벡터 및 스칼라 데이터 조작에 의해 지배됩니다. 이로 인해 최적화 여백이 발생합니다.
- 포함된 논리 및 검색 절차는 데이터 수준 파이프라인보다 쉽게 병렬화되지 않는 복잡한 조건부 제어 흐름으로 나타납니다.
- 심볼적 지식을 신경 표현과 결합하면 더 높은 희소성으로 인해 불규칙한 메모리 액세스 패턴이 도입됩니다. 이는 데이터 이동 오버헤드를 증가시킵니다.
- 총 런타임은 데이터 세트 크기에 따라 비선형으로 지수 함수적으로 확장되며, 이는 심볼적 추론 절차에 영향을 줌으로써 확장성이 우려됩니다.

<div class="content-ad"></div>

앞으로 나아갈 길

언어 모델 간에 약속된 협력적 연속성을 정맥화하려면, 구조화된 지식과 추론 토폴로지를 극복하고 이러한 시스템 수준 병목현상을 공동 설계를 통해 극복해야합니다:

- 다양한 심볼릭, 신경망 및 확률적 구성요소의 쉬운 효율적인 통합을 가능하게 하는 최적화된 소프트웨어 프레임워크.
- 심볼적 워크로드를 가속화하기 위한 벡터 프로세서, 재구성 가능한 인터커넥트 및 균형 잡힌 칩 내부 메모리와 같은 전문 하드웨어 가속기.
- 계산의 다양성과 접근 패턴을 포착하고 최적화 기회를 확인하기 위한 표준화된 평가 및 최적화 기회 식별을 가능하게 하는 대표적인 벤치마크.

현대 기계 학습이 놀라운 발전을 이루었지만, 보다 인간다운 투명한 추론을 실현하기 위해서는 구조화된 설명적 지식에 모델을 유기적으로 둘러싸는 것이 필요합니다. 이는 그래프와 언어의 장점을 결합한 협력적 아키텍처가 가지는 약속입니다.

<div class="content-ad"></div>

하지만 시스템 효율성 장벽을 극복하기 위해 하드웨어와 소프트웨어의 조화로운 공동 설계가 필수적이며, 이는 AI 능력의 다음 수준을 발전시키는 데 중요합니다.

# 일상어로 해석하기 🚀

In Plain English 커뮤니티에 함께해 주셔서 감사합니다! 떠나시기 전에:

- 작가의 글을 클랩하고 팔로우해주세요 ️👏️
- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter
- 다른 플랫폼에서도 만나보세요: Stackademic | CoFeed | Venture
- PlainEnglish.io에서 더 많은 콘텐츠를 확인해보세요
