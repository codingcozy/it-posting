---
title: "CPO-SimPO  CPO-SimPOë¥¼ ì‚¬ìš©í•´ Phi3-Mini4k-Instruct í›ˆë ¨í•˜ëŠ” ë°©ë²•"
description: ""
coverImage: "/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_0.png"
date: 2024-07-07 13:30
ogImage:
  url: /assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_0.png
tag: Tech
originalTitle: "CPO-SimPO | Training Phi3-Mini4k-Instruct with CPO-SimPO"
link: "https://medium.com/@zaiinn440/cpo-simpo-training-phi3-mini4k-instruct-with-cpo-simpo-de8c58b3ac32"
isUpdated: true
---

ì¹œì• í•˜ëŠ” ë¶„ë“¤,

LLMì„ DPOë³´ë‹¤ ëœ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ë¹ ë¥¸ ì†ë„ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

![ì´ë¯¸ì§€](/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_0.png)

# ì†Œê°œ

ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•´ LLMì„ ì •ë ¬í•˜ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•ì€ ì§€ë„ Fine-Tuning (SFT)ë¡œ ì‹œì‘ë©ë‹ˆë‹¤. ë³´í†µ ëª¨ë¸ì„ 4-Bitë¡œ ë¡œë“œí•˜ê³  LoRA í›ˆë ¨ì„ ìœ„í•œ êµ¬ì„±ì„ ì ìš©í•©ë‹ˆë‹¤. í‘œì¤€ ë°©ë²•ì€ ëª¨ë¸ì„ 4-Bit ëª¨ë“œë¡œ ë¡œë“œí•˜ê³  LoRA (ë‚®ì€ ìˆœìœ„ ì ì‘) í›ˆë ¨ì„ ìœ„í•œ êµ¬ì„±ì„ ì ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. DPO (ì§ì ‘ ì„ í˜¸ ìµœì í™”)ëŠ” ë¹„ìš©ì„ ë‚®ì¶”ê¸° ìœ„í•´ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ë˜ ë‹¤ë¥¸ ì£¼ìš” ê¸°ë²•ì…ë‹ˆë‹¤. í‘œì¤€ ë°©ë²•ì€ SFT+DPOë¥¼ ê²°í•©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ë” ê°œì„ í•˜ì§€ë§Œ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Odds Ratio Preference Optimization (ORPO)ëŠ” SFT+DPOë¥¼ ëŒ€ì²´í•˜ì—¬ ì„ í˜¸ ë° ë¹„ì„ í˜¸ ì‘ë‹µ ì‚¬ì´ì˜ ìƒì„± ìŠ¤íƒ€ì¼ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ í™•ë¥  ë¹„ìœ¨ ê¸°ë°˜ì˜ íŒ¨ë„í‹°ë¥¼ ë¶€ê³¼í•˜ì—¬ ë³´ë‹¤ í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ë‹¨ì¼ ë‹¨ê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

ë” ì•ˆì •ì ì¸ í›ˆë ¨ê³¼ í–¥ìƒëœ ì„±ëŠ¥ì„ ìœ„í•œ ë˜ ë‹¤ë¥¸ ê¸°ìˆ ë¡œ CPO-SimPOê°€ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í›ˆë ¨ ë°ì´í„° í’ˆì§ˆì— ëŒ€í•œ SFTì˜ ì˜ì¡´ì„±ì„ ê·¹ë³µí•˜ê³ , DPOì˜ ë©”ëª¨ë¦¬+ì†ë„ ë¹„íš¨ìœ¨ì„±ì„ (parametrizedì™€ reference policy ë‘˜ ë‹¤ ë‹¤ë£° ë•Œ) ì™„í™”í•˜ë©°, ê¸´ â€‹â€‹but ì €í’ˆì§ˆ ìˆœì„œì˜ ìƒì„±ì„ ë°©ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” ì´ ê¸°ìˆ ì— ëŒ€í•´ ìì„¸íˆ ì†Œê°œí•˜ê³  CPO-SimPOì—ì„œ Phi3-Mini-4K-Instructë¥¼ ì¶”ê°€ë¡œ í›ˆë ¨í•  ê²ƒì…ë‹ˆë‹¤.

# CPO-SimPOëŠ” ë¬´ì—‡ì¸ê°€ìš”?

ì´ê²ƒì€ ë‘ ì„ í˜¸ ìµœì í™” ë°©ë²•ì¸ CPOì™€ SimPOë¥¼ ê²°í•©í•œ ê²ƒì…ë‹ˆë‹¤.

# ëŒ€ì¡°ì ì¸ ì„ í˜¸ ìµœì í™” â€” CPO

<div class="content-ad"></div>

í•˜ì˜¤ë€ ì”¨ ë“±ì´ ì œì•ˆí•œ CPO ëª©ì ì€ ì›ë˜ DPO ì†ì‹¤ì—ì„œ ì´ìƒì ì¸ ì •ì±…ì„ ì œì™¸í•˜ê³  ê·¼ì‚¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ í–‰ë™ ë³µì œ(BC) ì •ê·œí™”ê¸°ê°€ í†µí•©ë˜ì–´ ëª¨ë¸ì´ ì„ í˜¸í•˜ëŠ” ë°ì´í„° ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.

![CPO Training](/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_1.png)

CPOëŠ” ë›°ì–´ë‚œ í’ˆì§ˆì˜ ê·¸ëŸ¬ë‚˜ í ì—†ëŠ” ì„ í˜¸ ë°ì´í„°ì…‹(prompt, chosen, rejected í˜•ì‹)ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ ì¶œë ¥ì˜ ì™„ë²½í•¨ì„ ë‹¬ì„±í•˜ê³  ì‹¬ì§€ì–´ ì‘ì€ ê²°í•¨ë„ ì™„í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# Simple Preference Optimization â€” SimPO

<div class="content-ad"></div>

Yu Mengë‹˜ ë“±ì— ì˜í•´ ì†Œê°œëœ 2024ë…„ SimPOëŠ” ì¼ë°˜ DPOì™€ ëŒ€ë¹„í•˜ì—¬ ì°¸ì¡° ëª¨ë¸ì´ í•„ìš” ì—†ì–´ìš”. ì´ëŠ” ì£¼ìš” ì •ì±… ëª¨ë¸ì´ ìƒì„±í•œ ëª¨ë“  í† í°ì˜ í‰ê·  ë¡œê·¸ í™•ë¥ ì— ê¸°ë°˜í•œ ê¸¸ì´ ì •ê·œí™”ëœ ë³´ìƒì„ í†µí•´ ëª…ì‹œì  ë³´ìƒ ëª¨ë¸ ëŒ€ì‹ ì— ì§ì ‘ ë™ì‘í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ë‘˜ì§¸ë¡œ, ê±°ì ˆëœ ì‘ë‹µê³¼ ì„ íƒëœ ì‘ë‹µ ê°„ ë³´ìƒ ì°¨ì´ê°€ íŠ¹ì • ë³´ìƒ ë§ˆì§„ Î³ë¥¼ ì´ˆê³¼í•˜ë„ë¡ í•˜ëŠ” ëª©í‘œ ë³´ìƒ ë§ˆì§„ Î³ë¥¼ ë„ì…í•©ë‹ˆë‹¤.

![ì´ë¯¸ì§€](/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_2.png)

SimPOëŠ” ëª…ì‹œì  ë³´ìƒ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ DPOë³´ë‹¤ ë©”ëª¨ë¦¬ ë° ê³„ì‚° íš¨ìœ¨ì´ ë†’ìœ¼ë©°, AlpacaEval2ì™€ ArenaHardì—ì„œ DPOë¥¼ ëŠ¥ê°€í•˜ë©´ì„œ ê¸´ ê¸¸ì´ì˜ ë‚®ì€ í’ˆì§ˆ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.

![ì´ë¯¸ì§€](/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_3.png)

<div class="content-ad"></div>

# CPO-SimPO

ë‘ ê°€ì§€ ëª©ì ì„ ê²°í•©í•˜ë©´ CPO-SimPO ì†ì‹¤ì´ ë°œìƒí•˜ì—¬ ë‘ ì„ í˜¸ ìµœì í™” ë°©ë²•ì˜ í˜œíƒì„ í•¨ê»˜ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![image](/assets/img/2024-07-07-CPO-SimPOTrainingPhi3-Mini4k-InstructwithCPO-SimPO_4.png)

# CPO-SimPO Training of Phi3-Mini-4k-Instruct

<div class="content-ad"></div>

HuggingFace ëª¨ë¸ì˜ CPO-SimPO êµìœ¡ì„ ê³µì‹ GitHub ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ìš”.

# ì¢…ì†ì„± ì„¤ì •í•˜ê¸°

condaë¥¼ ì‚¬ìš©í•˜ì—¬ Python í™˜ê²½ì„ ë§Œë“¤ì–´ì•¼ í•´ìš”. condaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš° condaë¥¼ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ ë“œë¦´ê²Œìš”:

```js
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
```

<div class="content-ad"></div>

ìƒˆë¡œìš´ íš¨ê³¼ê°€ ì ìš©ë˜ë ¤ë©´ ìƒˆ í„°ë¯¸ë„ì„ ì—´ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ì œ íŒŒì´ì¬ ê°€ìƒ í™˜ê²½ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.

```bash
conda create -n handbook python=3.10 && conda activate handbook
```

ê·¸ëŸ° ë‹¤ìŒ ì‹œìŠ¤í…œì— ë”°ë¼ ì„¤ì¹˜ ë°©ë²•ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” pytorch v2.2.2ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
conda install pytorch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 pytorch-cuda=11.8 -c pytorch -c nvidia
```

<div class="content-ad"></div>

ì´ ì½”ë“œë² ì´ìŠ¤ëŠ” alignment-handbook ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œì–´ìš”. ê·¸ë˜ì„œ í•´ë‹¹ íŒ¨í‚¤ì§€ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•  ìˆ˜ ìˆì–´ìš”.

```bash
git clone https://github.com/huggingface/alignment-handbook.git
cd ./alignment-handbook/
python -m pip install .
cd ..
```

ë˜í•œ Flash Attention 2ë„ ì„¤ì¹˜í•´ì•¼ í•´ìš”:

```bash
python -m pip install flash-attn --no-build-isolation
```

<div class="content-ad"></div>

ì´ì œ CPO_SimPO ì €ì¥ì†Œë¥¼ ë³µì œí•´ ë³¼ê¹Œìš”?

```js
git clone https://github.com/fe1ixxu/CPO_SIMPO.git
cd CPO_SIMPO
```

# í›ˆë ¨ êµ¬ì„±

í›ˆë ¨ ì¸ìë¥¼ ì§€ì •í•˜ëŠ” .yaml êµ¬ì„± íŒŒì¼ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. GPU ì‚¬ì–‘ì— ë”°ë¼ per_device_train_batch_sizeì™€ max_lengthë¥¼ ì¡°ì •í•˜ì‹­ì‹œì˜¤. 'loss_type: simpo'ì™€ 'cpo_alpha'ë¥¼ 0ì´ ì•„ë‹Œ ê°’ìœ¼ë¡œ ì„¤ì •í–ˆë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”.

<div class="content-ad"></div>

# ëª¨ë¸ ì¸ì

- model_name_or_path: microsoft/Phi-3-mini-4k-instruct
- torch_dtype: null
- use_flash_attention_2: false

# ë°ì´í„° í›ˆë ¨ ì¸ì

- dataset_mixer: princeton-nlp/llama3-ultrafeedback: 1.0
- dataset_splits:
  - train
  - test
- preprocessing_num_workers: 12

# CPOTrainer ì¸ì

- bf16: true
- beta: 10
- simpo_gamma: 5.4
- cpo_alpha: 0.05
- loss_type: simpo
- do_eval: true
- evaluation_strategy: steps
- eval_steps: 400
- gradient_accumulation_steps: 4
- gradient_checkpointing: true
- gradient_checkpointing_kwargs:
  - use_reentrant: False
- hub_model_id: cpo-simpo-exps
- learning_rate: 1.0e-6
- log_level: info
- logging_steps: 5
- lr_scheduler_type: cosine
- max_length: 2048
- max_prompt_length: 1800
- num_train_epochs: 1
- optim: adamw_torch
- output_dir: outputs/phi3mini4k-cpo-simpo
- run_name: phi3mini4k-cpo-simpo
- per_device_train_batch_size: 2
- per_device_eval_batch_size: 2
- push_to_hub: false
- save_strategy: "steps"
- save_steps: 1000000
- report_to:
  - none
- save_total_limit: 20
- seed: 42
- warmup_ratio: 0.1

# ê°€ì†í™” êµ¬ì„±

ë‹¤ìŒìœ¼ë¡œ í•˜ë“œì›¨ì–´ êµ¬ì„±ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. accelerate_configs ë””ë ‰í„°ë¦¬ ì•„ë˜ì˜ ì €ì¥ì†Œì—ì„œ ì œê³µëœ deepspeed_zero3.yaml êµ¬ì„±ì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. num_processesë¥¼ ì‚¬ìš© ê°€ëŠ¥í•œ GPUì˜ ìˆ˜ë¡œ ì„ íƒí•˜ì„¸ìš”. CUDA ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ A100 GPUê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- compute_environment: LOCAL_MACHINE
- debug: false
- deepspeed_config:
  - deepspeed_multinode_launcher: standard
  - offload_optimizer_device: none
  - offload_param_device: none
  - zero3_init_flag: true
  - zero3_save_16bit_model: true
  - zero_stage: 3
- distributed_type: DEEPSPEED
- downcast_bf16: 'no'
- machine_rank: 0
- main_training_function: main
- mixed_precision: bf16
- num_machines: 1
- num_processes: 1
- rdzv_backend: static
- same_network: true
- tpu_env: []
- tpu_use_cluster: false
- tpu_use_sudo: false
- use_cpu: false

<div class="content-ad"></div>

# í›ˆë ¨ ì‹œì‘

í›ˆë ¨ê³¼ ê°€ì† êµ¬ì„± íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì œê³µí•˜ê³  í›ˆë ¨ì„ ì‹œì‘í•˜ì„¸ìš”. ìµœì¢… ëª¨ë¸ì€ í›ˆë ¨ ì¸ìˆ˜ì—ì„œ ì§€ì •ëœ output_dirì— ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

```js
ACCELERATE_LOG_LEVEL=info accelerate launch --config_file accelerate_configs/deepspeed_zero3.yaml scripts/run_cpo.py training_configs/phi3-mini4k-instruct-cpo-simpo.yaml
```

# ì¶”ë¡ 

<div class="content-ad"></div>

í—ˆê¹…í˜ì´ìŠ¤ ê³„ì •ì— ëª¨ë¸ì„ ì—…ë¡œë“œí•œ í›„ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ìš”:

```js
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
torch.random.manual_seed(0)
model = AutoModelForCausalLM.from_pretrained(
    "abideen/Phi-3-mini-4K-instruct-cpo-simpo",
    device_map="cuda",
    torch_dtype="auto",
    trust_remote_code=True,
)
tokenizer = AutoTokenizer.from_pretrained("abideen/Phi-3-mini-4K-instruct-cpo-simpo")
messages = [
    {"role": "user", "content": "ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸ ì˜ ì¡°í•©ì„ ë¨¹ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
    {"role": "assistant", "content": "ë¬¼ë¡ ì´ì£ ! ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸ ë¥¼ í•¨ê»˜ ë¨¹ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆì–´ìš”: 1. ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸  ìŠ¤ë¬´ë””: ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸ ë¥¼ ìš°ìœ ì™€ ê¿€ê³¼ í•¨ê»˜ ê°ˆì•„ ë§Œë“¤ì–´ìš”. 2. ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸  ìƒëŸ¬ë“œ: ìŠ¬ë¼ì´ìŠ¤í•œ ë°”ë‚˜ë‚˜ì™€ ë“œë˜ê³¤í”„ë£¨ì¸ ë¥¼ ë ˆëª¬ ì£¼ìŠ¤ì™€ ê¿€ê³¼ í•¨ê»˜ ì„ì–´ìš”."},
    {"role": "user", "content": "2x + 3 = 7 ë°©ì •ì‹ì„ í’€ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"},
]
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
)
generation_args = {
    "max_new_tokens": 500,
    "return_full_text": False,
    "temperature": 0.0,
    "do_sample": False,
}
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])
```

ì´ ì‹¤í—˜ì— ì‚¬ìš©ëœ ì»´í“¨íŒ…ì„ í›„ì›í•´ì¤€ QueryLoopAIì— íŠ¹ë³„íˆ ê°ì‚¬ë“œë ¤ìš”.

ê·¸ë¦¬ê³  ì–¸ì œë“ ì§€ ë©”ì‹œì§€ë¥¼ ë‚¨ê¸°ê±°ë‚˜:

- [Twitter](https://twitter.com/example)
- [Email](mailto:example@example.com)
- [Website](https://www.example.com)

ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì—°ë½í•´ë„ ë¼ìš”.

<div class="content-ad"></div>

- LinkedIn, Twitterì—ì„œ ì—°ë½í•˜ê³  íŒ”ë¡œìš°í•´ ì£¼ì„¸ìš”
- ğŸ“š Mediumì—ì„œ ì œ íŒ”ë¡œìš° í•´ì£¼ì„¸ìš”
- ğŸ“¢ ì£¼ê°„ AI ë‰´ìŠ¤ë ˆí„°ë¥¼ êµ¬ë…í•´ ì£¼ì„¸ìš”!
- ğŸ¤— Hugging Faceë„ í™•ì¸í•´ ë³´ì„¸ìš”
