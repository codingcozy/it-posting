---
title: "구조화된 지식을 활용한 대형 언어 모델에서의 환각 탐지 자동화 방법"
description: ""
coverImage: "/assets/img/2024-07-12-LeveragingStructuredKnowledgetoAutomaticallyDetectHallucinationinLargeLanguageModels_0.png"
date: 2024-07-12 23:34
ogImage:
  url: /assets/img/2024-07-12-LeveragingStructuredKnowledgetoAutomaticallyDetectHallucinationinLargeLanguageModels_0.png
tag: Tech
originalTitle: "Leveraging Structured Knowledge to Automatically Detect Hallucination in Large Language Models"
link: "https://medium.com/the-modern-scientist/leveraging-structured-knowledge-to-automatically-detect-hallucination-in-large-language-models-1a94a7929492"
isUpdated: true
---

인공 지능 소프트웨어가 사용되어 이 기사의 텍스트 문법, 흐름 및 가독성을 개선했습니다.

대형 언어 모델(Large Language Models)은 인공 지능의 자연어 능력에 혁명을 일으켰습니다. 이러한 기본 모델은 유도되었을 때 거의 모든 주제에 대해 인상적으로 일관된 텍스트를 생성할 수 있습니다.

그러나 사실 일관성과 환각적인 내용에 대한 우려가 함께 수반되었습니다.

폐쇄 도메인 데이터셋에서 강력한 성능을 보여주지만, 개방형 질의는 LLM의 세계 지식의 왜곡을 드러낼 수 있습니다.

<div class="content-ad"></div>

예를 들어, LLM(언어 모델)은 엔티티, 관계 또는 시간적 사건을 혼동하여 타당하지만 부정확한 답변을 생성할 수 있습니다.

또는 LLM은 훈련 분포를 넘어설 때 서로 다른 맥락의 세부 정보를 혼동할 수 있습니다. 이러한 사실상의 부정확성은 개방 도메인에서 추론 주변의 근본적 제한성을 가리킵니다.

훈련 후 LLM의 사실적인 구멍을 측정하는 측정 벤치마크가 도움이 될 수 있지만, 이제는 실제 세계 배포에서의 런타임 모니터링과 검증에 초점을 전환해야 합니다.

기업이 점점 더 LLM으로 구동되는 대화형 인터페이스를 통합할 때, 진실과 일치하는 것은 신뢰성과 신뢰에 중요합니다. 수동 사실 확인은 비용이 많이 들며 처리량이 부족하며 특정 도메인에는 실행 불가능할 수 있습니다.

<div class="content-ad"></div>

이 기사는 구조화된 지식 그래프(KGs)와 비교하여 LLM 추론을 통해 자동 환각 감지를 제안합니다. KGs는 엔티티 및 이벤트에 대한 관계적 사실을 인코딩하는 외부 메모리 백본 역할을 합니다.

LLM 응답에서 계속해서 주장을 추출하고 해당 도메인 특정 KG와 일치시켜 모순이 환각 가능성을 가리킬 수 있습니다. 이 메트릭을 시간이 지남에 따라 추적함으로써 사실적 변화에 대한 전체적인 관점을 제공합니다.

KGs는 LLM의 유동적 생성 공간 내에서 편차를 평가하는 데 고정 위치 참조를 제공합니다. 신경 표현 학습의 강점과 상징적 지식 기반이 결합된 결과로 현실에서의 이탈을 감지뿐만 아니라 수정하는 길을 열어줍니다. 안전하고 신뢰할 수 있는 언어 AI를 달성하기 위해서는 LLM의 발전이 계속되는 동안 이러한 분야에서의 연구를 지속하는 것이 필수적입니다.

지속적으로 개선되는 검색 보조 생성(RAG) 시스템을 구축하는 것은 효과적인 데이터 플라이휠을 구현하는 것을 요구합니다. 이런 진전의 주기는 계기, 분석, 문제를 데이터 갭으로 연결, 기본 데이터 원본을 개선하고 반복 함으로써, 질문 응답을 위해 지식 그래프와 대형 언어 모델을 활용하는 시스템을 크게 향상시킬 수 있습니다. 문제가 있는 응답을 체계적으로 감지하고 지식 그래프를 확장하여 결함을 해결함으로써, 데이터 플라이휠은 이러한 시스템이 단계적으로 관리되고 대상적인 방식으로 학습하도록 가능케 합니다.

<div class="content-ad"></div>

이 체계적인 플라이휠 파이프라인은 대화형 검색, 고객 지원 및 사실 기반 지식에 기초한 신뢰할 수 있는 질문 응답을 필요로 하는 기타 도메인에서 배포되는 지식 그래프 보강 대형 언어 모델에 매우 관련이 있습니다. 통합된 지식 기반에서 누락된 엔티티, 관계 또는 사실로 인한 부적절한 응답을 사용 중에 추적함으로써 타겟팅된 보완 및 세밀한 조정을 통해 성능과 신뢰성을 향상시킬 수 있습니다. 이 플라이휠 효과는 또한 개선 루프를 코딩하는 것으로 수동 감시 필요성을 줄입니다. 표현 학습, 구조화된 지식 및 사용 중심 개선을 오케스트레이션하는 것이 확장 가능한 진전에 중요합니다.

이 기사는 데이터 플라이휠에 의해 구동되는 지속적인 검토 및 세분화 프로세스가 배포 수명 동안 지식 그래프 기반 대형 언어 모델을 더 적응적이고 실제와 일치하는 것으로 만들 수 있는 방법을 심도 있게 탐구할 것입니다. 이 기술은 산업용 신뢰성에 중요한 자동화된 필요에 중점을 둔 학습을 위한 템플릿을 제공합니다.

![이미지](/assets/img/2024-07-12-LeveragingStructuredKnowledgetoAutomaticallyDetectHallucinationinLargeLanguageModels_0.png)

# 자동 환각 감지의 필요성

<div class="content-ad"></div>

커다란 언어 모델이 성숙해지면서 실제 응용 프로그램으로의 통합이 고갤 들고 여러 분야에서 가속화되고 있습니다. 고객 지원, 콘텐츠 생성 및 대화형 검색과 같이 영역들에서 말이죠. 그러나, 믿음성에 대한 새로운 도전들이 나타나고 있는 너머의 현실적인 실제 배치입니다. 엄격한 유효성 확인 보호장치 없이, 언어 모델의 추론에서의 오차는 절차적 무결성과 신뢰를 감안에 두다는 위험을 초래할 수 있습니다.

예를 들어, 자동 생성된 소셜 미디어 게시물의 잘못된 사건 정보나 사실은 조직의 신뢰성을 약화시킬 수 있습니다. 대화 인터페이스의 혼란스러운 사실은 사용자를 오도하고 믿을 수 없는 워크플로우를 야기시킬 수 있습니다. 이러한 사실적 왜곡은 충분하지 않은 세계 지식, 노이즈가 많은 학습 데이터 혹은 배포 분포와의 불일치에서 기인할 수 있습니다. 원인에 상관없이, 모델이 생성한 텍스트에서 발견되지 않은 환각은 가치 추가 목표를 약화시킬 수 있습니다.

측정 연구들은 학습 후 약점을 특성화하는 데 도움을 줍니다만, 우선순위는 운영적 설정에서 지속적인 검증으로 전환되고 있습니다. 그러나 도메인 전문가에 의한 수동 사실 확인은 대량 처리 제한사항이 있습니다. 동적 환각을 모니터링하는 자동화 메커니즘을 구축하는 것이 중요합니다. 실시간으로 진실에서의 편차를 추적하고 적절한 보안 기준을 정의하여, 언어 모델을 안전하게 배치할 수 있습니다. 이는 특화된 도메인에 맞춘 구조적 지식 하부기초가 필요하지만 말이죠. 다양한 Entity, 관계 및 시간적 사건을 포함하는 구조화된 지식을 잡는 것이 중요합니다.

좁은 도메인을 위한 철저한 확인 소스를 구축하는 것은 비용 및 지연의 장벽을 일으키기도 합니다. 다만, 최근 연구에 따르면 정제된 지식 그래프와 신경 언어 모델을 결합하면 사실성을 평가하고 지식 간격을 식별하는 데 도움이 되었음을 보여줍니다. 저지체 연결지 모델을 저지체 생산 파이프라인에 적용함으로써 자동환각 탐지 기능이 실현 가능해질 수 있습니다. 다음 절에서는 이러한 아이디어를 중심으로 한 접근 방식에 대해 자세히 설명하겠습니다. AI 애플리케이션에 대한 사용자의 신뢰를 유지하려면 신뢰성 있는 언어 모델을 강화해야 합니다. 앞으로의 길은 구조화된 지식을 신경 표현과 결합하여 이 원칙을 유지하는 데 있습니다.

<div class="content-ad"></div>

## 질문 응답 활용하여 감지 향상

KGLens 논문에서 제안된 흥미로운 기술은 도메인 지식 그래프를 자연어 질문 스위트로 자동으로 변환하여 언어 모델을 평가하는 것입니다. Entity-relation 엣지를 샘플링하고 질문 생성 모듈을 사용하여 사실 확인 및 사실 응답 평가를 다양한 구조화된 쿼리에서 사용할 수 있게 합니다.

이 질문 생성 전략을 확장하여 환각 탐지 파이프라인에 공급되는 입력을 다양화할 수 있습니다. 지식 그래프의 부분을 질문으로 재구성하여 평가하는 것은 LLM이 정확하게 응답하면서 인코딩된 사실과 일관성을 유지하는 추가적인 도전을 제공합니다. 다양한 질문 형식에 대한 LLM의 응답에 불일치가 있다면 사실적인 공백을 드러내는 데 도움이 됩니다.

특히, 모듈은 주기적으로 하위 그래프를 다시 샘플링하고 Yes/No 및 WH 형태의 자연어 질문을 생성하여 해당 entity 관계를 질의할 수 있습니다. 파이프라인은 이전과 같이 응답을 추출하고 지식 그래프와 일치시킵니다. 그러나 이제 모순은 오픈 엔드 추론 및 질문 응답 능력의 오류를 신호로 삼습니다.

<div class="content-ad"></div>

## 논리 규칙 통합

ChatRule 논문은 대규모 언어 모델로부터 엔티티와 이벤트 간의 논리 규칙을 유도하기 위해 프롬프트 기반 기술을 활용하는 방법을 보여줍니다. 이러한 심볼릭 규칙은 LLMs에서의 왜곡을 예측하고 설명하기 위한 해석 가능한 검증자 역할을 합니다.

도메인 지식 그래프를 컨텍스트로 사용하여 대상 LLM 자체에 프롬프트 기반 기술을 통해 채굴된 논리 규칙 공간을 분석할 수 있습니다. 프롬프트 템플릿은 규칙 제안을 생성하는 데 도움이 되며, 이들은 크라우드 소싱 필터링을 거칩니다. 검증된 규칙은 KG를 확장합니다. 실행 중에 규칙을 위반하는 인코딩된 규칙들로 거슬러 올라가 모순을 추적할 수 있습니다. 집계 통계는 어떤 논리적 제약이 자주 위반되는지를 나타냅니다. 이는 심볼릭 논리와 신경 표현을 혼합하여 설명력과 정밀도를 향상시킵니다.

# 핵심 아이디어

<div class="content-ad"></div>

큰 언어 모델에서 사실적인 모순을 감지하는 제안된 방법은 실행 시 비교 및 기초로 작동하는 도메인별 지식 그래프(KG)를 구축하는 것을 포함합니다.

지식 그래프는 연결된 네트워크를 통해 개념(엔티티)과 관계(술어)를 세 개씩 구조적으로 표현합니다. 키 엔티티에 대한 정리된 사실과 논리 규칙을 인코딩함으로써 고도로 특화된 KG가 만들어지며, 이는 특정 도메인을 아우르는 영역을 확장합니다. 예를 들어 의료 분야에서는 KG가 의약품, 부작용, 시간 간격, 용량 지침 등 온톨로지 기반 연결 사이를 담을 수 있습니다.

논리 규칙과 함께 KG를 보강하면 체계적 추론을 통해 범위를 확장할 수 있습니다. 도메인 텍스트로부터 연관성을 채굴하고 이를 Horn 절로 인코딩하면 새로운 사실적인 명제가 유도됩니다. 예를 들어 “상호 작용(X,Y) ∧ Y가 경고(Z)를 함 ⇒ X가 Z에 대해 경고한다”는 규칙은 추가적인 경고 부작용을 추론합니다. 이러한 규칙 기반의 향상은 유추될 수 있는 지식으로 KG를 보강합니다.

추론 시점에서 사용자 프롬프트는 큰 언어 모델(LLM) 응답을 호출합니다. LLM이 학습한 표현에서 동적 생성된 이 응답들은 정적 KG와 비교됩니다. 통사 분석 및 개체/관계 추출을 사용하여 LLM 응답에서 사실적인 명제가 추출되고, 개체는 정규화 기술(정확 일치, 동의어 매핑 등)을 사용하여 KG 어휘에 연결됩니다.

<div class="content-ad"></div>

마침내, 추출된 명제들을 KG에 대조하면 일치와 모순이 드러납니다. 일치는 적절하게 부호화된 지식을 나타내고, 모순은 잠재적인 환각을 가리킵니다. 여러 LLM 쿼리 교환을 통해 모순을 추적함으로써 사실적인 변화를 경험적으로 찾아낼 수 있습니다. 더 나아가, 규칙별 통계는 어떤 논리적 제약이 자주 어기지는지를 밝혀내어 설명력을 제공합니다.

이 방법론은 구조화된 지식과 신경 표현 학습을 섞어 연속적인 환각 모니터링을 합니다. 이후 섹션에서는 특수화된 KG 구축, 런타임 파이프라인 아키텍처, 그리고 이 방법을 다국어로 확장하는 방법을 설명합니다.

# 지식 그래프 구축

첫 번째 단계는 대상 도메인에 대한 중요한 엔터티와 관계에 대한 구조화된 데이터를 제공하는 적합한 지식 원본을 식별하는 것입니다. 위키데이터, DBpedia, ConceptNet과 같은 협력적인 지식 베이스와 도메인별 온타로지가 쿼리되어 관련 시맨틱 트리플을 추출합니다. 예를 들어, 약학 연구에서 기존 의료 온타로지는 다양한 약물, 단백질 상호작용, 질병 연관 및 부작용을 설명합니다.

<div class="content-ad"></div>

그 다음 집계된 사실들은 정보 정확성을 중점으로 신중하게 필터링하고 정리해야 합니다. 추출된 서브그래프 위에서의 제한된 랜덤 워크 같은 기술은 핵심 개체 중심의 제어된 확장을 가능케하면서 원본 분포의 대표성을 유지합니다. 랜덤 워크는 관련된 개체와 관계를 수집하면서 관련 없는 영역으로의 이동을 방지합니다. 통계적 메트릭은 인기 있는 지역 대 비군데를 식별하여 산산조각을 제거하는 데 도움을 줍니다. 소스 간의 통합으로 인한 모순들 또한 해결됩니다.

더 나아가, 주제 전문가들에 의한 수동 검토는 남은 오류와 오용을 제거합니다. 추가 사용자 입력은 문학 전반에 걸쳐 모호함을 명확히하여 정제된 시드 지식 그래프를 구성하는 데 도움이 됩니다. 그런 다음 눈에 띄는 관련성 주변의 도메인 논리 규칙을 Prolog, Datalog 또는 linear Horn clauses와 같은 논리 프로그래밍 언어로 수동으로 인코딩합니다. 이 추론 규칙은 새로운 유효한 명제를 추론함으로써 KG를 확장합니다. 예를 들어, 만약 바이러스 X가 조직 Y에 영향을 미치고 약물 Z가 바이러스 X를 표적으로 삼는다면, 약물 Z가 조직 Y의 영향을 치료한다는 규칙일 수 있습니다.

통계적 링킹과 인간 중심의 감독을 융합함으로써, 응용 도메인에서 사실 확인이 필요한 개체 및 관계에 집중한 고품질 KG가 생성됩니다. 시드 사실, 바인딩 및 추론을 포함하는 확장된 KG는 런타임에서 언어 모델 편차를 평가하는 데 기초가 되는 정답을 제공합니다. 이 특화된 KG의 세밀한 구축은 운영에 들어가기 전에 키 포인트입니다.

# 파이프라인 설계

<div class="content-ad"></div>

스케일 가능한 마이크로서비스 파이프라인은 사용자 입력을 받아 LLM 응답과 지식 그래프를 비교하여 환각을 감지하는 엔드 투 엔드 흐름을 처리합니다.

각 단계에 모듈식 구성 요소를 활용합니다:

- 사용자 입력 처리: 동시 요청을 처리하고 백엔드 LLM으로 경로 지정합니다.
- LLM 추론: 고용량 GPU 클러스터를 사용하여 입력에 대한 응답 생성합니다.
- 정보 추출: 주요 엔티티 및 관계의 관계형 트리플을 추출합니다.
- 엔티티 링킹: 추출된 엔티티를 지식 그래프의 노드에 매핑합니다.
- 그래프 추론: 그래프 패턴을 매칭하고 모순을 식별합니다.
- 환각 감지: 지식 그래프와 상충되는 응답을 식별합니다.
- 메트릭 추적: 시간 경과에 따라 정렬 메트릭을 계산합니다.
- 알림: 메트릭 임계값을 초과할 때 알림을 트리거합니다.

이러한 구성 요소를 통해 LLM 출력을 지식 그래프와 비교하여 자동화되고 확장 가능하며 계속된 환각 감시가 가능합니다.

<div class="content-ad"></div>

# 앞으로 나아갈 길

대형 언어 모델들이 빠르게 발전함에 따라 사실적인 지식과의 조화 유지는 계속 발전하는 과제입니다. 이전에 개요된 기술들은 구조화된 지식 그래프를 사용하여 환각을 모니터링하는 초기 프레임워크를 제공하지만, 각종 분야에서 보다 많은 연구가 필수적이며 견고하고 신뢰할 수 있는 언어 인공지능을 실현하기 위해 필요합니다.

오늘날의 주요 병목 현상은 전문 지식 그래프 및 인코딩 유효성 규칙의 수동적 구축에 대한 전문적 지식이 필요합니다. 변환 모델을 사용하여 논리 규칙을 생성함으로써 이 프로세스의 일부를 자동화할 기회가 있습니다. 예를 들어, 시드 그래프를 기반으로 한 소수의 프롬프트는 모델로부터 재귀적인 규칙 제안을 유도할 수 있습니다. 사용자 입력을 크라우드소싱하여 의미 있는 규칙을 걸러내어 보다 많은 지도 학습 신호를 제공할 수 있습니다.

그러나 수동적인 사실 수집에만 의존하는 것은 완전성 문제를 유발할 수 있습니다. 그래서 외부 데이터셋과 모델 추론으로부터 지식 그래프 자체를 계속 확장하는 것이 중요합니다. 그러나 이는 확장 가능성을 위해 그래프 분석을 최적화하는 것을 필요로 합니다. 상용 하드웨어를 통한 분산 저장은 데이터 수집 및 쿼리 속도를 높일 수 있습니다. 서버리스 아키텍처는 복잡한 탐색을 동적으로 확장할 수 있습니다.

<div class="content-ad"></div>

더 넓은 시각에서, 종합적인 프레임워크는 단순한 상징적인 삼중체나 규칙보다는 이미지, 비디오, 음성, 텍스트를 포괄하는 다중 형식 데이터를 통합해야 합니다. 지각 모듈을 이용한 씬 그래프 통합은 언어 해석 시 더 풍부한 맥락을 제공합니다. 시계열 데이터세트에서 얻은 인과 관계는 추론에 더 많은 제약사항을 부과합니다. 이러한 다중 감각적 지식을 사용한 기본 물리적, 사회적 직관을 모델에 포함하도록 하는 그라운드 러닝 목표는 모델에 가르치는 것입니다.

인간의 감독 역시 경험적인 응답을 사용하여 모델의 한계를 디버깅하는 데 중추적인 역할을 합니다. 사용자들로부터 생성물에 대한 평가를 요청하는 인터페이스는 정확도 조정을 위한 훈련 세트를 구축합니다. 피드백을 의미론적 파스 트리로 공식화하면 분포 조정을 통해 대상 매개변수 업데이트가 가능해집니다. 이러한 인간-인공지능 상호작용 사이클은 가치 일치를 중심으로 시간이 지남에 따라 개선을 확대합니다.

지속적인 진전은 다중 감각적 기저지식을 통합하는 상호간의 제 disciplin으로 가는 노력이 필요합니다. 신경-기호 연합과 인간지도학습을 통한 자동화된 향상을 통합하는 이 퓨전은 보다 견고한 언어 모델을 약속하며 세계 지식과 밀접하게 결합할 것입니다.

<div class="content-ad"></div>

대인관계 카드를 한 장 뽑아볼게요! 이번에는 'The Lovers' 카드가 나왔네요. 'The Lovers' 카드는 사랑, 동반자십, 결합의 의미를 가지고 있어요. 이 카드는 선택과 연결에 대한 중요성을 상기시켜 주는 에너지를 가지고 있답니다. 함께 일하는 동료나 파트너와의 관계에 주의를 기울이며, 서로의 의견을 존중하고 협력하는 데 초점을 맞춰보는 것은 어떨까요? 함께 한다면 더 큰 성취를 이룰 수 있을 거예요. 함께 일하는 모든 분들과 긍정적인 상호작용을 이어가길 바래요!
