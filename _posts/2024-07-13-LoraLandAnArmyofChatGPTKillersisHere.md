---
title: "LoraLand ChatGPT 경쟁 AI들의 등장"
description: ""
coverImage: "/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_0.png"
date: 2024-07-13 23:07
ogImage:
  url: /assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_0.png
tag: Tech
originalTitle: "LoraLand, An Army of ChatGPT Killers is Here"
link: "https://medium.com/@ignacio.de.gregorio.noblejas/loraland-an-army-of-chatgpt-killers-is-here-05630010b2c6"
isUpdated: true
---

오픈소스 세계가 기다려온 순간일까요? 기업들은 이에 주목해야 합니다.

여러분도 주목해야 합니다.

한 LLM 플랫폼인 Predibase가 기업 수준에서 하는 창조적 AI의 역사를 바꿀 수도 있는 모델 세트를 발표했습니다.

'로라랜드'라 불리는 이 작은 모델 세트는 다양한 하향 작업에서 ChatGPT(GPT-4 버전)보다 우수한 성과를 내며, 동시에 모든 모델을 동일 GPU에 배포할 수 있고, 평균 8달러만을 소비해 세밀한 조정을 할 수 있다고 하는데, 이는 매우 놀라운 소식입니다.

<div class="content-ad"></div>

새로운 장이 열립니다. 개인과 공개 모델 사이의 생성적 AI 전쟁에서, 오늘 당신이 시도하고 있는 새로운 장입니다.

# 가장 어려운 결정

다양한 작업에 사용할 수 있는 사전 훈련된 모델인 기반 모델이 등장하면서, 기업 AI의 불씨가 2022년에 정식으로 불이 붙었습니다.

## 고통스러운 여정

<div class="content-ad"></div>

이전에는 AI 적용이 어려운 과제였고 매우 위험했죠.

각 작업마다 특정 모델을 훈련시켜야 했고, 실패 확률은 Gartner에 따르면 거의 90%에 달했습니다.

하지만 이제는 AI가 이미 매우 우수한 기본 모델을 제공하며, 우리가 필요로 하는 작업에 맞게 조정해 주기만 하면 됩니다.

그러나 마지막으로, 결국은 Generative AI에서 가장 어려운 결정 중 하나인 올바른 LLM을 올바른 작업에 선택하는 데 모든 것이 달려 있습니다.

<div class="content-ad"></div>

하지만 처음 시작하시는 분들에게는 결정이 상당히 명확해 보일 수 있습니다.

### 자사 솔루션 대 오픈 소스

가장 인기 있는 벤치마크를 빠르게 살펴보면 ChatGPT, Gemini, Claude가 최고의 모델들임을 알 수 있습니다.

또한, 이러한 자사 솔루션은 큰 자본력을 가지고 있어 저렴한 가격을 제공할 수 있습니다. 그러나 이러한 자사 솔루션을 사용하는 데는 비용이 드는데, 그 비용은 경제적인 것이 아닙니다.

<div class="content-ad"></div>

이것은 예기치 않게 모델이 업데이트되어 배포를 다시 설계하게 만들 수 있음을 의미할 수 있습니다.

덤으로, 이 회사들이 당신의 기밀 데이터를 모델로 보내는 것을 하지 않을 걸로 신뢰해야 합니다.

반대로, LLaMa나 Mixtral8×7B 같은 오픈소스 모델은 일반적으로 품질이 낮지만, 모델에 절대적인 통제권을 부여합니다.

또한, 오늘날 기업에게 가장 중요한 자산인 기밀 데이터가 절대 유출되지 않는다는 보장이 있습니다.

<div class="content-ad"></div>

하지만, 다행히도 ChatGPT나 Gemini와 같은 앞선 개인 모델과의 품질 격차는 세밀 조정(모델을 특정 작업에 더 학습시키는 것)을 통해 좁힐 수 있습니다.

## 데이터가 가장 중요하며, 크기는 둘째

현재 오픈 소스 모델은 실제로 뒤처져 있지만, 특정 작업에 충분한 세밀 조정을 하면 오픈 소스 모델의 성능을 ChatGPT가 제공하는 것 이상으로 향상시킬 수 있습니다.

그러나 이 작업에 전통적인 방식으로 접근할 때 발생하는 문제는 두 가지입니다:

<div class="content-ad"></div>

- 파인튜닝의 절충안. 특정 하류 작업에 대한 파인튜닝은 지식 잊기로 인해 모델의 일반성을 희생시킵니다.

2. 비즈니스 케이스가 변경되었습니다. OpenAI가 제안하는 토큰 당 가격 대신, LLM 공급 업체는 이제 전용 인스턴스에 대한 요금을 청구할 것입니다. 왜냐하면 파인튜닝된 모델은 독립적이고 전용 GPU 모델/클러스터에서 실행되어야 하며, 이는 더 비싸기 때문입니다.

그러므로 파인튜닝이 대부분 기업용 사례에서 이상적인 경우라도, 일반적으로 한 가지 작업에서 최고의 성능을 요구하는 경우에는 가격이 지나치게 비쌉니다.

하지만 Predibase의 발표로 상황이 변했습니다.

<div class="content-ad"></div>

# 전문가들의 군단

어쩔 수 없어요. Predibase의 성취는 정말로 이해하기 어렵네요.

사실, 그들은 불가능을 달성한 것 같아요: 최고의 모델들보다 우월한 모델을 비용 효율적인 방법으로 제공하고 있어요.

구체적으로, Mistralx7B의 25가지 세심하게 조정된 버전을 출시했는데, 이 버전은 특정 작업에 있어 ChatGPT의 가장 고급 버전보다 우수한 성능을 보여주고 있어요. 그것도 수백 배나 작은 크기라는 점에서 말이죠.

<div class="content-ad"></div>

![image](/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_0.png)

They have achieved success by focusing on two key aspects:

- Fine-tuning with QLoRA
- Deploying with LoRAX

## QLoRA, Quantized low-ranking fine-tuning

<div class="content-ad"></div>

QLoRA는 현재 모델을 세밀하게 조정하는 가장 핫한 방법 중 하나입니다. 여기에는 두 가지 측면이 관여됩니다:

- 양자화(Quantization): 여기서는 메모리에 저장된 매개변수의 정밀도를 줄입니다. 이것은 모델의 매개변수를 0.288392384923과 같은 완전한 정밀도로 저장하는 대신 반올림하여 0.3과 같이 저장함을 의미합니다. 자명하게도 메모리 요구 사항을 줄이기 위해 반올림 오류가 발생합니다.

- LoRA 세밀 조정: 여기서는 어댑터를 추가하여 네트워크를 최적화하고 가중치의 작은 부분만 세밀하게 조정할 수 있습니다.

후자에 대해서, 아이디어는 간단합니다: 세밀 조정에 대한 전통적인 접근 방식은 네트워크의 모든 매개변수를 업데이트하여 새 데이터 세트에서 모델을 훈련하는 것인데, 이는 수십억 개의 매개변수를 여러 번 업데이트하는 것을 고려하면 매우 비용이 많이 듭니다.

<div class="content-ad"></div>

하지만 그게 무슨 의미이고 왜 그렇게 중요한 걸까?

행렬의 순위란 선형 독립인 행 또는 열의 최소 개수를 의미합니다. 다른 행이나 열을 결합하여 이들을 재구성할 수 없다는 것을 의미합니다.

간단히 말해, 행렬 내 정보 중복의 척도를 나타내며, 선형 종속적인 행/열은 추가 정보를 제공하지 않는다는 것을 의미합니다.

그렇다면 우리는 어떻게 해야 할까요?

<div class="content-ad"></div>

우리는 모델의 가중치 행렬을 가져와 그것을 낮은 순위의 등가물 형태로 표현하는 두 개의 행렬로 분해합니다.

아래에서 보듯이, 우리는 5x5 행렬을 2x5와 5x2 행렬로 분해할 수 있습니다 (이 특정 행렬의 순위는 2입니다).

![image](/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_1.png)

결과적으로 우리는 전체 크기의 행렬을 업데이트하지 않고, 낮은 순위의 행렬을 업데이트하여 파라미터 업데이트 수를 25에서 10으로 줄입니다 (이 특정한 경우).

<div class="content-ad"></div>

이것은 대부분의 경우 LLM이 주어진 작업에 필요한 것보다 훨씬 더 많은 매개변수(가중치)를 가지고 있기 때문에 잘 작동하는 것입니다. 이는 동일한 결과를 얻기 위해 전체 행렬을 업데이트할 필요가 없고 중요한 가중치 부분만 업데이트하면 되기 때문입니다.

이 혜택은 매우 잘 쌓이는데, 아래 이미지에서 확인할 수 있듯이, 랭크가 512인 경우에도(이전에 본 2와 비교했을 때) 모델의 총 가중치 중 1.22%만 업데이트하면서 최상의 개선을 얻을 수 있습니다.

![image](/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_2.png)

하지만 여전히 가장 큰 문제에 직면하고 있습니다: 모든 파인튜닝된 모델은 전용 GPU가 필요한 것이 맞나요?

<div class="content-ad"></div>

당신이 그것을 성실히 따른다면, 그것은 세밀하게 조정된 모델의 목적을 무시하는것이 되버릴 것입니다.

하지만 여기서 LoRAX가 등장합니다.

## 하나의 GPU, 100개의 LLMs

LoRAX의 아이디어는 각 어댑터가 고유한 가중치를 기존의 변경되지 않은 모델에 추가할 때, 세밀하게 조정된 버전에 사용되는 한 해당 모델의 베이스 가중치가 변경되지 않는다는 것입니다. 모든 세밀하게 조정된 모델이 같은 기본 모델에서 나온다면. 여기서는 Mistralx7B이지만, (당신이 상상할 수 있듯이) 이는 LLM에 중립적입니다.

<div class="content-ad"></div>

LoRAX(로랙스)가 가능하게 하는 것은, 사용자가 보내는 요청의 종류에 따라 동적으로 로드되고 삭제되는 세트의 세밀하게 조정된 모델인 어댑터를 효율적으로 관리하는 것입니다:

![이미지](/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_3.png)

간단하게 말하자면, 사용자가 보내는 다양한 요청에 따라 모델은 어떠한 어댑터가 각각의 경우에 요구되는지 자동으로 감지하고, 해당 어댑터의 가중치를 베이스 모델에 로드합니다.

![이미지](/assets/img/2024-07-13-LoraLandAnArmyofChatGPTKillersisHere_4.png)

<div class="content-ad"></div>

비용 총합은 어떻게 되나요?

평균 가격으로 약 200달러(1회 조정당 8달러)를 쓰면, 개별적으로 GPT-4를 이길 수 있는 25개의 모델 세트를 한 대의 A100 GPU에서 실행하면서 모델을 총괄할 수 있는 모든 장점을 누릴 수 있습니다.

## 오픈 소스의 '이 순간'?

이 모든 것은, 말 그대로, 고객과 기업 모두에게 꿈 같은 현실이 될 것입니다. 경제적으로 실용적이면서도 특정 작업의 최고 성능을 제공하는 LLM을 구현하여 두 마지막 동시에 달성하는 것이죠.

<div class="content-ad"></div>

실제로, PrediBase는 우리에게 기업용 GenAI의 미래를 엿본 것일지도 모른다. 그냥 눈을 돌릴 수 없을 정도로 오픈 소스가 기업들이 GenAI 혁명을 받아들일 수 있는 주요 솔루션으로 갈수록 어려워지고 있기 때문입니다. PrediBase를 사용하든 다른 여러 LLM 플랫폼을 사용하든, 이제는 그들이 제공하고 있는 품질/가격 비율을 고려해야 합니다.
