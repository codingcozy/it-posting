---
title: "SLAM을 활용한 자율 주행 3D 프린팅 로봇 만드는 방법"
description: ""
coverImage: "/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_0.png"
date: 2024-07-06 10:51
ogImage:
  url: /assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_0.png
tag: Tech
originalTitle: "Building a 3D-printed robot that uses SLAM for autonomous navigation"
link: "https://medium.com/@pliam1105/building-a-3d-printed-robot-that-uses-slam-for-autonomous-navigation-cd83473dac7c"
isUpdated: true
---

## Jetson Nano, Arduino 및 ROS 2의 Nav2 라이브러리를 사용하는 자율 로봇

이전 게시물에서 SLAM (Simultaneous Localization and Mapping)에 대해 얘기했었죠. 그것이 어떻게 작동하며 다양한 분야에서의 엄청난 잠재력에 대해 언급했습니다. 로봇이 알 수 없는 지역에서 자신의 위치를 확인할 수 있는 방법인데요, 이는 사람이 하는 방식과 비슷합니다. 환경의 독특한 특성을 기록하고 모터와 다른 센서(보통 LiDAR)에서의 데이터를 결합하여 지도를 만들고 해당 위치를 추정합니다. 알고리즘의 작동 방식에는 방대한 수학적 배경이 있지만 이를 이해하면 매우 유익할 수 있습니다 (심화 학습을 원하신다면 확률 로보틱스를 확인해보세요).

그러나 만들기를 좋아하는 창조주시다 보니 프로젝트를 만들기에 엄청난 열정이 있어서, 이를 직접 체험하고 다양한 가능성을 탐구하며 유용한 것을 만드는 방법을 찾고 싶었습니다. 첫 번째 단계는 로봇을 만드는 것이죠.

프로젝트의 완전한 기술 사양 및 코드를 GitHub에서 확인할 수 있습니다: [GitHub 링크](https://github.com/pliam1105/3D-Printed-ROS-SLAM-Robot)

<div class="content-ad"></div>

# 로봇 만들기

로봇을 처음부터 만드는 것은 처음이었어요. 지금까지 제가 다뤄온 로봇의 샤시에 대해서는 DIY 키트의 기계 부품들을 조립한 후 전자 부품을 통합해 왔기 때문에, 새로운 경험이었어요. 하지만 오랫동안 기다렸던 경험이었어요. 샤시를 디자인하고 만들고, 모터, 엔코더, 배터리, 레귤레이터 등 이 모든 필요한 전자 부품들에 대해 연구하고 조립하며 생기는 모든 문제를 스스로 해결해 보고 싶었거든요. 이 과정은 제가 공학과 프로젝트를 사랑하고 학습 경험으로 활용하는 이유입니다.

전자 부품에 대한 계획은 다음과 같아요:

<div class="content-ad"></div>

- ​NVIDIA Jetson Nano를 주요 마이크로컨트롤러 보드로 사용하여 그래픽 카드를 비롯한 높은 성능 덕분에 카메라를 통합하고 나중에 AI 기능을 추가하고 싶어서 선택했어요.
- ​Arduino Mega는 모터 제어와 인코더 속도 측정을 담당하며, Jetson Nano와 빈번히 통신해야 하는데, 이를 위해 시리얼 USB로 연결했어요.
- ​RPLiDAR A1은 SLAM 구현에 필요한 Jetson Nano에 센서 데이터를 제공해요.
- ​​기어 비율(19.2:1)과 메커니즘이 높은 토크와 낮은 속도를 제공하는 12V DC 플래니터리 기어 모터 2개가 있어서 우리가 필요한 것과 정확히 일치해요.
- ​2개의 BTS7960 모터 드라이버는 아두이노에서 PWM 펄스를 통해 모터를 제어해요.
- ​속도를 제어하고 SLAM에 필요한 오도메트리 데이터를 제공하는 2개의 점증 회전 인코더가 있어요.

모터의 전원을 공급하기 위해 12V 리튬 폴리머 배터리(3S)를 사용했고, 조절 가능한 스텝-다운 모듈을 통해 5V로 설정된 후, 인코더에도 전원을 공급했어요. Jetson Nano가 이동 중일 때는 전원 은행을 사용하여 전원을 공급했고, 아두이노는 Jetson Nano로부터 USB로 전원이 공급되었어요.

부품 구하는 것은 약간 귀찮았어요. 작은 배송 시간으로 인코더, 배터리 및 다른 모든 전자 부품을 찾을 수 있었지만, 모터는 UK에서 와야했어요. Brexit 및 관세 변경으로 첫 번째 세트가 사라진 후 (두 번째 세트가 도착했어요), 한 달 후 도착했어요. 이상적이진 않았어요.

그동안 Fusion 360을 사용하여 구성 요소 설계에 착수했어요. 인터페이스와 워크플로우 (스케치, 구성 요소 및 다양한 도구)에 익숙해지고, 온라인 자습서의 유익한 팁을 통해 빠르게 적응했어요.

<div class="content-ad"></div>

'''
/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_1.png

나는 모터와 엔코더 마운트, 플랫폼, 기어, 그리고 각각의 로봇 측면에 대한 바퀴 설계를 시작했어 (이는 같은 디자인을 수평으로 180° 회전한 것이었어). 그런 다음 이것들을 알루미늄 익스트루전과 결합하여 일목요연하게 조립해보았고, 로봇이 넘어지지 않도록 캐스터 휠 마운트를 추가했으며, LiDAR와 전자기기가 위치할 더 높은 플랫폼을 만들었고, 이것들을 아래의 익스트루전 부분들과 4개의 부품으로 연결했어.

이 과정에서 나는 측정용 캘리퍼와 온라인 사양을 사용하여 부품의 치수를 확인하고, 완벽하게 조립될 수 있는 정확한 디자인을 만들 수 있었어. 다행히도 이 작업은 의도한 대로 잘 마무리 되었고(전압 조절기 구멍을 제외하고), 조립 중 확인할 수 있었어.

디자인을 마친 후에는, 3D 프린터가 유용하게 사용될 때가 드디어 왔어. 나는 약 5일(아니면 일주일)이 걸려서 모든 부품들을 인쇄했어. PETG 필라멘트를 1kg 미만 사용했고 (퓨전에서 정렬 오류를 범해 다시 프린트해야 했던 바퀴들도 추가로 인쇄). 그 당시에는 모터가 아직 도착하지 않았기 때문에, 조립에 필요한 나사, 너트, 막대, 축, 스페이서를 구입 중이었고 (생각보다 필요한 양이 더 많다는 것을 깨달아서 여러 차례 주문을 했었어). 마침내, 모터가 도착하여 조립이 시작되었어.
'''

<div class="content-ad"></div>

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_2.png

저는 모든 기계 부품을 조립하고 일렉트로닉스를 장착했어요 (처음에는 상부 플랫폼을 잘못된 쪽에 놓아서 한 번 더 장착했고, 구멍이 틀렸다는 것을 깨달았어요). 그런 다음 모든 부품을 연결하기 위해 살코기로 작업을 해야 했지만, 결국 하드웨어 부분을 완료하고 코딩 작업에 들어갈 준비가 되었어요.

# 모터와 엔코더 제어

먼저, 아두이노가 엔코더 속도를 측정하고 런타임에서 지정된 속도로 모터를 이동시키도록 하기 위해 필요했어요. 먼저, 모터 드라이버에 일정한 PWM (펄스 폭 변조, 디지털 장치에서 아날로그 신호를 모방하는 방법) 펄스를 제공하여 모터 속도를 제어하는 방법을 알아냈어요 (기본적으로 현재는 전압에 해당하고, 나중에 정확한 속도로 이어질 거예요).

<div class="content-ad"></div>

![image](https://miro.medium.com/v2/resize:fit:800/0*GRzvHgMFb158MtSZ.gif)

저는 엔코더의 작동 방식도 배웠고, 핀 A와 B의 펄스를 기반으로 속도를 측정하는 방법을 구현했습니다. 아래 이미지에서 시각적이고 직관적인 설명이 제공되며, 코드로 간단하게 변환되어 핀 A가 신호를 LOW에서 HIGH로 변경할 때(상승 신호 = 펄스) 인터럽트를 부착하고 B 신호를 확인하여 방향을 결정합니다.

![image](https://miro.medium.com/v2/resize:fit:1142/0*CNieScOmQdpIFYbs.gif)

속도를 측정하기 위해 일정 시간 간격 동안의 펄스 수를 해당 간격으로 나누고, 펄스/밀리초에서 미터/초로 변환합니다. 이 마지막 부분에서 미터를 펄스로 변환하는 것이 필요했는데, 이를 위해 측정 테이프를 사용해 로봇을 이동시키고 기록된 펄스 수를 확인했습니다(이후 측정된 속도가 PID 컨트롤러의 목표 속도와 일치하지 않아 펄스 수를 수정했습니다).

<div class="content-ad"></div>

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_3.png

지금은 두 부분이 준비되었습니다: 모터 전압 제어(출력)와 그들의 속도 측정(입력). 각 순간 원하는 속도로 모터를 움직이기 위해서는 이 둘을 연결해야 합니다. 이때 PID(비례, 적분, 미분) 컨트롤러가 필요합니다. 이는 입력이 특정한 설정값에 도달하도록 출력을 조정하는 닫힌 루프 컨트롤러입니다. 작동 방식은 입력 - 설정값의 오차를 가중치 KP와 곱한 것, 이전 오차의 합을 시간으로 나눈 적분에 KI를 곱한 것, 이전 오차와 이전 오차의 차이를 시간 차이로 나눈 미분에 KD를 곱한 것을 합하여 출력을 만듭니다.

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_4.png

이를 위해 PID_v1 Arduino 라이브러리를 사용했고, KP, KI, 그리고 KD 매개변수를 조정하여 원하는 속도로 부드럽게, 짧은 시간 내에 이동하고 그것에서 벗어나지 않도록 이루어졌습니다.

<div class="content-ad"></div>

하지만 ROS에서 오는 속도 명령은 그 형식(왼쪽 바퀴 속도 및 오른쪽 바퀴 속도)으로 오지 않습니다. 대신에 선형 및 각도 구성 요소로 제공되는데, 이를 계산해야 합니다. 아래에 표시된 대로요.

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_5.png

# Arduino와 ROS 연결하기

이 프로젝트는 주로 ROS(로봇 운영 시스템)에 의존하여 여러 부분을 연결합니다. ROS는 서로 다른 구성 요소(노드)가 함께 작동할 수 있는 프레임워크로, 각 구성 요소가 다른 기능을 달성합니다. 실제로 운영 체제는 아니지만 Ubuntu에서 실행됩니다(저는 Jetson Nano와 PC에 모두 ROS 2 Foxy와 Ubuntu 20.04를 설치했습니다).

<div class="content-ad"></div>

## 아두이노와 젯슨 나노 간의 통신

시스템의 나머지 부분과 아두이노를 연결하기 위해, 아두이노와 젯슨 나노 사이에 시리얼을 통해 데이터를 전송하는 노드인 arduino_serial을 만들어야 했습니다. 데이터 통신이 양방향으로 이루어져야 하며 바이트 버퍼로 작동하기 때문에, 프로토콜과 두 장치 간의 데이터 전송을 동기화하는 방법이 필요합니다.

프로토콜 부분에서, 아두이노 측에서는 SerialTransfer 라이브러리를 사용했고, 젯슨 나노 측에서는 이에 대응하는 파이썬 라이브러리인 pySerialTransfer를 사용했습니다. 두 라이브러리는 변수 및 컨테이너(예: 구조체)를 바이트 버퍼로 변환하고, 시리얼을 통해 정확한 데이터 전송을 보장합니다.

그러나 서로 다른 주기로 동작하는 두 장치 간의 데이터 전송을 동기화하는 것은 조금 문제가 있었습니다. 이를 비동기적으로 수행할 수는 없으므로 (만약 두 개의 시리얼이 있지 않다면), 다양한 방법을 시도한 끝에 다음과 같이 동작하는 방법을 결론 내렸습니다:

<div class="content-ad"></div>

- 아두이노와 제트슨 나노 프로그램의 시작 시점에서 핸드셰이크를 성취하고 싶어요. 즉, 제트슨 나노에서 메시지를 시도하고 아두이노로부터 응답을 받는 메세지 시퀀스를 말해요. <br>
- 제트슨 나노 각 사이클마다, 먼저 속도 명령을 보내고, 그 후 아두이노로부터 엔코더 속도를 받기를 기다립니다. <br>
- 아두이노 측에서는, 먼저 속도 명령을 받고, 그 후 엔코더 속도를 보내줍니다.

그 작업을 가능케 한 중요한 포인트 중 하나는 새 데이터가 없더라도 데이터를 계속 전송하는 것이었어요 (가능한 경우 가용한 최신 데이터를 전송하도록), 그렇지 않으면 받은 데이터와 보낸 데이터를 매칭하는 데 여러 문제가 발생할 수 있어요.

## 제트슨 나노에서 데이터 게시 및 수신

제트슨 나노에서 실행되는 아두이노 시리얼 노드는 아두이노와 대화하며 시스템의 나머지 부분과 통신해야 해요. 이는 ROS를 사용하여 주제를 통해 수행됩니다. 노드는 주제를 게시하거나 구독하여 데이터를 보내거나 받을 수 있어요. 이 경우, 노드는 cmd_vel 주제를 구독하여 속도 명령을 받고(odometry topic으로 옳바른 형식을 사용하여) odom 주제를 게시하여 오도메트리 데이터(예상 속도와 위치/방향)를 전달해야 해요.

<div class="content-ad"></div>

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_6.png

또한 ROS에는 변환(transforms)이라는 것이 있는데, 이는 한 좌표 프레임에서 다른 좌표 프레임으로 데이터 세트(좌표계의 점들)를 변환하는 역할을 합니다. 위치추정 및 맵핑을 위해 3가지 중요한 프레임이 사용됩니다:

- map은 로봇의 실제 환경을 나타내는 프레임으로, 정지 상태를 가정합니다.
- odom은 로봇의 시작 위치에 대해 고정된 프레임으로 로봇의 오도메트리 위치 추정을 나타내기 위해 사용됩니다.
- base_link은 로봇의 위치를 나타내는 프레임입니다.

map에서 odom 변환은 저는 나중에 설명할 Localization 노드에 의해 계산됩니다만, 이 변환은 오차(드리프트)가 있는 오도메트리 데이터와 센서 데이터 간의 시간에 따른 정렬을 보여줍니다.

<div class="content-ad"></div>

내가 직접 구현해야 하는 것은 추정된 현재 위치와 방향과 초기 위치와 방향의 차이를 나타내는 odom to base_link 변환입니다.

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_7.png

따라서 우리가 아두이노로부터 획득하는 엔코더 속도로부터 유도해야 하는 두 가지 측면은 선속도 및 각속도, 그리고 위치와 방향입니다.

나는 다음의 공식을 사용하여 (선속도, 각속도) 성분을 계산합니다:

<div class="content-ad"></div>

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_8.png

또한, 왼쪽 및 오른쪽 바퀴 속도를 시간적분하여 추정 위치 및 방향을 계산하기 위해 다음 공식을 사용했어요(각 시간 단계마다 새로운 인코더 데이터를 적용):

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_9.png

저는 로봇을 teleop_twist_keyboard를 사용하여 방 안을 움직이면서 속도 명령 전송 및 오도메트리 자세 추정을 테스트했고, LiDAR 데이터의 드리프트(아래에서 설명할 것)를 고정 좌표 프레임(odom)에 대해 시각화하여 RViz 2(ROS 2에서 제 PC에)를 통해 확인했어요. 이를 통해 Jetson Nano와 아두이노 간의 통신 및 올바른 데이터 전송이 작동하고 SLAM을 사용하여 로봇이 작동하는 것을 확인할 수 있었어요.

<div class="content-ad"></div>

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_10.png

# 동시적 위치추적 및 지도매핑 통합

모든 상기 부품들이 함께 LiDAR와 연결되어 영역을 매핑하고 로봇을 지역에서 찾을 수 있는 부분입니다. 하지만 먼저, LiDAR을 ROS와 통합해야 합니다. RPLiDAR ROS 라이브러리 덕분에 이 과정은 노드를 실행하고 스캔 토픽의 메시지를 확인하는 것만으로도 쉽게 할 수 있습니다. 이를 RViz 2에서 시각화할 수도 있습니다.

/assets/img/2024-07-06-Buildinga3D-printedrobotthatusesSLAMforautonomousnavigation_11.png

<div class="content-ad"></div>

그러나 SLAM에 대해 논의하기 전에 몇 가지 더 설정해야 할 사항이 있습니다. 앞서 언급했듯이, ROS는 변환을 사용하여 작업 좌표를 조정하며, 이를 통해 한 프레임에서 다른 프레임으로 좌표를 변환할 수 있습니다. 이것은 로봇 구성 요소 간이나 로봇 상태 게시자 및 조인트 게시자 노드 사이에서도 수행할 수 있습니다. 로봇 상태 게시자는 서로 다른 로봇 구성 요소 간의 관계를 나타내기 위해 조인트를 사용합니다. 예를 들어, base_link 프레임(로봇 중심)에서 LiDAR 데이터가 사용하는 레이저 프레임으로 이동하는 데 필요한 변환 및 회전과 같은 것입니다. 이러한 조인트를 URDF(Unified Robot Description Format) 파일(기본적으로는 확장된 XML 파일)에 저장하고 로봇 상태 게시자 노드를 사용하여 게시합니다. 또한 조인트 상태(예: 바퀴의 방향)를 joint_state_publisher 노드를 사용하여 게시하며(그리고 GUI를 사용하여 변경할 수도 있습니다).

로봇에서 마침내 SLAM을 구현할 수 있습니다. 이를 위해 slam_toolbox를 사용하며, 해당 주제 및 변환을 구독하고 오도메트리 및 센서 데이터를 결합하여 지역의 지도를 생성하면서 로봇의 위치를 추정합니다.

<div class="content-ad"></div>

이 프로젝트에 추가 기능으로, 로봇이 자율적으로 특정 목표/지점으로 이동하도록 할 것입니다. 이는 다양한 회전 및 이동 기능에 필요한 다양한 노드를 포함하는 navigation2 패키지를 사용하여 구현됩니다.

본 목적을 위해, 먼저 노드는 이전에 계산된 지도(또한 지속적으로 업데이트됨)를 취하여 특정 영역을 탐험하는 데 얼마나 위험/안전한지를 나타낼 수 있는 비용 함수 형태로 변환합니다. 그런 다음, 플래너 노드는 해당 비용 지도를 취하여 목표 달성을 위한 가장 효율적인 경로를 계산하고, 컨트롤러 노드는 해당 경로를 로봇에게 전달하여 위에서 설명한 속도 명령으로 변환합니다. 또한, 로봇이 불확실하거나 위험한 상황에서 회복할 수 있도록 다양한 백업 노드도 있습니다. 상기 모든 노드는 새로운 지도 및 위치가 계산될 때마다 업데이트됩니다.

# 로봇 동작 중

<div class="content-ad"></div>

여기 제 PC에서 보낸 목표지점으로 로봇이 제 방 안을 맵핑하고 탐색하는 GIF가 있어요:

![로봇 맵핑 및 내비게이션](https://miro.medium.com/v2/resize:fit:1200/1*Qm9YiXyYScnDA8q4b0atcQ.gif)

# 결론

이 프로젝트를 실행하는 동안 달성한 목표를 요약해보겠습니다:

<div class="content-ad"></div>

- 로봇 샤시를 처음부터 디자인하고 제작하였으며 모든 전자 기기를 배선했습니다.
- 모터 제어 방법 및 인코더 속도 측정 방법을 파악하고, 인코더를 펄스에서 미터로 교정하였으며, PID 컨트롤러를 조정하여 필요에 따라 일정한 속도를 유지했습니다.
- 아두이노와 젯슨 나노 간의 양방향 시리얼 통신을 구현하고, 인코더 속도를 원하는 오도메트리 위치 및 속도 추정값으로 변환했습니다.
- ROS에 대해 학습하고, 위의 기능을 시스템의 나머지 부분과 통합할 노드를 작성했습니다.
- LiDAR 노드를 통합하고, 로봇 및 관절 상태 게시자를 설정하고, SLAM 및 Navigation 노드를 통합하여 자율 주행을 달성했습니다.

이것은 우리 삶의 다양한 측면에서 유용한 작업을 수행할 수 있는 로봇을 만드는 첫걸음입니다. SLAM은 로봇의 모든 다른 기능이 의존하는 기반입니다. 로봇은 자신이 어디에 있는지 알아야 하기 때문입니다. 따라서 다음 단계는 이 프로젝트에 유용한 목적을 탐색하고 그것들을 적용하는 것입니다. 로봇에 카메라를 추가하고, 젯슨 나노의 향상된 AI 기능을 활용하며, 주변 환경과 상호 작용하기 위한 조작기와 종단 부위를 추가하는 것을 고려 중입니다.

내 뉴스레터에서 매월 업데이트(다음 단계 프로젝트에 대한 작업 포함)를 확인하실 수 있습니다: https://panagiotisliampas.substack.com/
