---
title: "원인 추론을 위한 LLM 활용 지식과 알고리즘이 중요한 이유"
description: ""
coverImage: "/assets/img/2024-07-12-LeveragingLLMsforCausalReasoningWhyKnowledgeandAlgorithmsareKey_0.png"
date: 2024-07-12 23:44
ogImage:
  url: /assets/img/2024-07-12-LeveragingLLMsforCausalReasoningWhyKnowledgeandAlgorithmsareKey_0.png
tag: Tech
originalTitle: "Leveraging LLMs for Causal Reasoning: Why Knowledge and Algorithms are Key"
link: "https://medium.com/gopenai/leveraging-llms-for-causal-reasoning-why-knowledge-and-algorithms-are-key-d1928b7051c7"
isUpdated: true
---

인공 지능 소프트웨어가 이 기사의 텍스트를 개선하여 문법, 흐름, 가독성을 향상했습니다.

인과 추론 - 인과 관계를 이해하고 개입에 대한 추론을 하는 능력 -은 지능에 근본적입니다. 이는 결과를 예측함으로써 의사 결정을 뒷받침합니다.

이 능력은 오랫동안 인간에게만 고유한 것으로 여겨졌으며, 다양한 현실 세계 개념과 관련된 정교한 인과 모델을 개발하기 위해 수년간의 경험이 필요했습니다.

그러나 현재 인공 지능이 어떤 인간 능력과 일치하려고 하는 점에서, 특히 고도의 일반화된 지능의 상징인 인과 인식을 복제하는 데 집중이 집중되고 있습니다.

<div class="content-ad"></div>

AI 시스템은 물리적 세계에서의 경험이 부족하기 때문에 인과 관계에 대해 추론할 수 있을까요?

최근 대형 언어 모델에서 원인과 결과에 대한 흥미로운 성능이 나타나고 있습니다. 이러한 모델들은 텍스트 데이터만으로 자가 감독 학습을 통해 훈련되었습니다.

자연어 텍스트로 설명된 사건들에 대한 안내를 받은 경우, 이러한 시스템들은 진술 쌍 간의 인과 관계를 평가하는 데 사람과 유사한 판단력을 나타내며 높은 정확도로 작동합니다.

일부 모델은 미학습 인간과 견줄 만한 역량으로 필요한 또는 충분한 원인을 결정할 수도 있습니다.

<div class="content-ad"></div>

이러한 발전은 미래에 AI 어시스턴트들이 전문가들에게 복잡한 원인과 결과를 고려한 결정을 내리도록 조언하고, 사회 정책들이 시행 전 AI 생성 평가를 고려하며, 개인 에이전트들이 개인 맥락과 선호도에 따라 맞춤형 원인 모델을 사용하여 추천을 제공하는 미래를 보여줍니다.

그러나 이러한 비전을 완벽히 실현하려면 순수 언어 모델 기반 접근의 한계에 직면해야 합니다.

진정으로 신뢰할 만하고 다재다능한 실제 세계의 원인 규명이라면 언어 모델이 제공하는 유동적인 추론 능력과 구조화된 세계 지식 및 견고한 원인 지능을 통합해야 합니다. 이는 부분들의 합보다 더 강력한 원인 지혜가 됩니다.

이 글은 왜 언어 모델을 지식 그래프와 전문 알고리즘과 결합하는 것이 확장 가능하고 실용적인 AI 원인 추론을 위해 필수적이며 모호함에 대처하고 맥락을 이해하며 동적으로 추론하며 궁극적으로 기계 주도의 원인 지혜로 인간의 결정을 향상시킬 수 있는지 설명합니다.

<div class="content-ad"></div>

![Language Model Causal Reasoning](/assets/img/2024-07-12-LeveragingLLMsforCausalReasoningWhyKnowledgeandAlgorithmsareKey_0.png)

# 언어 모델의 인과 추론의 약속

이 논문 '인과 추론과 대규모 언어 모델'은 올바른 프롬프팅을 통해 LLMs가 다양한 인과 관계 작업을 위한 새로운 능력을 보여준다는 것을 보여줍니다:

- 인과 관계: GPT-3와 PaLM은 텍스트로 설명된 변수 쌍 사이의 확률적 원인-결과 관계를 결정하는 데 약 97%의 정확도를 달성합니다.
- 반사실적 추론: GPT-4는 벤치마크 반사실적 예측 작업에서 92%의 정확도를 달성하여 인간의 성능에 근접합니다.
- 필연적 원인 식별: GPT-4는 인과 소설들에 걸쳐 특정 이벤트가 다른 이벤트의 필요 원인인지를 평가하여 86%의 정확도를 달성합니다.

<div class="content-ad"></div>

LMPriors는 언어 모델을 조정하여 변수 이름 및 설명 메타데이터에서 올바른 인과 판단을 학습할 수 있다는 것을 성공적으로 보여주고 있습니다:

- 그들의 방법은 어려운 인과 그래프 예측 과제의 데이터셋에서 89%의 정확도를 달성하며 기본 방법보다 크게 개선되었습니다.
- 이는 맥락 속 메타-러닝을 보여주는데, 메타데이터 설명에서 인과 관계를 배우는 것입니다.

게다가, 논문 '실수가 있는 전문가로서 언어 모델을 사용한 인과 발견'은 LLMs가 사전 훈련만으로도 적극적으로 인과 지식을 축적했다는 증거를 제공합니다:

- LLMs는 등가 인과 그래프에서 엣지를 정확하게 지향하여, 발견 알고리즘만 사용하는 것보다 구조적 불확실성을 15–25% 감소시킵니다.
- 모델의 판단은 불완전하지만 여전히 유용한 지식 원천으로 작용하여 인과 그래프를 개선하는 데 사용됩니다.

<div class="content-ad"></div>

상이한 추론 작업에서의 일관된 높은 성능은 LLMs의 일반적이고 맥락 속 인과적 학습 능력을 보여줍니다. 이러한 능력은 텍스트 훈련 데이터에서의 패턴에 노출되어 얻어졌습니다.

추가 훈련 없이 단지 프롬프트 지침만으로 빠른 적응을 보이는 이 능력은 인간 중심의 인과 분석에 사용될 수 있게 합니다.

# 외부 지식의 필요성

대형 언어 모델은 내제적으로 훈련 데이터로부터 추출된 방대한 세계 지식을 내포하고 있지만, 이 지식에는 한계가 있어 추론 능력이 제한됩니다.

<div class="content-ad"></div>

1. 미완전한 범위

LLM은 훈련 데이터에서 자주 언급되는 사실적 지식에 노출됩니다. 이는 긴 꼬리 엔터티와 드물게 논의되는 인과 관계를 위한 공백을 남깁니다. 지식 그래프는 흔한 것과 드물게 나타나는 세계 지식의 구조화된 저장소를 포함합니다.

2. 기본 스키마 없음

사전 훈련은 엔터티, 속성, 의존성의 조직화된 표현 없이 비구조적입니다. 이는 추론 중 특정 이벤트/엔터티에 대한 관련 사실 및 관계를 상기하는 데 비효율적으로 만듭니다. 지식 그래프는 스키마 기반 구조화된 기억을 제공합니다.

<div class="content-ad"></div>

3. 유효성 검증 소스가 없어요

LLM은 추측한 사건, 요소, 맥락 사이의 관계가 사실적으로 올바른지 확인할 근거가 없습니다. 지식 그래프에 연결하여 알려진 사실에 대한 확인을 할 수 있어요.

4. 맥락 부족

LLM에 대한 프롬프트는 종종 관련 세부사항을 충분히 명시하지 않아요. LLM들이 이에 근거 없는 가정을 하곤 해요. 풍부한 지식 그래프에 접근하여 결정에 도움이 되는 환경/역사적 세부사항을 제공할 수 있어요.

<div class="content-ad"></div>

**5. 일관성을 보장하지 않습니다**

LLM이 내린 단독 인과 판단은 동일 시나리오에 대해 논리적으로 서로 모순될 수 있습니다. 지식 그래프는 통일된 온톨로지를 사용하여 의사 결정의 전역 논리적 일관성을 강제합니다.

이러한 측면들을 다룸으로써, 지식 그래프를 통합함으로써 LLM의 능력이 얕은 패턴인식에서 견고한 구조화된 추론으로 원천적으로 진화합니다. 이러한 변화는 다양한 맥락에서 신뢰할 수 있는 추론을 할 수 있는 AI 어시스턴트를 위해 중요합니다.

# 알고리즘의 역할

<div class="content-ad"></div>

게다가, 강화되지 않은 LLM은 다단계 인과 추론에 어려움을 겪고, 잠재적 혼동을 체계적으로 고려하지 못합니다. 그들의 추론은 국부적이며, 전역적 인과 일관성을 최적화하도록 되어 있지 않습니다. 알고리즘은 언어 모델의 유연한 지능을 보완해야 합니다.

인과 발견 알고리즘은 관찰 데이터를 처리하여 인과 관계를 발견하고 그래픽 모델을 구축할 수 있습니다. 다른 알고리즘은 개입적 추론에 특화되어 있어 행동의 효과를 예측합니다. 일부 알고리즘은 텍스트에서 지정된 효용성과 선호도에 기초하여 개입을 최적화합니다.

복잡한 추론의 확장

강화되지 않은 언어 모델은 복잡한 다단계 인과 추론에서 실패합니다. 수십 개의 현실 세계 이벤트/개체를 아우르는 인과 사슬을 발견하기 위해서는 구조화된 알고리즘이 필요합니다, 지식 그래프에 액세스가 가능하더라도요.

<div class="content-ad"></div>

알고리즘은 원인 경로를 체계적으로 탐색하여 지역 LLM 판단을 전체적으로 일관성 있는 내러티브로 엮어냅니다. 또한, 공리적 추론을 통해 결정을 공식적으로 검증하며, 판단이 논리적으로 존재론적 제약 조건을 지키는지 증명합니다.

대규모 문제의 효율적인 추론

수십억 개의 엔티티와 관계로 이루어진 거대 그래프 상에서 LLM 판단을 철저히 탐색하는 것은 불가능합니다. 알고리즘은 그래프를 효율적으로 탐색하기 위해 정보에 기반한 탐색 휴리스틱을 활용하며, 무작위적인 탐색 대신 지능적인 검색을 통해 그래프를 탐색합니다.

전문화된 서브그래프 식별 알고리즘은 관련된 일련의 사건과 관련이 깊은 관계를 가진 그래프 조각만 추출합니다. 이렇게 함으로써 추론 검색 공간을 줄이고 효율적인 쿼리를 최소화합니다.

<div class="content-ad"></div>

**규모에 따른 일관성**

알고리즘 없이는 거대한 멀티도메인 지식 그래프 전체에서의 표현과 결정이 쉽게 모순될 수 있습니다. 알고리즘은 이러한 모순을 감지하고 해소하여 결론이 논리적으로 일관되게 유지되도록 합니다.

또한, 사실적인 지식이 불완전한 상황에서 그래프 분석을 사용하여 추론 가능한 결과를 보충함으로써 부분적인 지식을 완성합니다. 이를 통해 KG의 크기나 문맥의 특이성에 관계없이 출력 안정성을 유지합니다.

Efficient Causal Graph Discovery Using Large Language Models와 같은 최근 연구 결과는, LLMs가 인과 추론 능력을 보여주기는 하지만 그 방법이 확장이 잘 되지 않는다는 것을 입증합니다. 이전 방법은 모든 변수 쌍에 대해 LLM을 철저히 쿼리하여 제곱 시간 복잡도를 필요로 했습니다.

<div class="content-ad"></div>

해당 내용은 선형 시간 알고리즘을 도입하여 LLM의 판단을 활용하여 인과 그래프를 구성하는 너비 우선 탐색 프레임워크를 소개했습니다. 이는 알고리즘이 효율성을 위해 LLM 사용을 최적화하는 방법을 보여줍니다.

이 작업의 핵심 이노베이션은 너비 우선 탐색(BFS) 알고리즘을 사용하여 LLM에 쿼리를 보내는 것으로 인과 그래프를 반복적으로 구성하는 것이며, 각 변수 쌍에 대해 철저히 묻는 대신 (제곱 시간 복잡성이 필요한) 방식입니다.

구체적으로:

- BFS 알고리즘은 먼저 LLM에게 원인이 없는 "루트" 변수를 식별하도록 요청합니다. 이러한 변수들이 대기열에 추가됩니다.
- 그런 다음 대기열의 각 변수가 확장됩니다 - LLM에게 해당 변수에 인과적으로 영향을받는 변수를 나열하도록 요청합니다.
- 이러한 변수들이 그래프에 추가되고 추가 확장을 위해 대기열에 추가됩니다. 단, 이러한 변수가 순환 구조를 만들지 않도록 합니다.
- 모든 변수가 방문될 때까지 이 과정이 반복됩니다.

<div class="content-ad"></div>

그래서 각 단계에서 알고리즘은 두 변수 간의 관계 질문으로 애매모호해지지 않도록, 단일 변수의 효과에 관한 집중된 판단을 LLM에 요청합니다.

BFS 방문 순서로 인해 각 변수에 대해 효과에 관해 한 번씩만 질문됨으로써 핵심 효율성이 실현됩니다. 이로써 변수 수 N에 대한 쿼리 수가 O(N²)에서 O(N)으로 줄어들게 되는데, 이는 계산 효율성이 상당히 향상된 것입니다.

본질적으로 알고리즘은 LLM 인과 판단의 활용을 최적화하며, 전체 그래프를 규모에 맞게 확장하여 구성함으로써 짝지어질 때 가능했던 것과 같은 방식으로 확장됩니다.

# 통합 인과 추론 시스템

<div class="content-ad"></div>

대형 언어 모델은 명시적으로 인과 추론 능력을 증명했습니다. 텍스트 데이터의 패턴을 직관적으로 이해하고 그것을 통해 사건의 인과 관계를 판단합니다. 그러나 유연하고 탄탄한 인간의 원인 추론 능력을 완전히 재현하기 위해서는 단순한 통계적 패턴 인식 이상이 필요합니다.

하지만 더 복잡한 현실 시나리오에 대해서는 추가적인 제약 사항이 드러납니다. 대형 언어 모델은 사람들이 추론에 통합하는 방대한 배경 지식을 부족하게 합니다. 콘텍스트 요소가 어떻게 상호 작용하고 결과에 영향을 주는지를 이해하는 것입니다. 그들의 판단은 국부적으로 일관성이 있을 수 있지만 전체적으로 일관성이 없을 수 있습니다.

지식 그래프는 이러한 문제에 대처하는 데 도움을 줍니다. 그들은 사건, 개체 및 그들의 종속성에 대한 빠진 콘텍스트 세부 사항을 제공하여 실제 세계의 원인 메커니즘을 대표합니다. 알고리즘은 그래프를 통해 인과 추론을 최적화하며 논리적 일관성을 유지합니다.

지식 그래프와 알고리즘이 함께하는 일:

<div class="content-ad"></div>

- 중복 쿼리를 줄여 LLM 추론을 확장성 있게 만들기
- 단독 판단이 아닌 다단계 인과 관계를 최적화
- 지역적 결정을 검증하여 전역적 일관성 유지
- 맥락적 판단을 위한 현실 세계 스키마 제공

지식은 지식 그래프의 상징적 엄밀성을 LLM의 유동적 인텔리전스와 연결합니다. 그리고 알고리즘은 그들을 결합하여 성능을 향상시킵니다. 이 공생 통합은 판단을 현실적 인과 시스템에서 중요성을 부여함으로써 맥락 속에서 학습을 강화합니다.

따라서 지식 그래프와 알고리즘은 LLM을 단순히 증폭시키는 것뿐만 아니라 확장성과 일관성 문제를 극복하기 위해 그 능력을 최적화하고 맥락을 제공합니다.

언어 모델의 유동적 추론을 구조화된 현실 지식과 인과 알고리즘과 밀접하게 결합해야 합니다. 지식 그래프는 알려진 인과 메커니즘을 나타내는 화식적 메모리를 제공합니다. 알고리즘은 일관성을 위한 논리적 연역, 추론 및 최적화를 다룹니다.

<div class="content-ad"></div>

함께하여, 언어 모델의 고유한 한계를 우회합니다. 지역적인 판단이 세계적으로 일치하도록 하여 그들을 더욱 견고하게 만들고, 가정을 없애기 위해 누락된 맥락을 제공하며, 결정을 형식적으로 확인합니다. 이 엔슨블은 섬세한 설명 가능한 인텔리전스에 힘을 실어줍니다.

이 통합된 접근법은 인공지능의 다음 진화를 주도할 수 있습니다. 단순히 결과를 예측하는 것이 아니라 전략을 제안해주며, 대안적 선택의 함의를 정량화하고, 복잡하게 연결된 세계 사건과의 인과 연결을 설명합니다.

이러한 모달리티를 통합한 시스템은 기계에 인과적 상상력을 부여하는 선도적 조건 인지 연구자들이 제시한 비전을 실현합니다. 이들은 우리에게 인과적 지혜가 공공 토론을 스며들게 하고 체계적인 영향 세평 검토로 정책이 나오는 미래를 상상하도록 합니다.

부분들의 합보다 더 큰 증강 인텔리전스를 구현한 통합 아키텍처는 인과 추론을 인간 인지의 만만치 않은 기둥으로 만들어줍니다. 설명 가능한 인공지능의 획기적인 발전을 기다리며 산업, 학계, 정부, 그리고 사회를 발전시키기 위한 기회일 것입니다.
