---
title: "데이터를 암기하지 않고 처리하는 방법 Goldfish LLM 사용법"
description: ""
coverImage: "/assets/img/2024-07-08-TheGoldfishLLMSwimmingThroughDataWithoutMemorizingIt_0.png"
date: 2024-07-08 00:06
ogImage: 
  url: /assets/img/2024-07-08-TheGoldfishLLMSwimmingThroughDataWithoutMemorizingIt_0.png
tag: Tech
originalTitle: "The Goldfish LLM: Swimming Through Data Without Memorizing It"
link: "https://medium.com/gitconnected/the-goldfish-llm-swimming-through-data-without-memorizing-it-5903e9bd90eb"
isUpdated: true
---





## |개인정보보호|기억|학습기계|비학습|

![TheGoldfishLLMSwimmingThroughDataWithoutMemorizingIt](/assets/img/2024-07-08-TheGoldfishLLMSwimmingThroughDataWithoutMemorizingIt_0.png)

마음이 아픈 이해관계는 암기와 일반화 사이의 섬세한 균형에 관한 것입니다. 결국, 대규모 언어 모델(Large Language Model, LLM)은 텍스트 시퀀스에서 다음 단어를 예측하도록 훈련되었으며 (그리고 막대한 양의 텍스트에 대해 반복된 접근으로 모델이 자신의 기능을 배우게 합니다). 능력을 학습하는 데 추가로, 모델은 제시된 텍스트를 기억합니다. 이러한 기억 회로는 초기 단계에서 가장 효율적이며 이러한 일반화 능력은 나중에 나타납니다. 더 깊이 있는 토론을 위해, 이곳에서 더 자세히 다루어 보았습니다.