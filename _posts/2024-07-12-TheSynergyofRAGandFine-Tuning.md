---
title: "RAG와 파인튜닝의 시너지 효과 최신 방법 알아보기"
description: ""
coverImage: "/assets/img/2024-07-12-TheSynergyofRAGandFine-Tuning_0.png"
date: 2024-07-12 23:14
ogImage:
  url: /assets/img/2024-07-12-TheSynergyofRAGandFine-Tuning_0.png
tag: Tech
originalTitle: "The Synergy of RAG and Fine-Tuning"
link: "https://medium.com/ai-in-plain-english/the-synergy-of-rag-and-fine-tuning-ff24701d9dcc"
isUpdated: true
---

인공 지능 소프트웨어를 사용하여이 기사 텍스트의 문법, 흐름 및 가독성을 향상시키는 데 성공했습니다.

대형 언어 모델(LLMs)은 다양한 영역에서 인간과 유사한 텍스트를 이해하고 생성하는 데 놀라운 성공을 거두었습니다.

사전 훈련 중 대규모 데이터 세트로부터 패턴을 활용할 수있는 능력을 통해 광범위한 지식과 강력한 언어 이해 능력을 습득할 수 있습니다.

그러나 놀랍도록 성능이 좋은에도 불구하고, LLMs는 여전히 일부 주요 제한 사항에 직면하고 있습니다. 그들의 지식은 종종 얕으며 특정 영역에서 깊이 있는 전문 지식이 부족합니다.

<div class="content-ad"></div>

또한, LLM(언어모델)은 다양한 웹 데이터로 훈련되어 있기 때문에 그들의 지식은 일관성이 없거나 권위 있는 사실에 기반하지 않을 수 있습니다. 이는 특히 지식 밀집적 분야에서 환각이나 잘못된 주장으로 이어질 수 있습니다.

이러한 단점을 해결하기 위해 연구자들은 외부 지식 원본을 활용하여 LLM을 강화하는 방법을 탐구해 왔습니다. 이러한 방법 중 두 가지 중요한 기술은 검색 증강 생성(RAG)과 도메인 적응 세밀 조정입니다.

검색 증강 생성(RAG)은 LLM과 정보 검색 시스템을 결합하여 외부 소스에서 입력 컨텍스트에 기반한 관련 문서, 단락 또는 지식 단편을 가져올 수 있는 방법을 포함합니다. 추론 과정에서 검색된 지식이 입력에 덧붙여져 LLM이 신뢰할 만한 소스의 사실적 정보를 기반으로 생성되도록 하여 정보를 보충합니다. RAG는 오픈 도메인 질문 응답 및 지식 밀집적 작업에서 훌륭한 결과를 보여주었습니다.

반면, 도메인 적응 세밀 조정은 일반적인 LLM을 특정 관심 분야의 데이터로 세밀하게 조정하여 전문화하는 작업을 목표로 합니다. 도메인 특정 텍스트로 훈련함으로써 LLM은 해당 분야에 맞춤화된 지식과 언어 패턴을 습득하여 관련 작업에서 성능을 크게 향상시킵니다. 이 방법은 생명 과학, 컴퓨터 과학, 금융 및 법률과 같은 분야에서 효과적임이 입증되었습니다.

<div class="content-ad"></div>

RAG은 추론 중에 외부 지식을 사용하여 LLM을 강화하고, 파인 튜닝은 훈련 중에 도메인 특화 지식을 전달합니다. 이 두 가지 방법은 대부분 별개로 탐구되어 왔습니다. 그러나 최근 연구에서는 RAG와 파인 튜닝 기술을 결합하여, 지식을 보유하고 도메인에 특화된 LLM을 만들 수 있는 잠재력을 강조했습니다.

RAG 능력을 파인 튜닝 과정에 통합하는 것은 LLM이 검색된 지식을 효과적으로 출력물에 통합하는 방법을 학습하고 동시에 도메인 전문 지식을 습득하게 합니다. 그 반대로, 도메인 데이터에서 RAG 모델을 파인 튜닝하면 검색 능력과 해당 도메인에 특화된 지식 기반을 개선할 수 있습니다.

다음 장에서는 RAG와 파인 튜닝을 시너지 효과를 내는 최근 제안된 방법들인 RAFT(검색 증강 파인 튜닝) 및 RoG(그래프 추론)과 같은 기술에 대해 자세히 살펴보겠습니다.

이 기술들이 어떻게 작동하며, 주요 이점과 가능한 적용 분야에 대해 알아보겠습니다.

<div class="content-ad"></div>

외부 지식 액세스와 도메인 특화를 결합함으로써, 여러 분야의 실제 응용 프로그램을 위한 더 많은 지식이 풍부하고 근거가 있으며 믿을 만한 LLM을 만드는 길을 열어놓습니다.

![RAG](/assets/img/2024-07-12-TheSynergyofRAGandFine-Tuning_0.png)

# Retrieval-Augmented Generation (RAG)

Retrieval-Augmented Generation (RAG)은 추론 중에 언어 모델이 외부 지식 원본에 액세스하고 논리를 추론할 수 있도록 하는 방법론입니다. RAG의 핵심 아이디어는 사전에 훈련된 언어 모델과 정보 검색 시스템을 결합하여 두 구성 요소의 강점을 결합한 모듈식 아키텍처를 만드는 것입니다.

<div class="content-ad"></div>

The RAG framework involves a series of crucial steps:

- **Input Processing**: The user inputs a query or prompt, which the system then analyzes using the language model to understand the intent and information required.
- **Retrieval**: The retrieval module scans an external knowledge source, like a document corpus or knowledge base, to fetch information that might be relevant, such as passages, documents, or knowledge snippets.
- **Context Integration**: The retrieved context is merged with the original input to create an enriched prompt containing both the query and additional knowledge.
- **Language Model Generation**: The language model evaluates the augmented prompt and generates a response, using the context provided to ensure the response is based on factual information from the external source.

RAG has demonstrated positive outcomes in tasks such as open-domain question answering, knowledge-based challenges, and even code creation by retrieving relevant documentation or examples. By incorporating external knowledge, RAG models can deliver responses that are more accurate and informative than language models that operate solely on pre-existing knowledge.

However, a notable limitation of conventional RAG frameworks is that the retrieval component is usually kept static during training. This implies that the language model does not learn to effectively utilize the retrieved information or adapt its reasoning across various knowledge domains. The retrieval module functions independently, and its performance relies heavily on the quality and relevance of the information it retrieves.

<div class="content-ad"></div>

# 도메인별 세밀 조정

세밀 조정은 대규모 사전 훈련된 언어 모델(LLMs)을 특정 하위 작업이나 도메인에서 잘 수행하도록 적응시키는 강력한 기술로 부상했습니다. 세밀 조정의 핵심 아이디어는 데이터의 넓은 코퍼스에서 사전 훈련된 LLM을 취하고 나서 해당 하위 작업이나 도메인에 맞춘 작은 데이터셋에서 이어서 훈련(또는 "세밀 조정")하여 파라미터를 조정하는 것입니다.

세밀 조정 중에는 사전 훈련된 LLM의 가중치를 조절하고 도메인별 데이터에 존재하는 패턴, 어휘 및 지식에 특화되도록 합니다. 이 과정은 LLM이 해당 도메인과 관련된 지식과 언어 능력을 습득하도록 도와주어 관련된 하위 응용 프로그램에서 성능을 개선합니다.

도메인별 세밀 조정은 일반적이고 조정되지 않은 LLM보다 다양한 도메인에서 상당한 개선을 보여주었습니다.

<div class="content-ad"></div>

- 생명 과학: 과학 문헌과 의료 데이터의 세밀한 조정을 통해 LLM(언어 모델)은 문제 해결, 문헌 분석, 심지어 의료 코딩과 같은 작업을 지원할 수 있습니다.
- 컴퓨터 과학: 코드 저장소와 문서에서의 세밀한 조정은 LLM이 코드 생성, 문서 이해, 개발자 지원 도구 강화하는 데 도움을 줍니다.
- 금융: 금융 뉴스, 보고서, 분석에 대한 세밀한 조정은 LLM이 주식 예측, 위험 평가, 금융 보고서 생성과 같은 작업에서 성능을 향상시킬 수 있습니다.
- 법률: 법률 문서와 판례에 대한 세밀한 조정은 LLM이 법률 연구 지원, 계약 분석, 심지어 법률 문서 작성을 제공할 수 있게 합니다.

도메인 특화 세밀한 조정의 성공은 LLM이 세밀한 조정 데이터에 포함된 도메인 특화 지식, 용어, 스타일 패턴 및 추론 방법론을 포착할 수 있는 능력에 기인합니다. 이 획득된 도메인 전문지식은 LLM이 해당 도메인에 대해 더 정확하고 관련성 높고 믿을 만한 출력물을 생성할 수 있게 합니다.

## 전통적 세밀한 조정의 한계

도메인 특화 세밀한 조정이 LLM의 성능을 향상시키는 데 효과적임이 입증되었지만, 전통적 세밀한 조정 방법에는 중요한 제한 사항이 있습니다: 외부 지식 검색 능력을 명시적으로 통합하지 않습니다. 세밀한 조정 과정에서 LLM의 지식 습득은 제공된 세밀한 조정 데이터셋에서만 배울 수 있는 것으로 한정됩니다.

<div class="content-ad"></div>

이러한 제한은 지식이 지속적으로 발전하거나 세부 튜닝 데이터가 작업에 필요한 정보의 전체 범위를 다루지 못할 수 있는 도메인에서 문제가 될 수 있습니다. 게다가, 세부 조정 데이터는 미세 조정된 LLM에 전파될 수 있는 일관성, 편향 또는 지식의 공백을 포함할 수 있습니다.

# 시너지 효과적인 해결책: RAG + Fine-Tuning

RAG와 도메인별 세부 튜닝은 개별적으로 유망한 결과를 보여주었지만, 최근 연구에서는 이러한 접근 방법의 강점을 시너지적으로 결합하는 방법을 제안했습니다. 외부 지식 검색을 세부 튜닝 프로세스에 통합함으로써, 이러한 기술은 자신의 도메인에 특화된 언어 모델을 생성하는 것뿐만 아니라 결과물을 권위 있는 소스에 근거지으면서 가장 최신이고 포괄적인 정보를 활용하는 능력을 갖춘 언어 모델을 만들고 있습니다.

## 검색 증강 세부 튜닝 (RAFT)

<div class="content-ad"></div>

하나의 접근 방식인 리트리벌 보강 파인 튜닝(RAFT)은 "도메인 특화 RAG에 어댑팅된 언어 모델" 논문에서 소개되었습니다. RAFT는 도메인 특화 리트리벌 보강 생성(RAG)을 수행하는 언어 모델의 능력을 향상시키기 위해 설계된 파인 튜닝 방법입니다.

RAFT의 주요 아이디어는 언어 모델을 도메인 특화 데이터셋으로 파인 튜닝하는 것으로, 이 데이터셋은 관련 있는 ("오라클") 문서와 관련 없는 ("방해 요소") 문서를 모두 포함합니다. 파인 튜닝 중에 모델은 오라클 문서로부터 관련 정보를 인용하고 방해 요소 문서를 무시하면서 답변을 생성하도록 훈련됩니다.

RAFT 훈련 과정은 다음 단계를 포함합니다:

- 질문-답변 쌍, 답변이 포함된 오라클 문서 및 답변과 관련 없는 방해 요소 문서를 포함하는 도메인 특화 데이터셋 구성
- 일부 훈련 예제에서는 오라클 문서가 함께 제시되며 방해 요소 문서 집합이 제공됩니다.
- 나머지 예제에서는 오라클 문서 없이 방해 요소 문서만 제공됩니다.
- 제공된 문서와 질문에서 답변을 생성하기 위해 지도 학습을 사용하여 언어 모델을 파인 튜닝합니다.
- 모델은 오라클 문서에서 관련 단락을 명확하게 인용하는 "사고의 연쇄" 스타일 답변을 생성하도록 유도됩니다.

<div class="content-ad"></div>

RAFT은 모델이 관련 및 관련 없는 문서를 미세 조정하는 과정을 통해 가르치는데, 이를 통해 모델은 주요한 정보를 식별하고 활용하면서 방해요소를 무시하는 방법을 배웁니다. 이 과정을 통해 모델은 도메인별 RAG를 수행할 수 있는 능력을 향상시키며, 관련 도메인 지식을 검색하고 추론하는 것을 통해 질문에 답하는 능력이 향상됩니다.

## 그래프 추론 (RoG)

다른 상호 작용적인 접근 방식은 그래프 추론 (RoG)으로, 이는 언어 모델과 구조화된 지식 그래프 (KGs)를 통합하는 데 초점을 맞춥니다. RoG는 언어 모델과 지식 그래프의 장점을 통합하여 충실하고 해석 가능한 추론을 가능하게 하려는 목표를 갖고 있습니다.

RoG 프레임워크는 세 가지 주요 구성 요소로 구성됩니다:

<div class="content-ad"></div>

- 계획 모듈: 이 모듈은 언어 모델에게 주어진 질문에 대한 답변을 위해 지식 그래프를 기반으로 생성된 관계 시퀀스로 나타낸 고수준 계획을 생성하도록 유도합니다.
- 검색 모듈: 생성된 관계 시퀀스를 가이드로 사용하여, 이 모듈은 지식 그래프에서 특정 경로를 검색하여 답변이 포함될 수 있는 경로를 검색합니다.
- 추론 모듈: 지식 그래프에서 검색된 경로는 언어 모델에게 제공되며, 모델은 이러한 경로의 가능성에 기반하여 답변을 생성합니다.

RoG의 핵심은 언어 모델이 지식 그래프 데이터 세트에서 질문에 대한 답변을하고하는 데 미세 조정되었다는 점입니다. 미세 조정 과정에서 모델은 지식 그래프에 근거한 유효한 관계 경로를 생성함을 학습하고, 그래프에서 검색된 경로에 기반하여 추론하는 능력에 대한 최적화를 진행합니다.

이러한 미세 조정 과정을 통해 언어 모델은 그래프에 인코딩된 구조화된 지식을 활용하여 충실하고 해석 가능한 추론을 수행하는 법을 배웁니다. 생성된 답변은 지식 그래프에서 검색된 명시적인 경로에 근거하여 강인성과 신뢰성을 향상시킵니다.

# 상호 협력적 접근법의 혜택

<div class="content-ad"></div>

**지식 기반 확립:**

레그(RAG)와 세밀 조정 접근 방식의 주요 이점 중 하나는 언어 모델이 외부 지식 원천에서 자신의 추론과 생성을 바탕으로 하는 것을 가능하게 한다는 것입니다. 이를 통해 언어 모델이 사전 훈련 데이터만을 기반으로 사물적으로 올바르지만 사실적으로 부정확한 결과물을 생성하는 환각 문제를 완화할 수 있습니다.

세밀 조정 과정 중 외부 지식 검색 기능을 통합함으로써, 이러한 방법들은 언어 모델이 도메인별 문서 수집 또는 구조화된 지식 그래프와 같은 권위 있는 정보 원천을 활용하도록 가르치게 됩니다. 이러한 실질 지식 원천에 대한 기반은 언어 모델의 출력물의 정확도와 신뢰성을 향상시키며, 잘못된 정보 생성이나 모순된 진술을 하는 가능성을 줄입니다.

**도메인 적응:**

이렇게 융합적인 접근 방식의 또 다른 중요한 장점은 세밀 조정을 통해 언어 모델을 특정 도메인에 맞게 조정할 수 있는 능력입니다. 도메인별 데이터에 대해 세밀 조정함으로써, 언어 모델은 해당 도메인에 관련된 지식, 용어, 스타일적 패턴 및 추론 방법론을 습득할 수 있습니다.

<div class="content-ad"></div>

이 도메인 적응은 언어 모델이 해당 도메인 내의 하위 작업과 응용 프로그램을 더 잘 수행하도록 합니다. 예를 들어, 생물 의학 문헌에 대해 세밀하게 조정된 언어 모델은 의료 질문 응답, 문헌 분석 또는 진단 지원과 같은 작업을 수행하는 데 일반적이고 조정되지 않은 모델보다 능숙할 수 있습니다.

**해석 가능성:**

RoG (Reasoning on Graphs)와 같은 특정한 상호 작용 방법은 추론 가능한 추론 경로를 결과물의 일부로 생성합니다. 지식 그래프에서 검색된 관계 또는 경로의 시퀀스로 추론 과정을 명시적으로 나타내면 이러한 방법은 언어 모델이 최종 답변에 도달하는 방법에 대한 투명성을 제공합니다.

해석 가능성은 언어 모델에 대한 신뢰를 구축하는 데 중요합니다, 특히 설명 가능성과 책임성이 중요한 고위험 도메인에서는 더욱 그렇습니다. 추론 과정을 이해함으로써 사용자는 모델의 출력의 타당성과 정확성을 평가할 수 있으며, 신뢰를 형성하고 보다 정보에 기반한 의사 결정을 내릴 수 있게 됩니다.

<div class="content-ad"></div>

## 유연성:

시너지적 RAG + 세밀 조정 접근법은 활용할 수 있는 지식 소스 측면에서 유연합니다. RAFT (검색 보완 세밀 조정)와 같은 방법은 구조화되지 않은 문서 컬렉션과 작동할 수 있으며, RoG는 언어 모델을 구조화된 지식 그래프와 통합할 수 있습니다.

이 유연성은 시너지 접근법이 과학 논문 및 뉴스 기사에서부터 도메인별 지식 베이스 및 온톨로지까지 다양한 도메인과 지식 소스에 적용될 수 있게 합니다. 이 넓은 적용 가능성은 다양한 지식 집약적 응용 프로그램에 대해 이 접근법을 가치 있게 만듭니다.

## 확장성:

<div class="content-ad"></div>

시너지 메서드의 주요 장점 중 하나는 대형 언어 모델의 자가 감독 사전 훈련 능력을 활용할 수 있다는 것입니다. 이들 사전 훈련 모델은 이미 방대한 일반 지식을 보유하고 있어, 새로운 도메인이나 지식 소스에 효율적으로 적응시킬 수 있습니다.

미세 조정은 처음부터 사전 훈련을 하는 것에 비해 비교적 계산 효율적인 프로세스입니다. 이를 통해 언어 모델을 새로운 도메인이나 지식 소스에 확장적으로 적응시키는 것이 가능해집니다. 이런 확장성은 지식 소스의 폭과 복잡성이 계속해서 증가함에 따라 중요한데, 언어 모델이 최신 정보를 반영하고 관련성을 유지할 수 있도록 해줍니다.

외부 지식 접근과 도메인 별 지식 습득을 결합한 시너지적 RAG + 미세 조정 접근법은 기존 언어 모델과 미세 조정 방법의 몇 가지 한계를 극복합니다. 이러한 해결책은 질문 응답 시스템, 추천 엔진부터 과학 연구 및 의사 결정 지원 도구까지 다양한 지식 중심 응용 프로그램에서 뛰어난 언어 모델을 만들 수 있는 길을 열어줍니다.

# 잠재적 응용 분야

<div class="content-ad"></div>

## 전문 분야를 위한 질문 응답 시스템:

의학, 법률 및 과학 분야와 같은 전문 분야에 맞춘 질문 응답 시스템 개발은 가장 유망한 응용 중 하나입니다. 이러한 분야들은 종종 심층적인 도메인 지식, 권위 있는 출처에 대한 접근 및 복잡한 정보에 대한 추론 능력이 필요합니다.

RAG 기능을 도메인별 세부 조정과 통합하면, 언어 모델을 훈련시켜 관련 문서, 사례 법률, 연구 논문 또는 도메인별 지식 베이스를 검색하고 추론할 수 있습니다. 이를 통해 해당 분야의 권위 있는 출처에 근거한 정확하고 신뢰할 수 있는 응답을 제공할 수 있는 지능형 질문 응답 보조 도구를 만들 수 있습니다.

<div class="content-ad"></div>

시너지적 접근은 특정 프로그래밍 언어, 프레임워크 또는 코드베이스에 대한 코드 생성 및 문서 이해를 혁신할 수 있습니다. 언어 모델은 코드 저장소, API 문서 및 코드 예제에서 세밀하게 조정될 수 있어서 도메인별 프로그래밍 구조, 규칙 및 모범 사례에 대한 지식을 습득할 수 있습니다.

RAG 기능을 이용하면 이러한 세밀하게 조정된 모델이 관련 코드 조각, 문서 섹션 또는 Stack Overflow 토론을 검색하여 코드 생성 및 설명 역량을 맥락화하고 강화할 수 있습니다. 이는 개발자들을 위한 강력한 도구를 만들어내며, 더 효율적이고 정확한 코드 완성, 문서 생성 및 코드 이해 지원이 가능해질 수 있습니다.

## 구조화된 지식 그래프를 활용한 추천 시스템:

추천 시스템은 RAG 및 세밀한 조정 기술을 통합하는 데 큰 이점을 얻을 수 있습니다, 특히 구조화된 지식 그래프를 활용할 때. 언어 모델은 제품 카탈로그, 사용자 선호도 또는 엔터테인먼트 온톨로지와 같은 도메인별 지식 그래프에서 세밀하게 조정될 수 있습니다.

<div class="content-ad"></div>

이 도메인 지식을 RAG 기능과 결합하면, 추천 시스템이 구조화된 지식 그래프에 기반한 맞춤형 추천을 생성할 수 있습니다. 언어 모델은 사용자의 선호도, 제품 속성 및 그래프 내에서의 관계에 대해 추론하여 더 정확하고 설명 가능한 추천을 제공할 수 있습니다.

## 약물 발견 및 생물 의학 연구:

생물 의학 및 제약 분야는 시너지적 관점에서 크게 이점을 얻을 수 있습니다. 언어 모델은 방대한 과학 문헌, 임상 실험 데이터 및 생물 의학 지식 베이스를 기반으로 세밀하게 조정될 수 있으며, 깊은 도메인 지식과 추론 능력을 획들할 수 있게 됩니다.

RAG 기능을 통해 이러한 세밀하게 조정된 모델은 관련 연구 논문, 약물 화합물 데이터베이스 및 생물학적 경로 정보를 검색하고 추론하여 약물 발견, 약물 재활용, 개인 맞춤 의학 및 문헌 기반 발견과 같은 다양한 작업을 지원할 수 있습니다.

<div class="content-ad"></div>

이러한 특정 응용 분야를 넘어서, RAG와 세밀한 조정의 시너지는 금융, 교육, 고객 지원 및 결정 지원 시스템을 포함한 다양한 지식 집약적 도메인에 대한 약속을 가지고 있습니다. 이 분야에서의 연구가 진전됨에 따라, 외부 지식을 언어 모델에 원활하게 통합하여 이해가 더 많이 되고 근거 있는 그리고 신뢰할 만한 AI 시스템을 가능케 하는 더 정교한 기술들을 기대할 수 있을 것입니다.

이러한 응용 프로그램의 전체 잠재력을 발휘하기 위한 열쇠는 도메인별 지식 원본을 활용한 언어 모델의 세밀한 조정의 견고하고 확장 가능한 방법의 개발과 함께 효율적이고 효과적인 검색 메커니즘입니다. 게다가, 지식 베이스의 불완전성, 진화 및 모호한 사용자 쿼리와 같은 도전에 대처하는 것이 신뢰할 수 있고 영향력 있는 솔루션을 제공하는 데 중요한 역할을 할 것입니다.

**결론**

검색 증강 생성(RAG)과 도메인별 세부 조정의 결합은 외부 지식과 도메인 전문 지식으로 대규모 언어 모델을 강화하는 강력한 솔루션을 제공합니다. 두 가지 접근 방식의 장점을 활용하여 연구자들은 LLMs를 이해가능한 정보에 근거를 두고, 전문화 된 도메인에 적응하며, 보다 해석 가능하고 신뢰할 수 있는 결과물을 생성할 수 있는 방법을 개발했습니다.

<div class="content-ad"></div>

RAG와 섬세한 조정 사이의 시너지가 계속해서 탐구되는 가운데, 우리는 넓은 지식뿐만 아니라 심도 있는 도메인 전문 지식, 추론 능력 및 사실적인 정보에 기반을 둔 언어 모델을 기대할 수 있습니다. 이는 보다 지식이 풍부하고 신뢰할 만한 AI 시스템으로의 중요한 한 걸음입니다.

# 간단히 이야기하는 🚀

In Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:

- 반드시 박수를 치고 글쓴이를 팔로우하세요 ️👏️️
- 팔로우하기: X | LinkedIn | YouTube | Discord | 뉴스레터
- 다른 플랫폼 방문하기: Stackademic | CoFeed | Venture | Cubed
- PlainEnglish.io에서 더 많은 콘텐츠를 확인하세요.
